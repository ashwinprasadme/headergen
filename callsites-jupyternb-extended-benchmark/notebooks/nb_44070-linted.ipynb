{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5e350c0",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    },
    "source_hidden": true
   },
   "source": [
    "### Index of ML Operations<a id='top_phases'></a>\n",
    "<div><ul>\n",
    "<ul><li><details><summary style='list-style: none; cursor: pointer;'><strong>Imported Libraries</strong></summary>\n",
    "<ul>\n",
    "\n",
    "<li><b>datetime</b></li>\n",
    "<li><b>pandas</b></li>\n",
    "\n",
    "</ul>\n",
    "</details></li></ul>\n",
    "<ul><li><details><summary style='list-style: none;'><s>Visualization</s> (no calls found)</summary>\n",
    "<ul>\n",
    "\n",
    "None\n",
    "\n",
    "</ul>\n",
    "</details></li></ul>\n",
    "<li><details><summary style='list-style: none;'><h3><span style='color:#42a5f5'>Data Preparation</span></h3></summary>\n",
    "<ul>\n",
    "\n",
    "None\n",
    "\n",
    "</ul>\n",
    "</details></li>\n",
    "<ul><li><details><summary style='list-style: none; cursor: pointer;'><strong>Data Profiling and Exploratory Data Analysis</strong></summary>\n",
    "<ul>\n",
    "\n",
    "<li><details open><summary style='list-style: none; cursor: pointer;'><strong><u>Cell # 2</u></strong></summary><small><a href=#2>goto cell # 2</a></small>\n",
    "<ul>\n",
    "\n",
    "Code pattern match\n",
    "\n",
    "</ul>\n",
    "</details></li>\n",
    "<li><details open><summary style='list-style: none; cursor: pointer;'><strong><u>Cell # 3</u></strong></summary><small><a href=#3>goto cell # 3</a></small>\n",
    "<ul>\n",
    "\n",
    "Code pattern match\n",
    "\n",
    "</ul>\n",
    "</details></li>\n",
    "<li><details open><summary style='list-style: none; cursor: pointer;'><strong><u>Cell # 14</u></strong></summary><small><a href=#14>goto cell # 14</a></small>\n",
    "<ul>\n",
    "\n",
    "Code pattern match\n",
    "\n",
    "</ul>\n",
    "</details></li>\n",
    "<li><details open><summary style='list-style: none; cursor: pointer;'><strong><u>Cell # 25</u></strong></summary><small><a href=#25>goto cell # 25</a></small>\n",
    "<ul>\n",
    "\n",
    "Code pattern match\n",
    "\n",
    "</ul>\n",
    "</details></li>\n",
    "\n",
    "</ul>\n",
    "</details></li></ul>\n",
    "<ul><li><details><summary style='list-style: none;'><s>Data Cleaning Filtering</s> (no calls found)</summary>\n",
    "<ul>\n",
    "\n",
    "None\n",
    "\n",
    "</ul>\n",
    "</details></li></ul>\n",
    "<ul><li><details><summary style='list-style: none;'><s>Data Sub-sampling and Train-test Splitting</s> (no calls found)</summary>\n",
    "<ul>\n",
    "\n",
    "None\n",
    "\n",
    "</ul>\n",
    "</details></li></ul>\n",
    "<li><details><summary style='list-style: none;'><h3><span style='color:#42a5f5'>Feature Engineering</span></h3></summary>\n",
    "<ul>\n",
    "\n",
    "None\n",
    "\n",
    "</ul>\n",
    "</details></li>\n",
    "<ul><li><details><summary style='list-style: none; cursor: pointer;'><strong>Feature Transformation</strong></summary>\n",
    "<ul>\n",
    "\n",
    "<li><details><summary style='list-style: none; cursor: pointer;'><u>View All \"Feature Transformation\" Calls</u></summary>\n",
    "<ul>\n",
    "\n",
    "<li> <b>pandas</b>\n",
    "<ul>\n",
    "<li>\n",
    "<details><summary style='list-style: none; cursor: pointer;'><u>pandas.core.generic.NDFrame._add_numeric_operations.<locals>.sum</u> | (No Args Found) </summary>\n",
    "<blockquote>\n",
    "<code>\n",
    "Return the sum of the values over the requested axis.\n",
    "\n",
    "This is equivalent to the method ``numpy.sum``.\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "axis : {index (0), columns (1)}\n",
    "    Axis for the function to be applied on.\n",
    "skipna : bool, default True\n",
    "    Exclude NA/null values when computing the result.\n",
    "level : int or level name, default None\n",
    "    If the axis is a MultiIndex (hierarchical), count along a\n",
    "    particular level, collapsing into a Series.\n",
    "numeric_only : bool, default None\n",
    "    Include only float, int, boolean columns. If None, will attempt to use\n",
    "    everything, then use only numeric data. Not implemented for Series.\n",
    "min_count : int, default 0\n",
    "    The required number of valid values to perform the operation. If fewer than\n",
    "    ``min_count`` non-NA values are present the result will be NA.\n",
    "**kwargs\n",
    "    Additional keyword arguments to be passed to the function.\n",
    "\n",
    "Returns\n",
    "-------\n",
    "Series or DataFrame (if level specified)\n",
    "\n",
    "See Also\n",
    "--------\n",
    "Series.sum : Return the sum.\n",
    "Series.min : Return the minimum.\n",
    "Series.max : Return the maximum.\n",
    "Series.idxmin : Return the index of the minimum.\n",
    "Series.idxmax : Return the index of the maximum.\n",
    "DataFrame.sum : Return the sum over the requested axis.\n",
    "DataFrame.min : Return the minimum over the requested axis.\n",
    "DataFrame.max : Return the maximum over the requested axis.\n",
    "DataFrame.idxmin : Return the index of the minimum over the requested axis.\n",
    "DataFrame.idxmax : Return the index of the maximum over the requested axis.\n",
    "\n",
    "Examples\n",
    "--------\n",
    ">>> idx = pd.MultiIndex.from_arrays([\n",
    "...     ['warm', 'warm', 'cold', 'cold'],\n",
    "...     ['dog', 'falcon', 'fish', 'spider']],\n",
    "...     names=['blooded', 'animal'])\n",
    ">>> s = pd.Series([4, 2, 0, 8], name='legs', index=idx)\n",
    ">>> s\n",
    "blooded  animal\n",
    "warm     dog       4\n",
    "         falcon    2\n",
    "cold     fish      0\n",
    "         spider    8\n",
    "Name: legs, dtype: int64\n",
    "\n",
    ">>> s.sum()\n",
    "14\n",
    "\n",
    "By default, the sum of an empty or all-NA Series is ``0``.\n",
    "\n",
    ">>> pd.Series([], dtype=\"float64\").sum()  # min_count=0 is the default\n",
    "0.0\n",
    "\n",
    "This can be controlled with the ``min_count`` parameter. For example, if\n",
    "you'd like the sum of an empty series to be NaN, pass ``min_count=1``.\n",
    "\n",
    ">>> pd.Series([], dtype=\"float64\").sum(min_count=1)\n",
    "nan\n",
    "\n",
    "Thanks to the ``skipna`` parameter, ``min_count`` handles all-NA and\n",
    "empty series identically.\n",
    "\n",
    ">>> pd.Series([np.nan]).sum()\n",
    "0.0\n",
    "\n",
    ">>> pd.Series([np.nan]).sum(min_count=1)\n",
    "nan\n",
    "\n",
    "</code>\n",
    "<a href='#top_phases'>back to header</a>\n",
    "</blockquote>\n",
    "</details>\n",
    "</li>\n",
    "<li>\n",
    "<details><summary style='list-style: none; cursor: pointer;'><u>pandas.core.tools.datetimes.to_datetime</u> | (No Args Found) </summary>\n",
    "<blockquote>\n",
    "<code>\n",
    "Convert argument to datetime.\n",
    "\n",
    "This function converts a scalar, array-like, :class:`Series` or\n",
    ":class:`DataFrame`/dict-like to a pandas datetime object.\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "arg : int, float, str, datetime, list, tuple, 1-d array, Series, DataFrame/dict-like\n",
    "    The object to convert to a datetime. If a :class:`DataFrame` is provided, the\n",
    "    method expects minimally the following columns: :const:`\"year\"`,\n",
    "    :const:`\"month\"`, :const:`\"day\"`.\n",
    "errors : {'ignore', 'raise', 'coerce'}, default 'raise'\n",
    "    - If :const:`'raise'`, then invalid parsing will raise an exception.\n",
    "    - If :const:`'coerce'`, then invalid parsing will be set as :const:`NaT`.\n",
    "    - If :const:`'ignore'`, then invalid parsing will return the input.\n",
    "dayfirst : bool, default False\n",
    "    Specify a date parse order if `arg` is str or is list-like.\n",
    "    If :const:`True`, parses dates with the day first, e.g. :const:`\"10/11/12\"`\n",
    "    is parsed as :const:`2012-11-10`.\n",
    "\n",
    "    .. warning::\n",
    "\n",
    "        ``dayfirst=True`` is not strict, but will prefer to parse\n",
    "        with day first. If a delimited date string cannot be parsed in\n",
    "        accordance with the given `dayfirst` option, e.g.\n",
    "        ``to_datetime(['31-12-2021'])``, then a warning will be shown.\n",
    "\n",
    "yearfirst : bool, default False\n",
    "    Specify a date parse order if `arg` is str or is list-like.\n",
    "\n",
    "    - If :const:`True` parses dates with the year first, e.g.\n",
    "      :const:`\"10/11/12\"` is parsed as :const:`2010-11-12`.\n",
    "    - If both `dayfirst` and `yearfirst` are :const:`True`, `yearfirst` is\n",
    "      preceded (same as :mod:`dateutil`).\n",
    "\n",
    "    .. warning::\n",
    "\n",
    "        ``yearfirst=True`` is not strict, but will prefer to parse\n",
    "        with year first.\n",
    "\n",
    "utc : bool, default None\n",
    "    Control timezone-related parsing, localization and conversion.\n",
    "\n",
    "    - If :const:`True`, the function *always* returns a timezone-aware\n",
    "      UTC-localized :class:`Timestamp`, :class:`Series` or\n",
    "      :class:`DatetimeIndex`. To do this, timezone-naive inputs are\n",
    "      *localized* as UTC, while timezone-aware inputs are *converted* to UTC.\n",
    "\n",
    "    - If :const:`False` (default), inputs will not be coerced to UTC.\n",
    "      Timezone-naive inputs will remain naive, while timezone-aware ones\n",
    "      will keep their time offsets. Limitations exist for mixed\n",
    "      offsets (typically, daylight savings), see :ref:`Examples\n",
    "      <to_datetime_tz_examples>` section for details.\n",
    "\n",
    "    See also: pandas general documentation about `timezone conversion and\n",
    "    localization\n",
    "    <https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html\n",
    "    #time-zone-handling>`_.\n",
    "\n",
    "format : str, default None\n",
    "    The strftime to parse time, e.g. :const:`\"%d/%m/%Y\"`. Note that\n",
    "    :const:`\"%f\"` will parse all the way up to nanoseconds. See\n",
    "    `strftime documentation\n",
    "    <https://docs.python.org/3/library/datetime.html\n",
    "    #strftime-and-strptime-behavior>`_ for more information on choices.\n",
    "exact : bool, default True\n",
    "    Control how `format` is used:\n",
    "\n",
    "    - If :const:`True`, require an exact `format` match.\n",
    "    - If :const:`False`, allow the `format` to match anywhere in the target\n",
    "      string.\n",
    "\n",
    "unit : str, default 'ns'\n",
    "    The unit of the arg (D,s,ms,us,ns) denote the unit, which is an\n",
    "    integer or float number. This will be based off the origin.\n",
    "    Example, with ``unit='ms'`` and ``origin='unix'`` (the default), this\n",
    "    would calculate the number of milliseconds to the unix epoch start.\n",
    "infer_datetime_format : bool, default False\n",
    "    If :const:`True` and no `format` is given, attempt to infer the format\n",
    "    of the datetime strings based on the first non-NaN element,\n",
    "    and if it can be inferred, switch to a faster method of parsing them.\n",
    "    In some cases this can increase the parsing speed by ~5-10x.\n",
    "origin : scalar, default 'unix'\n",
    "    Define the reference date. The numeric values would be parsed as number\n",
    "    of units (defined by `unit`) since this reference date.\n",
    "\n",
    "    - If :const:`'unix'` (or POSIX) time; origin is set to 1970-01-01.\n",
    "    - If :const:`'julian'`, unit must be :const:`'D'`, and origin is set to\n",
    "      beginning of Julian Calendar. Julian day number :const:`0` is assigned\n",
    "      to the day starting at noon on January 1, 4713 BC.\n",
    "    - If Timestamp convertible, origin is set to Timestamp identified by\n",
    "      origin.\n",
    "cache : bool, default True\n",
    "    If :const:`True`, use a cache of unique, converted dates to apply the\n",
    "    datetime conversion. May produce significant speed-up when parsing\n",
    "    duplicate date strings, especially ones with timezone offsets. The cache\n",
    "    is only used when there are at least 50 values. The presence of\n",
    "    out-of-bounds values will render the cache unusable and may slow down\n",
    "    parsing.\n",
    "\n",
    "    .. versionchanged:: 0.25.0\n",
    "        changed default value from :const:`False` to :const:`True`.\n",
    "\n",
    "Returns\n",
    "-------\n",
    "datetime\n",
    "    If parsing succeeded.\n",
    "    Return type depends on input (types in parenthesis correspond to\n",
    "    fallback in case of unsuccessful timezone or out-of-range timestamp\n",
    "    parsing):\n",
    "\n",
    "    - scalar: :class:`Timestamp` (or :class:`datetime.datetime`)\n",
    "    - array-like: :class:`DatetimeIndex` (or :class:`Series` with\n",
    "      :class:`object` dtype containing :class:`datetime.datetime`)\n",
    "    - Series: :class:`Series` of :class:`datetime64` dtype (or\n",
    "      :class:`Series` of :class:`object` dtype containing\n",
    "      :class:`datetime.datetime`)\n",
    "    - DataFrame: :class:`Series` of :class:`datetime64` dtype (or\n",
    "      :class:`Series` of :class:`object` dtype containing\n",
    "      :class:`datetime.datetime`)\n",
    "\n",
    "Raises\n",
    "------\n",
    "ParserError\n",
    "    When parsing a date from string fails.\n",
    "ValueError\n",
    "    When another datetime conversion error happens. For example when one\n",
    "    of 'year', 'month', day' columns is missing in a :class:`DataFrame`, or\n",
    "    when a Timezone-aware :class:`datetime.datetime` is found in an array-like\n",
    "    of mixed time offsets, and ``utc=False``.\n",
    "\n",
    "See Also\n",
    "--------\n",
    "DataFrame.astype : Cast argument to a specified dtype.\n",
    "to_timedelta : Convert argument to timedelta.\n",
    "convert_dtypes : Convert dtypes.\n",
    "\n",
    "Notes\n",
    "-----\n",
    "\n",
    "Many input types are supported, and lead to different output types:\n",
    "\n",
    "- **scalars** can be int, float, str, datetime object (from stdlib :mod:`datetime`\n",
    "  module or :mod:`numpy`). They are converted to :class:`Timestamp` when\n",
    "  possible, otherwise they are converted to :class:`datetime.datetime`.\n",
    "  None/NaN/null scalars are converted to :const:`NaT`.\n",
    "\n",
    "- **array-like** can contain int, float, str, datetime objects. They are\n",
    "  converted to :class:`DatetimeIndex` when possible, otherwise they are\n",
    "  converted to :class:`Index` with :class:`object` dtype, containing\n",
    "  :class:`datetime.datetime`. None/NaN/null entries are converted to\n",
    "  :const:`NaT` in both cases.\n",
    "\n",
    "- **Series** are converted to :class:`Series` with :class:`datetime64`\n",
    "  dtype when possible, otherwise they are converted to :class:`Series` with\n",
    "  :class:`object` dtype, containing :class:`datetime.datetime`. None/NaN/null\n",
    "  entries are converted to :const:`NaT` in both cases.\n",
    "\n",
    "- **DataFrame/dict-like** are converted to :class:`Series` with\n",
    "  :class:`datetime64` dtype. For each row a datetime is created from assembling\n",
    "  the various dataframe columns. Column keys can be common abbreviations\n",
    "  like [‘year’, ‘month’, ‘day’, ‘minute’, ‘second’, ‘ms’, ‘us’, ‘ns’]) or\n",
    "  plurals of the same.\n",
    "\n",
    "The following causes are responsible for :class:`datetime.datetime` objects\n",
    "being returned (possibly inside an :class:`Index` or a :class:`Series` with\n",
    ":class:`object` dtype) instead of a proper pandas designated type\n",
    "(:class:`Timestamp`, :class:`DatetimeIndex` or :class:`Series`\n",
    "with :class:`datetime64` dtype):\n",
    "\n",
    "- when any input element is before :const:`Timestamp.min` or after\n",
    "  :const:`Timestamp.max`, see `timestamp limitations\n",
    "  <https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html\n",
    "  #timeseries-timestamp-limits>`_.\n",
    "\n",
    "- when ``utc=False`` (default) and the input is an array-like or\n",
    "  :class:`Series` containing mixed naive/aware datetime, or aware with mixed\n",
    "  time offsets. Note that this happens in the (quite frequent) situation when\n",
    "  the timezone has a daylight savings policy. In that case you may wish to\n",
    "  use ``utc=True``.\n",
    "\n",
    "Examples\n",
    "--------\n",
    "\n",
    "**Handling various input formats**\n",
    "\n",
    "Assembling a datetime from multiple columns of a :class:`DataFrame`. The keys\n",
    "can be common abbreviations like ['year', 'month', 'day', 'minute', 'second',\n",
    "'ms', 'us', 'ns']) or plurals of the same\n",
    "\n",
    ">>> df = pd.DataFrame({'year': [2015, 2016],\n",
    "...                    'month': [2, 3],\n",
    "...                    'day': [4, 5]})\n",
    ">>> pd.to_datetime(df)\n",
    "0   2015-02-04\n",
    "1   2016-03-05\n",
    "dtype: datetime64[ns]\n",
    "\n",
    "Passing ``infer_datetime_format=True`` can often-times speedup a parsing\n",
    "if its not an ISO8601 format exactly, but in a regular format.\n",
    "\n",
    ">>> s = pd.Series(['3/11/2000', '3/12/2000', '3/13/2000'] * 1000)\n",
    ">>> s.head()\n",
    "0    3/11/2000\n",
    "1    3/12/2000\n",
    "2    3/13/2000\n",
    "3    3/11/2000\n",
    "4    3/12/2000\n",
    "dtype: object\n",
    "\n",
    ">>> %timeit pd.to_datetime(s, infer_datetime_format=True)  # doctest: +SKIP\n",
    "100 loops, best of 3: 10.4 ms per loop\n",
    "\n",
    ">>> %timeit pd.to_datetime(s, infer_datetime_format=False)  # doctest: +SKIP\n",
    "1 loop, best of 3: 471 ms per loop\n",
    "\n",
    "Using a unix epoch time\n",
    "\n",
    ">>> pd.to_datetime(1490195805, unit='s')\n",
    "Timestamp('2017-03-22 15:16:45')\n",
    ">>> pd.to_datetime(1490195805433502912, unit='ns')\n",
    "Timestamp('2017-03-22 15:16:45.433502912')\n",
    "\n",
    ".. warning:: For float arg, precision rounding might happen. To prevent\n",
    "    unexpected behavior use a fixed-width exact type.\n",
    "\n",
    "Using a non-unix epoch origin\n",
    "\n",
    ">>> pd.to_datetime([1, 2, 3], unit='D',\n",
    "...                origin=pd.Timestamp('1960-01-01'))\n",
    "DatetimeIndex(['1960-01-02', '1960-01-03', '1960-01-04'],\n",
    "              dtype='datetime64[ns]', freq=None)\n",
    "\n",
    "**Non-convertible date/times**\n",
    "\n",
    "If a date does not meet the `timestamp limitations\n",
    "<https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html\n",
    "timeseries-timestamp-limits>`_, passing ``errors='ignore'``\n",
    "will return the original input instead of raising any exception.\n",
    "\n",
    "Passing ``errors='coerce'`` will force an out-of-bounds date to :const:`NaT`,\n",
    "in addition to forcing non-dates (or non-parseable dates) to :const:`NaT`.\n",
    "\n",
    ">>> pd.to_datetime('13000101', format='%Y%m%d', errors='ignore')\n",
    "datetime.datetime(1300, 1, 1, 0, 0)\n",
    ">>> pd.to_datetime('13000101', format='%Y%m%d', errors='coerce')\n",
    "NaT\n",
    "\n",
    ".. _to_datetime_tz_examples:\n",
    "\n",
    "**Timezones and time offsets**\n",
    "\n",
    "The default behaviour (``utc=False``) is as follows:\n",
    "\n",
    "- Timezone-naive inputs are converted to timezone-naive :class:`DatetimeIndex`:\n",
    "\n",
    ">>> pd.to_datetime(['2018-10-26 12:00', '2018-10-26 13:00:15'])\n",
    "DatetimeIndex(['2018-10-26 12:00:00', '2018-10-26 13:00:15'],\n",
    "              dtype='datetime64[ns]', freq=None)\n",
    "\n",
    "- Timezone-aware inputs *with constant time offset* are converted to\n",
    "  timezone-aware :class:`DatetimeIndex`:\n",
    "\n",
    ">>> pd.to_datetime(['2018-10-26 12:00 -0500', '2018-10-26 13:00 -0500'])\n",
    "DatetimeIndex(['2018-10-26 12:00:00-05:00', '2018-10-26 13:00:00-05:00'],\n",
    "              dtype='datetime64[ns, pytz.FixedOffset(-300)]', freq=None)\n",
    "\n",
    "- However, timezone-aware inputs *with mixed time offsets* (for example\n",
    "  issued from a timezone with daylight savings, such as Europe/Paris)\n",
    "  are **not successfully converted** to a :class:`DatetimeIndex`. Instead a\n",
    "  simple :class:`Index` containing :class:`datetime.datetime` objects is\n",
    "  returned:\n",
    "\n",
    ">>> pd.to_datetime(['2020-10-25 02:00 +0200', '2020-10-25 04:00 +0100'])\n",
    "Index([2020-10-25 02:00:00+02:00, 2020-10-25 04:00:00+01:00],\n",
    "      dtype='object')\n",
    "\n",
    "- A mix of timezone-aware and timezone-naive inputs is converted to\n",
    "  a timezone-aware :class:`DatetimeIndex` if the offsets of the timezone-aware\n",
    "  are constant:\n",
    "\n",
    ">>> from datetime import datetime\n",
    ">>> pd.to_datetime([\"2020-01-01 01:00 -01:00\", datetime(2020, 1, 1, 3, 0)])\n",
    "DatetimeIndex(['2020-01-01 01:00:00-01:00', '2020-01-01 02:00:00-01:00'],\n",
    "              dtype='datetime64[ns, pytz.FixedOffset(-60)]', freq=None)\n",
    "\n",
    "- Finally, mixing timezone-aware strings and :class:`datetime.datetime` always\n",
    "  raises an error, even if the elements all have the same time offset.\n",
    "\n",
    ">>> from datetime import datetime, timezone, timedelta\n",
    ">>> d = datetime(2020, 1, 1, 18, tzinfo=timezone(-timedelta(hours=1)))\n",
    ">>> pd.to_datetime([\"2020-01-01 17:00 -0100\", d])\n",
    "Traceback (most recent call last):\n",
    "    ...\n",
    "ValueError: Tz-aware datetime.datetime cannot be converted to datetime64\n",
    "            unless utc=True\n",
    "\n",
    "|\n",
    "\n",
    "Setting ``utc=True`` solves most of the above issues:\n",
    "\n",
    "- Timezone-naive inputs are *localized* as UTC\n",
    "\n",
    ">>> pd.to_datetime(['2018-10-26 12:00', '2018-10-26 13:00'], utc=True)\n",
    "DatetimeIndex(['2018-10-26 12:00:00+00:00', '2018-10-26 13:00:00+00:00'],\n",
    "              dtype='datetime64[ns, UTC]', freq=None)\n",
    "\n",
    "- Timezone-aware inputs are *converted* to UTC (the output represents the\n",
    "  exact same datetime, but viewed from the UTC time offset `+00:00`).\n",
    "\n",
    ">>> pd.to_datetime(['2018-10-26 12:00 -0530', '2018-10-26 12:00 -0500'],\n",
    "...                utc=True)\n",
    "DatetimeIndex(['2018-10-26 17:30:00+00:00', '2018-10-26 17:00:00+00:00'],\n",
    "              dtype='datetime64[ns, UTC]', freq=None)\n",
    "\n",
    "- Inputs can contain both naive and aware, string or datetime, the above\n",
    "  rules still apply\n",
    "\n",
    ">>> pd.to_datetime(['2018-10-26 12:00', '2018-10-26 12:00 -0530',\n",
    "...                datetime(2020, 1, 1, 18),\n",
    "...                datetime(2020, 1, 1, 18,\n",
    "...                tzinfo=timezone(-timedelta(hours=1)))],\n",
    "...                utc=True)\n",
    "DatetimeIndex(['2018-10-26 12:00:00+00:00', '2018-10-26 17:30:00+00:00',\n",
    "               '2020-01-01 18:00:00+00:00', '2020-01-01 19:00:00+00:00'],\n",
    "              dtype='datetime64[ns, UTC]', freq=None)\n",
    "\n",
    "</code>\n",
    "<a href='#top_phases'>back to header</a>\n",
    "</blockquote>\n",
    "</details>\n",
    "</li>\n",
    "<li>\n",
    "<details><summary style='list-style: none; cursor: pointer;'><u>pandas.core.series.Series.apply</u> | (No Args Found) </summary>\n",
    "<blockquote>\n",
    "<code>\n",
    "Invoke function on values of Series.\n",
    "\n",
    "Can be ufunc (a NumPy function that applies to the entire Series)\n",
    "or a Python function that only works on single values.\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "func : function\n",
    "    Python function or NumPy ufunc to apply.\n",
    "convert_dtype : bool, default True\n",
    "    Try to find better dtype for elementwise function results. If\n",
    "    False, leave as dtype=object. Note that the dtype is always\n",
    "    preserved for some extension array dtypes, such as Categorical.\n",
    "args : tuple\n",
    "    Positional arguments passed to func after the series value.\n",
    "**kwargs\n",
    "    Additional keyword arguments passed to func.\n",
    "\n",
    "Returns\n",
    "-------\n",
    "Series or DataFrame\n",
    "    If func returns a Series object the result will be a DataFrame.\n",
    "\n",
    "See Also\n",
    "--------\n",
    "Series.map: For element-wise operations.\n",
    "Series.agg: Only perform aggregating type operations.\n",
    "Series.transform: Only perform transforming type operations.\n",
    "\n",
    "Notes\n",
    "-----\n",
    "Functions that mutate the passed object can produce unexpected\n",
    "behavior or errors and are not supported. See :ref:`gotchas.udf-mutation`\n",
    "for more details.\n",
    "\n",
    "Examples\n",
    "--------\n",
    "Create a series with typical summer temperatures for each city.\n",
    "\n",
    ">>> s = pd.Series([20, 21, 12],\n",
    "...               index=['London', 'New York', 'Helsinki'])\n",
    ">>> s\n",
    "London      20\n",
    "New York    21\n",
    "Helsinki    12\n",
    "dtype: int64\n",
    "\n",
    "Square the values by defining a function and passing it as an\n",
    "argument to ``apply()``.\n",
    "\n",
    ">>> def square(x):\n",
    "...     return x ** 2\n",
    ">>> s.apply(square)\n",
    "London      400\n",
    "New York    441\n",
    "Helsinki    144\n",
    "dtype: int64\n",
    "\n",
    "Square the values by passing an anonymous function as an\n",
    "argument to ``apply()``.\n",
    "\n",
    ">>> s.apply(lambda x: x ** 2)\n",
    "London      400\n",
    "New York    441\n",
    "Helsinki    144\n",
    "dtype: int64\n",
    "\n",
    "Define a custom function that needs additional positional\n",
    "arguments and pass these additional arguments using the\n",
    "``args`` keyword.\n",
    "\n",
    ">>> def subtract_custom_value(x, custom_value):\n",
    "...     return x - custom_value\n",
    "\n",
    ">>> s.apply(subtract_custom_value, args=(5,))\n",
    "London      15\n",
    "New York    16\n",
    "Helsinki     7\n",
    "dtype: int64\n",
    "\n",
    "Define a custom function that takes keyword arguments\n",
    "and pass these arguments to ``apply``.\n",
    "\n",
    ">>> def add_custom_values(x, **kwargs):\n",
    "...     for month in kwargs:\n",
    "...         x += kwargs[month]\n",
    "...     return x\n",
    "\n",
    ">>> s.apply(add_custom_values, june=30, july=20, august=25)\n",
    "London      95\n",
    "New York    96\n",
    "Helsinki    87\n",
    "dtype: int64\n",
    "\n",
    "Use a function from the Numpy library.\n",
    "\n",
    ">>> s.apply(np.log)\n",
    "London      2.995732\n",
    "New York    3.044522\n",
    "Helsinki    2.484907\n",
    "dtype: float64\n",
    "\n",
    "</code>\n",
    "<a href='#top_phases'>back to header</a>\n",
    "</blockquote>\n",
    "</details>\n",
    "</li>\n",
    "<li>\n",
    "<details><summary style='list-style: none; cursor: pointer;'><u>pandas.core.frame.DataFrame.apply</u> | (No Args Found) </summary>\n",
    "<blockquote>\n",
    "<code>\n",
    "Apply a function along an axis of the DataFrame.\n",
    "\n",
    "Objects passed to the function are Series objects whose index is\n",
    "either the DataFrame's index (``axis=0``) or the DataFrame's columns\n",
    "(``axis=1``). By default (``result_type=None``), the final return type\n",
    "is inferred from the return type of the applied function. Otherwise,\n",
    "it depends on the `result_type` argument.\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "func : function\n",
    "    Function to apply to each column or row.\n",
    "axis : {0 or 'index', 1 or 'columns'}, default 0\n",
    "    Axis along which the function is applied:\n",
    "\n",
    "    * 0 or 'index': apply function to each column.\n",
    "    * 1 or 'columns': apply function to each row.\n",
    "\n",
    "raw : bool, default False\n",
    "    Determines if row or column is passed as a Series or ndarray object:\n",
    "\n",
    "    * ``False`` : passes each row or column as a Series to the\n",
    "      function.\n",
    "    * ``True`` : the passed function will receive ndarray objects\n",
    "      instead.\n",
    "      If you are just applying a NumPy reduction function this will\n",
    "      achieve much better performance.\n",
    "\n",
    "result_type : {'expand', 'reduce', 'broadcast', None}, default None\n",
    "    These only act when ``axis=1`` (columns):\n",
    "\n",
    "    * 'expand' : list-like results will be turned into columns.\n",
    "    * 'reduce' : returns a Series if possible rather than expanding\n",
    "      list-like results. This is the opposite of 'expand'.\n",
    "    * 'broadcast' : results will be broadcast to the original shape\n",
    "      of the DataFrame, the original index and columns will be\n",
    "      retained.\n",
    "\n",
    "    The default behaviour (None) depends on the return value of the\n",
    "    applied function: list-like results will be returned as a Series\n",
    "    of those. However if the apply function returns a Series these\n",
    "    are expanded to columns.\n",
    "args : tuple\n",
    "    Positional arguments to pass to `func` in addition to the\n",
    "    array/series.\n",
    "**kwargs\n",
    "    Additional keyword arguments to pass as keywords arguments to\n",
    "    `func`.\n",
    "\n",
    "Returns\n",
    "-------\n",
    "Series or DataFrame\n",
    "    Result of applying ``func`` along the given axis of the\n",
    "    DataFrame.\n",
    "\n",
    "See Also\n",
    "--------\n",
    "DataFrame.applymap: For elementwise operations.\n",
    "DataFrame.aggregate: Only perform aggregating type operations.\n",
    "DataFrame.transform: Only perform transforming type operations.\n",
    "\n",
    "Notes\n",
    "-----\n",
    "Functions that mutate the passed object can produce unexpected\n",
    "behavior or errors and are not supported. See :ref:`gotchas.udf-mutation`\n",
    "for more details.\n",
    "\n",
    "Examples\n",
    "--------\n",
    ">>> df = pd.DataFrame([[4, 9]] * 3, columns=['A', 'B'])\n",
    ">>> df\n",
    "   A  B\n",
    "0  4  9\n",
    "1  4  9\n",
    "2  4  9\n",
    "\n",
    "Using a numpy universal function (in this case the same as\n",
    "``np.sqrt(df)``):\n",
    "\n",
    ">>> df.apply(np.sqrt)\n",
    "     A    B\n",
    "0  2.0  3.0\n",
    "1  2.0  3.0\n",
    "2  2.0  3.0\n",
    "\n",
    "Using a reducing function on either axis\n",
    "\n",
    ">>> df.apply(np.sum, axis=0)\n",
    "A    12\n",
    "B    27\n",
    "dtype: int64\n",
    "\n",
    ">>> df.apply(np.sum, axis=1)\n",
    "0    13\n",
    "1    13\n",
    "2    13\n",
    "dtype: int64\n",
    "\n",
    "Returning a list-like will result in a Series\n",
    "\n",
    ">>> df.apply(lambda x: [1, 2], axis=1)\n",
    "0    [1, 2]\n",
    "1    [1, 2]\n",
    "2    [1, 2]\n",
    "dtype: object\n",
    "\n",
    "Passing ``result_type='expand'`` will expand list-like results\n",
    "to columns of a Dataframe\n",
    "\n",
    ">>> df.apply(lambda x: [1, 2], axis=1, result_type='expand')\n",
    "   0  1\n",
    "0  1  2\n",
    "1  1  2\n",
    "2  1  2\n",
    "\n",
    "Returning a Series inside the function is similar to passing\n",
    "``result_type='expand'``. The resulting column names\n",
    "will be the Series index.\n",
    "\n",
    ">>> df.apply(lambda x: pd.Series([1, 2], index=['foo', 'bar']), axis=1)\n",
    "   foo  bar\n",
    "0    1    2\n",
    "1    1    2\n",
    "2    1    2\n",
    "\n",
    "Passing ``result_type='broadcast'`` will ensure the same shape\n",
    "result, whether list-like or scalar is returned by the function,\n",
    "and broadcast it along the axis. The resulting column names will\n",
    "be the originals.\n",
    "\n",
    ">>> df.apply(lambda x: [1, 2], axis=1, result_type='broadcast')\n",
    "   A  B\n",
    "0  1  2\n",
    "1  1  2\n",
    "2  1  2\n",
    "\n",
    "</code>\n",
    "<a href='#top_phases'>back to header</a>\n",
    "</blockquote>\n",
    "</details>\n",
    "</li>\n",
    "</ul>\n",
    "</li>\n",
    "\n",
    "</ul>\n",
    "</details></li>\n",
    "<li><details open><summary style='list-style: none; cursor: pointer;'><strong><u>Cell # 2</u></strong></summary><small><a href=#2>goto cell # 2</a></small>\n",
    "<ul>\n",
    "\n",
    "<li> <b>pandas</b>\n",
    "<ul>\n",
    "<li>\n",
    "<details><summary style='list-style: none; cursor: pointer;'><u>pandas.core.generic.NDFrame._add_numeric_operations.<locals>.sum</u> | (No Args Found) </summary>\n",
    "<blockquote>\n",
    "<code>\n",
    "Return the sum of the values over the requested axis.\n",
    "\n",
    "This is equivalent to the method ``numpy.sum``.\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "axis : {index (0), columns (1)}\n",
    "    Axis for the function to be applied on.\n",
    "skipna : bool, default True\n",
    "    Exclude NA/null values when computing the result.\n",
    "level : int or level name, default None\n",
    "    If the axis is a MultiIndex (hierarchical), count along a\n",
    "    particular level, collapsing into a Series.\n",
    "numeric_only : bool, default None\n",
    "    Include only float, int, boolean columns. If None, will attempt to use\n",
    "    everything, then use only numeric data. Not implemented for Series.\n",
    "min_count : int, default 0\n",
    "    The required number of valid values to perform the operation. If fewer than\n",
    "    ``min_count`` non-NA values are present the result will be NA.\n",
    "**kwargs\n",
    "    Additional keyword arguments to be passed to the function.\n",
    "\n",
    "Returns\n",
    "-------\n",
    "Series or DataFrame (if level specified)\n",
    "\n",
    "See Also\n",
    "--------\n",
    "Series.sum : Return the sum.\n",
    "Series.min : Return the minimum.\n",
    "Series.max : Return the maximum.\n",
    "Series.idxmin : Return the index of the minimum.\n",
    "Series.idxmax : Return the index of the maximum.\n",
    "DataFrame.sum : Return the sum over the requested axis.\n",
    "DataFrame.min : Return the minimum over the requested axis.\n",
    "DataFrame.max : Return the maximum over the requested axis.\n",
    "DataFrame.idxmin : Return the index of the minimum over the requested axis.\n",
    "DataFrame.idxmax : Return the index of the maximum over the requested axis.\n",
    "\n",
    "Examples\n",
    "--------\n",
    ">>> idx = pd.MultiIndex.from_arrays([\n",
    "...     ['warm', 'warm', 'cold', 'cold'],\n",
    "...     ['dog', 'falcon', 'fish', 'spider']],\n",
    "...     names=['blooded', 'animal'])\n",
    ">>> s = pd.Series([4, 2, 0, 8], name='legs', index=idx)\n",
    ">>> s\n",
    "blooded  animal\n",
    "warm     dog       4\n",
    "         falcon    2\n",
    "cold     fish      0\n",
    "         spider    8\n",
    "Name: legs, dtype: int64\n",
    "\n",
    ">>> s.sum()\n",
    "14\n",
    "\n",
    "By default, the sum of an empty or all-NA Series is ``0``.\n",
    "\n",
    ">>> pd.Series([], dtype=\"float64\").sum()  # min_count=0 is the default\n",
    "0.0\n",
    "\n",
    "This can be controlled with the ``min_count`` parameter. For example, if\n",
    "you'd like the sum of an empty series to be NaN, pass ``min_count=1``.\n",
    "\n",
    ">>> pd.Series([], dtype=\"float64\").sum(min_count=1)\n",
    "nan\n",
    "\n",
    "Thanks to the ``skipna`` parameter, ``min_count`` handles all-NA and\n",
    "empty series identically.\n",
    "\n",
    ">>> pd.Series([np.nan]).sum()\n",
    "0.0\n",
    "\n",
    ">>> pd.Series([np.nan]).sum(min_count=1)\n",
    "nan\n",
    "\n",
    "</code>\n",
    "<a href='#top_phases'>back to header</a>\n",
    "</blockquote>\n",
    "</details>\n",
    "</li>\n",
    "</ul>\n",
    "</li>\n",
    "\n",
    "</ul>\n",
    "</details></li>\n",
    "<li><details open><summary style='list-style: none; cursor: pointer;'><strong><u>Cell # 3</u></strong></summary><small><a href=#3>goto cell # 3</a></small>\n",
    "<ul>\n",
    "\n",
    "<li> <b>pandas</b>\n",
    "<ul>\n",
    "<li>\n",
    "<details><summary style='list-style: none; cursor: pointer;'><u>pandas.core.generic.NDFrame._add_numeric_operations.<locals>.sum</u> | (No Args Found) </summary>\n",
    "<blockquote>\n",
    "<code>\n",
    "Return the sum of the values over the requested axis.\n",
    "\n",
    "This is equivalent to the method ``numpy.sum``.\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "axis : {index (0), columns (1)}\n",
    "    Axis for the function to be applied on.\n",
    "skipna : bool, default True\n",
    "    Exclude NA/null values when computing the result.\n",
    "level : int or level name, default None\n",
    "    If the axis is a MultiIndex (hierarchical), count along a\n",
    "    particular level, collapsing into a Series.\n",
    "numeric_only : bool, default None\n",
    "    Include only float, int, boolean columns. If None, will attempt to use\n",
    "    everything, then use only numeric data. Not implemented for Series.\n",
    "min_count : int, default 0\n",
    "    The required number of valid values to perform the operation. If fewer than\n",
    "    ``min_count`` non-NA values are present the result will be NA.\n",
    "**kwargs\n",
    "    Additional keyword arguments to be passed to the function.\n",
    "\n",
    "Returns\n",
    "-------\n",
    "Series or DataFrame (if level specified)\n",
    "\n",
    "See Also\n",
    "--------\n",
    "Series.sum : Return the sum.\n",
    "Series.min : Return the minimum.\n",
    "Series.max : Return the maximum.\n",
    "Series.idxmin : Return the index of the minimum.\n",
    "Series.idxmax : Return the index of the maximum.\n",
    "DataFrame.sum : Return the sum over the requested axis.\n",
    "DataFrame.min : Return the minimum over the requested axis.\n",
    "DataFrame.max : Return the maximum over the requested axis.\n",
    "DataFrame.idxmin : Return the index of the minimum over the requested axis.\n",
    "DataFrame.idxmax : Return the index of the maximum over the requested axis.\n",
    "\n",
    "Examples\n",
    "--------\n",
    ">>> idx = pd.MultiIndex.from_arrays([\n",
    "...     ['warm', 'warm', 'cold', 'cold'],\n",
    "...     ['dog', 'falcon', 'fish', 'spider']],\n",
    "...     names=['blooded', 'animal'])\n",
    ">>> s = pd.Series([4, 2, 0, 8], name='legs', index=idx)\n",
    ">>> s\n",
    "blooded  animal\n",
    "warm     dog       4\n",
    "         falcon    2\n",
    "cold     fish      0\n",
    "         spider    8\n",
    "Name: legs, dtype: int64\n",
    "\n",
    ">>> s.sum()\n",
    "14\n",
    "\n",
    "By default, the sum of an empty or all-NA Series is ``0``.\n",
    "\n",
    ">>> pd.Series([], dtype=\"float64\").sum()  # min_count=0 is the default\n",
    "0.0\n",
    "\n",
    "This can be controlled with the ``min_count`` parameter. For example, if\n",
    "you'd like the sum of an empty series to be NaN, pass ``min_count=1``.\n",
    "\n",
    ">>> pd.Series([], dtype=\"float64\").sum(min_count=1)\n",
    "nan\n",
    "\n",
    "Thanks to the ``skipna`` parameter, ``min_count`` handles all-NA and\n",
    "empty series identically.\n",
    "\n",
    ">>> pd.Series([np.nan]).sum()\n",
    "0.0\n",
    "\n",
    ">>> pd.Series([np.nan]).sum(min_count=1)\n",
    "nan\n",
    "\n",
    "</code>\n",
    "<a href='#top_phases'>back to header</a>\n",
    "</blockquote>\n",
    "</details>\n",
    "</li>\n",
    "</ul>\n",
    "</li>\n",
    "\n",
    "</ul>\n",
    "</details></li>\n",
    "<li><details open><summary style='list-style: none; cursor: pointer;'><strong><u>Cell # 15</u></strong></summary><small><a href=#15>goto cell # 15</a></small>\n",
    "<ul>\n",
    "\n",
    "<li> <b>pandas</b>\n",
    "<ul>\n",
    "<li>\n",
    "<details><summary style='list-style: none; cursor: pointer;'><u>pandas.core.tools.datetimes.to_datetime</u> | (No Args Found) </summary>\n",
    "<blockquote>\n",
    "<code>\n",
    "Convert argument to datetime.\n",
    "\n",
    "This function converts a scalar, array-like, :class:`Series` or\n",
    ":class:`DataFrame`/dict-like to a pandas datetime object.\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "arg : int, float, str, datetime, list, tuple, 1-d array, Series, DataFrame/dict-like\n",
    "    The object to convert to a datetime. If a :class:`DataFrame` is provided, the\n",
    "    method expects minimally the following columns: :const:`\"year\"`,\n",
    "    :const:`\"month\"`, :const:`\"day\"`.\n",
    "errors : {'ignore', 'raise', 'coerce'}, default 'raise'\n",
    "    - If :const:`'raise'`, then invalid parsing will raise an exception.\n",
    "    - If :const:`'coerce'`, then invalid parsing will be set as :const:`NaT`.\n",
    "    - If :const:`'ignore'`, then invalid parsing will return the input.\n",
    "dayfirst : bool, default False\n",
    "    Specify a date parse order if `arg` is str or is list-like.\n",
    "    If :const:`True`, parses dates with the day first, e.g. :const:`\"10/11/12\"`\n",
    "    is parsed as :const:`2012-11-10`.\n",
    "\n",
    "    .. warning::\n",
    "\n",
    "        ``dayfirst=True`` is not strict, but will prefer to parse\n",
    "        with day first. If a delimited date string cannot be parsed in\n",
    "        accordance with the given `dayfirst` option, e.g.\n",
    "        ``to_datetime(['31-12-2021'])``, then a warning will be shown.\n",
    "\n",
    "yearfirst : bool, default False\n",
    "    Specify a date parse order if `arg` is str or is list-like.\n",
    "\n",
    "    - If :const:`True` parses dates with the year first, e.g.\n",
    "      :const:`\"10/11/12\"` is parsed as :const:`2010-11-12`.\n",
    "    - If both `dayfirst` and `yearfirst` are :const:`True`, `yearfirst` is\n",
    "      preceded (same as :mod:`dateutil`).\n",
    "\n",
    "    .. warning::\n",
    "\n",
    "        ``yearfirst=True`` is not strict, but will prefer to parse\n",
    "        with year first.\n",
    "\n",
    "utc : bool, default None\n",
    "    Control timezone-related parsing, localization and conversion.\n",
    "\n",
    "    - If :const:`True`, the function *always* returns a timezone-aware\n",
    "      UTC-localized :class:`Timestamp`, :class:`Series` or\n",
    "      :class:`DatetimeIndex`. To do this, timezone-naive inputs are\n",
    "      *localized* as UTC, while timezone-aware inputs are *converted* to UTC.\n",
    "\n",
    "    - If :const:`False` (default), inputs will not be coerced to UTC.\n",
    "      Timezone-naive inputs will remain naive, while timezone-aware ones\n",
    "      will keep their time offsets. Limitations exist for mixed\n",
    "      offsets (typically, daylight savings), see :ref:`Examples\n",
    "      <to_datetime_tz_examples>` section for details.\n",
    "\n",
    "    See also: pandas general documentation about `timezone conversion and\n",
    "    localization\n",
    "    <https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html\n",
    "    #time-zone-handling>`_.\n",
    "\n",
    "format : str, default None\n",
    "    The strftime to parse time, e.g. :const:`\"%d/%m/%Y\"`. Note that\n",
    "    :const:`\"%f\"` will parse all the way up to nanoseconds. See\n",
    "    `strftime documentation\n",
    "    <https://docs.python.org/3/library/datetime.html\n",
    "    #strftime-and-strptime-behavior>`_ for more information on choices.\n",
    "exact : bool, default True\n",
    "    Control how `format` is used:\n",
    "\n",
    "    - If :const:`True`, require an exact `format` match.\n",
    "    - If :const:`False`, allow the `format` to match anywhere in the target\n",
    "      string.\n",
    "\n",
    "unit : str, default 'ns'\n",
    "    The unit of the arg (D,s,ms,us,ns) denote the unit, which is an\n",
    "    integer or float number. This will be based off the origin.\n",
    "    Example, with ``unit='ms'`` and ``origin='unix'`` (the default), this\n",
    "    would calculate the number of milliseconds to the unix epoch start.\n",
    "infer_datetime_format : bool, default False\n",
    "    If :const:`True` and no `format` is given, attempt to infer the format\n",
    "    of the datetime strings based on the first non-NaN element,\n",
    "    and if it can be inferred, switch to a faster method of parsing them.\n",
    "    In some cases this can increase the parsing speed by ~5-10x.\n",
    "origin : scalar, default 'unix'\n",
    "    Define the reference date. The numeric values would be parsed as number\n",
    "    of units (defined by `unit`) since this reference date.\n",
    "\n",
    "    - If :const:`'unix'` (or POSIX) time; origin is set to 1970-01-01.\n",
    "    - If :const:`'julian'`, unit must be :const:`'D'`, and origin is set to\n",
    "      beginning of Julian Calendar. Julian day number :const:`0` is assigned\n",
    "      to the day starting at noon on January 1, 4713 BC.\n",
    "    - If Timestamp convertible, origin is set to Timestamp identified by\n",
    "      origin.\n",
    "cache : bool, default True\n",
    "    If :const:`True`, use a cache of unique, converted dates to apply the\n",
    "    datetime conversion. May produce significant speed-up when parsing\n",
    "    duplicate date strings, especially ones with timezone offsets. The cache\n",
    "    is only used when there are at least 50 values. The presence of\n",
    "    out-of-bounds values will render the cache unusable and may slow down\n",
    "    parsing.\n",
    "\n",
    "    .. versionchanged:: 0.25.0\n",
    "        changed default value from :const:`False` to :const:`True`.\n",
    "\n",
    "Returns\n",
    "-------\n",
    "datetime\n",
    "    If parsing succeeded.\n",
    "    Return type depends on input (types in parenthesis correspond to\n",
    "    fallback in case of unsuccessful timezone or out-of-range timestamp\n",
    "    parsing):\n",
    "\n",
    "    - scalar: :class:`Timestamp` (or :class:`datetime.datetime`)\n",
    "    - array-like: :class:`DatetimeIndex` (or :class:`Series` with\n",
    "      :class:`object` dtype containing :class:`datetime.datetime`)\n",
    "    - Series: :class:`Series` of :class:`datetime64` dtype (or\n",
    "      :class:`Series` of :class:`object` dtype containing\n",
    "      :class:`datetime.datetime`)\n",
    "    - DataFrame: :class:`Series` of :class:`datetime64` dtype (or\n",
    "      :class:`Series` of :class:`object` dtype containing\n",
    "      :class:`datetime.datetime`)\n",
    "\n",
    "Raises\n",
    "------\n",
    "ParserError\n",
    "    When parsing a date from string fails.\n",
    "ValueError\n",
    "    When another datetime conversion error happens. For example when one\n",
    "    of 'year', 'month', day' columns is missing in a :class:`DataFrame`, or\n",
    "    when a Timezone-aware :class:`datetime.datetime` is found in an array-like\n",
    "    of mixed time offsets, and ``utc=False``.\n",
    "\n",
    "See Also\n",
    "--------\n",
    "DataFrame.astype : Cast argument to a specified dtype.\n",
    "to_timedelta : Convert argument to timedelta.\n",
    "convert_dtypes : Convert dtypes.\n",
    "\n",
    "Notes\n",
    "-----\n",
    "\n",
    "Many input types are supported, and lead to different output types:\n",
    "\n",
    "- **scalars** can be int, float, str, datetime object (from stdlib :mod:`datetime`\n",
    "  module or :mod:`numpy`). They are converted to :class:`Timestamp` when\n",
    "  possible, otherwise they are converted to :class:`datetime.datetime`.\n",
    "  None/NaN/null scalars are converted to :const:`NaT`.\n",
    "\n",
    "- **array-like** can contain int, float, str, datetime objects. They are\n",
    "  converted to :class:`DatetimeIndex` when possible, otherwise they are\n",
    "  converted to :class:`Index` with :class:`object` dtype, containing\n",
    "  :class:`datetime.datetime`. None/NaN/null entries are converted to\n",
    "  :const:`NaT` in both cases.\n",
    "\n",
    "- **Series** are converted to :class:`Series` with :class:`datetime64`\n",
    "  dtype when possible, otherwise they are converted to :class:`Series` with\n",
    "  :class:`object` dtype, containing :class:`datetime.datetime`. None/NaN/null\n",
    "  entries are converted to :const:`NaT` in both cases.\n",
    "\n",
    "- **DataFrame/dict-like** are converted to :class:`Series` with\n",
    "  :class:`datetime64` dtype. For each row a datetime is created from assembling\n",
    "  the various dataframe columns. Column keys can be common abbreviations\n",
    "  like [‘year’, ‘month’, ‘day’, ‘minute’, ‘second’, ‘ms’, ‘us’, ‘ns’]) or\n",
    "  plurals of the same.\n",
    "\n",
    "The following causes are responsible for :class:`datetime.datetime` objects\n",
    "being returned (possibly inside an :class:`Index` or a :class:`Series` with\n",
    ":class:`object` dtype) instead of a proper pandas designated type\n",
    "(:class:`Timestamp`, :class:`DatetimeIndex` or :class:`Series`\n",
    "with :class:`datetime64` dtype):\n",
    "\n",
    "- when any input element is before :const:`Timestamp.min` or after\n",
    "  :const:`Timestamp.max`, see `timestamp limitations\n",
    "  <https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html\n",
    "  #timeseries-timestamp-limits>`_.\n",
    "\n",
    "- when ``utc=False`` (default) and the input is an array-like or\n",
    "  :class:`Series` containing mixed naive/aware datetime, or aware with mixed\n",
    "  time offsets. Note that this happens in the (quite frequent) situation when\n",
    "  the timezone has a daylight savings policy. In that case you may wish to\n",
    "  use ``utc=True``.\n",
    "\n",
    "Examples\n",
    "--------\n",
    "\n",
    "**Handling various input formats**\n",
    "\n",
    "Assembling a datetime from multiple columns of a :class:`DataFrame`. The keys\n",
    "can be common abbreviations like ['year', 'month', 'day', 'minute', 'second',\n",
    "'ms', 'us', 'ns']) or plurals of the same\n",
    "\n",
    ">>> df = pd.DataFrame({'year': [2015, 2016],\n",
    "...                    'month': [2, 3],\n",
    "...                    'day': [4, 5]})\n",
    ">>> pd.to_datetime(df)\n",
    "0   2015-02-04\n",
    "1   2016-03-05\n",
    "dtype: datetime64[ns]\n",
    "\n",
    "Passing ``infer_datetime_format=True`` can often-times speedup a parsing\n",
    "if its not an ISO8601 format exactly, but in a regular format.\n",
    "\n",
    ">>> s = pd.Series(['3/11/2000', '3/12/2000', '3/13/2000'] * 1000)\n",
    ">>> s.head()\n",
    "0    3/11/2000\n",
    "1    3/12/2000\n",
    "2    3/13/2000\n",
    "3    3/11/2000\n",
    "4    3/12/2000\n",
    "dtype: object\n",
    "\n",
    ">>> %timeit pd.to_datetime(s, infer_datetime_format=True)  # doctest: +SKIP\n",
    "100 loops, best of 3: 10.4 ms per loop\n",
    "\n",
    ">>> %timeit pd.to_datetime(s, infer_datetime_format=False)  # doctest: +SKIP\n",
    "1 loop, best of 3: 471 ms per loop\n",
    "\n",
    "Using a unix epoch time\n",
    "\n",
    ">>> pd.to_datetime(1490195805, unit='s')\n",
    "Timestamp('2017-03-22 15:16:45')\n",
    ">>> pd.to_datetime(1490195805433502912, unit='ns')\n",
    "Timestamp('2017-03-22 15:16:45.433502912')\n",
    "\n",
    ".. warning:: For float arg, precision rounding might happen. To prevent\n",
    "    unexpected behavior use a fixed-width exact type.\n",
    "\n",
    "Using a non-unix epoch origin\n",
    "\n",
    ">>> pd.to_datetime([1, 2, 3], unit='D',\n",
    "...                origin=pd.Timestamp('1960-01-01'))\n",
    "DatetimeIndex(['1960-01-02', '1960-01-03', '1960-01-04'],\n",
    "              dtype='datetime64[ns]', freq=None)\n",
    "\n",
    "**Non-convertible date/times**\n",
    "\n",
    "If a date does not meet the `timestamp limitations\n",
    "<https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html\n",
    "timeseries-timestamp-limits>`_, passing ``errors='ignore'``\n",
    "will return the original input instead of raising any exception.\n",
    "\n",
    "Passing ``errors='coerce'`` will force an out-of-bounds date to :const:`NaT`,\n",
    "in addition to forcing non-dates (or non-parseable dates) to :const:`NaT`.\n",
    "\n",
    ">>> pd.to_datetime('13000101', format='%Y%m%d', errors='ignore')\n",
    "datetime.datetime(1300, 1, 1, 0, 0)\n",
    ">>> pd.to_datetime('13000101', format='%Y%m%d', errors='coerce')\n",
    "NaT\n",
    "\n",
    ".. _to_datetime_tz_examples:\n",
    "\n",
    "**Timezones and time offsets**\n",
    "\n",
    "The default behaviour (``utc=False``) is as follows:\n",
    "\n",
    "- Timezone-naive inputs are converted to timezone-naive :class:`DatetimeIndex`:\n",
    "\n",
    ">>> pd.to_datetime(['2018-10-26 12:00', '2018-10-26 13:00:15'])\n",
    "DatetimeIndex(['2018-10-26 12:00:00', '2018-10-26 13:00:15'],\n",
    "              dtype='datetime64[ns]', freq=None)\n",
    "\n",
    "- Timezone-aware inputs *with constant time offset* are converted to\n",
    "  timezone-aware :class:`DatetimeIndex`:\n",
    "\n",
    ">>> pd.to_datetime(['2018-10-26 12:00 -0500', '2018-10-26 13:00 -0500'])\n",
    "DatetimeIndex(['2018-10-26 12:00:00-05:00', '2018-10-26 13:00:00-05:00'],\n",
    "              dtype='datetime64[ns, pytz.FixedOffset(-300)]', freq=None)\n",
    "\n",
    "- However, timezone-aware inputs *with mixed time offsets* (for example\n",
    "  issued from a timezone with daylight savings, such as Europe/Paris)\n",
    "  are **not successfully converted** to a :class:`DatetimeIndex`. Instead a\n",
    "  simple :class:`Index` containing :class:`datetime.datetime` objects is\n",
    "  returned:\n",
    "\n",
    ">>> pd.to_datetime(['2020-10-25 02:00 +0200', '2020-10-25 04:00 +0100'])\n",
    "Index([2020-10-25 02:00:00+02:00, 2020-10-25 04:00:00+01:00],\n",
    "      dtype='object')\n",
    "\n",
    "- A mix of timezone-aware and timezone-naive inputs is converted to\n",
    "  a timezone-aware :class:`DatetimeIndex` if the offsets of the timezone-aware\n",
    "  are constant:\n",
    "\n",
    ">>> from datetime import datetime\n",
    ">>> pd.to_datetime([\"2020-01-01 01:00 -01:00\", datetime(2020, 1, 1, 3, 0)])\n",
    "DatetimeIndex(['2020-01-01 01:00:00-01:00', '2020-01-01 02:00:00-01:00'],\n",
    "              dtype='datetime64[ns, pytz.FixedOffset(-60)]', freq=None)\n",
    "\n",
    "- Finally, mixing timezone-aware strings and :class:`datetime.datetime` always\n",
    "  raises an error, even if the elements all have the same time offset.\n",
    "\n",
    ">>> from datetime import datetime, timezone, timedelta\n",
    ">>> d = datetime(2020, 1, 1, 18, tzinfo=timezone(-timedelta(hours=1)))\n",
    ">>> pd.to_datetime([\"2020-01-01 17:00 -0100\", d])\n",
    "Traceback (most recent call last):\n",
    "    ...\n",
    "ValueError: Tz-aware datetime.datetime cannot be converted to datetime64\n",
    "            unless utc=True\n",
    "\n",
    "|\n",
    "\n",
    "Setting ``utc=True`` solves most of the above issues:\n",
    "\n",
    "- Timezone-naive inputs are *localized* as UTC\n",
    "\n",
    ">>> pd.to_datetime(['2018-10-26 12:00', '2018-10-26 13:00'], utc=True)\n",
    "DatetimeIndex(['2018-10-26 12:00:00+00:00', '2018-10-26 13:00:00+00:00'],\n",
    "              dtype='datetime64[ns, UTC]', freq=None)\n",
    "\n",
    "- Timezone-aware inputs are *converted* to UTC (the output represents the\n",
    "  exact same datetime, but viewed from the UTC time offset `+00:00`).\n",
    "\n",
    ">>> pd.to_datetime(['2018-10-26 12:00 -0530', '2018-10-26 12:00 -0500'],\n",
    "...                utc=True)\n",
    "DatetimeIndex(['2018-10-26 17:30:00+00:00', '2018-10-26 17:00:00+00:00'],\n",
    "              dtype='datetime64[ns, UTC]', freq=None)\n",
    "\n",
    "- Inputs can contain both naive and aware, string or datetime, the above\n",
    "  rules still apply\n",
    "\n",
    ">>> pd.to_datetime(['2018-10-26 12:00', '2018-10-26 12:00 -0530',\n",
    "...                datetime(2020, 1, 1, 18),\n",
    "...                datetime(2020, 1, 1, 18,\n",
    "...                tzinfo=timezone(-timedelta(hours=1)))],\n",
    "...                utc=True)\n",
    "DatetimeIndex(['2018-10-26 12:00:00+00:00', '2018-10-26 17:30:00+00:00',\n",
    "               '2020-01-01 18:00:00+00:00', '2020-01-01 19:00:00+00:00'],\n",
    "              dtype='datetime64[ns, UTC]', freq=None)\n",
    "\n",
    "</code>\n",
    "<a href='#top_phases'>back to header</a>\n",
    "</blockquote>\n",
    "</details>\n",
    "</li>\n",
    "</ul>\n",
    "</li>\n",
    "\n",
    "</ul>\n",
    "</details></li>\n",
    "<li><details open><summary style='list-style: none; cursor: pointer;'><strong><u>Cell # 16</u></strong></summary><small><a href=#16>goto cell # 16</a></small>\n",
    "<ul>\n",
    "\n",
    "<li> <b>pandas</b>\n",
    "<ul>\n",
    "<li>\n",
    "<details><summary style='list-style: none; cursor: pointer;'><u>pandas.core.series.Series.apply</u> | (No Args Found) </summary>\n",
    "<blockquote>\n",
    "<code>\n",
    "Invoke function on values of Series.\n",
    "\n",
    "Can be ufunc (a NumPy function that applies to the entire Series)\n",
    "or a Python function that only works on single values.\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "func : function\n",
    "    Python function or NumPy ufunc to apply.\n",
    "convert_dtype : bool, default True\n",
    "    Try to find better dtype for elementwise function results. If\n",
    "    False, leave as dtype=object. Note that the dtype is always\n",
    "    preserved for some extension array dtypes, such as Categorical.\n",
    "args : tuple\n",
    "    Positional arguments passed to func after the series value.\n",
    "**kwargs\n",
    "    Additional keyword arguments passed to func.\n",
    "\n",
    "Returns\n",
    "-------\n",
    "Series or DataFrame\n",
    "    If func returns a Series object the result will be a DataFrame.\n",
    "\n",
    "See Also\n",
    "--------\n",
    "Series.map: For element-wise operations.\n",
    "Series.agg: Only perform aggregating type operations.\n",
    "Series.transform: Only perform transforming type operations.\n",
    "\n",
    "Notes\n",
    "-----\n",
    "Functions that mutate the passed object can produce unexpected\n",
    "behavior or errors and are not supported. See :ref:`gotchas.udf-mutation`\n",
    "for more details.\n",
    "\n",
    "Examples\n",
    "--------\n",
    "Create a series with typical summer temperatures for each city.\n",
    "\n",
    ">>> s = pd.Series([20, 21, 12],\n",
    "...               index=['London', 'New York', 'Helsinki'])\n",
    ">>> s\n",
    "London      20\n",
    "New York    21\n",
    "Helsinki    12\n",
    "dtype: int64\n",
    "\n",
    "Square the values by defining a function and passing it as an\n",
    "argument to ``apply()``.\n",
    "\n",
    ">>> def square(x):\n",
    "...     return x ** 2\n",
    ">>> s.apply(square)\n",
    "London      400\n",
    "New York    441\n",
    "Helsinki    144\n",
    "dtype: int64\n",
    "\n",
    "Square the values by passing an anonymous function as an\n",
    "argument to ``apply()``.\n",
    "\n",
    ">>> s.apply(lambda x: x ** 2)\n",
    "London      400\n",
    "New York    441\n",
    "Helsinki    144\n",
    "dtype: int64\n",
    "\n",
    "Define a custom function that needs additional positional\n",
    "arguments and pass these additional arguments using the\n",
    "``args`` keyword.\n",
    "\n",
    ">>> def subtract_custom_value(x, custom_value):\n",
    "...     return x - custom_value\n",
    "\n",
    ">>> s.apply(subtract_custom_value, args=(5,))\n",
    "London      15\n",
    "New York    16\n",
    "Helsinki     7\n",
    "dtype: int64\n",
    "\n",
    "Define a custom function that takes keyword arguments\n",
    "and pass these arguments to ``apply``.\n",
    "\n",
    ">>> def add_custom_values(x, **kwargs):\n",
    "...     for month in kwargs:\n",
    "...         x += kwargs[month]\n",
    "...     return x\n",
    "\n",
    ">>> s.apply(add_custom_values, june=30, july=20, august=25)\n",
    "London      95\n",
    "New York    96\n",
    "Helsinki    87\n",
    "dtype: int64\n",
    "\n",
    "Use a function from the Numpy library.\n",
    "\n",
    ">>> s.apply(np.log)\n",
    "London      2.995732\n",
    "New York    3.044522\n",
    "Helsinki    2.484907\n",
    "dtype: float64\n",
    "\n",
    "</code>\n",
    "<a href='#top_phases'>back to header</a>\n",
    "</blockquote>\n",
    "</details>\n",
    "</li>\n",
    "<li>\n",
    "<details><summary style='list-style: none; cursor: pointer;'><u>pandas.core.frame.DataFrame.apply</u> | (No Args Found) </summary>\n",
    "<blockquote>\n",
    "<code>\n",
    "Apply a function along an axis of the DataFrame.\n",
    "\n",
    "Objects passed to the function are Series objects whose index is\n",
    "either the DataFrame's index (``axis=0``) or the DataFrame's columns\n",
    "(``axis=1``). By default (``result_type=None``), the final return type\n",
    "is inferred from the return type of the applied function. Otherwise,\n",
    "it depends on the `result_type` argument.\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "func : function\n",
    "    Function to apply to each column or row.\n",
    "axis : {0 or 'index', 1 or 'columns'}, default 0\n",
    "    Axis along which the function is applied:\n",
    "\n",
    "    * 0 or 'index': apply function to each column.\n",
    "    * 1 or 'columns': apply function to each row.\n",
    "\n",
    "raw : bool, default False\n",
    "    Determines if row or column is passed as a Series or ndarray object:\n",
    "\n",
    "    * ``False`` : passes each row or column as a Series to the\n",
    "      function.\n",
    "    * ``True`` : the passed function will receive ndarray objects\n",
    "      instead.\n",
    "      If you are just applying a NumPy reduction function this will\n",
    "      achieve much better performance.\n",
    "\n",
    "result_type : {'expand', 'reduce', 'broadcast', None}, default None\n",
    "    These only act when ``axis=1`` (columns):\n",
    "\n",
    "    * 'expand' : list-like results will be turned into columns.\n",
    "    * 'reduce' : returns a Series if possible rather than expanding\n",
    "      list-like results. This is the opposite of 'expand'.\n",
    "    * 'broadcast' : results will be broadcast to the original shape\n",
    "      of the DataFrame, the original index and columns will be\n",
    "      retained.\n",
    "\n",
    "    The default behaviour (None) depends on the return value of the\n",
    "    applied function: list-like results will be returned as a Series\n",
    "    of those. However if the apply function returns a Series these\n",
    "    are expanded to columns.\n",
    "args : tuple\n",
    "    Positional arguments to pass to `func` in addition to the\n",
    "    array/series.\n",
    "**kwargs\n",
    "    Additional keyword arguments to pass as keywords arguments to\n",
    "    `func`.\n",
    "\n",
    "Returns\n",
    "-------\n",
    "Series or DataFrame\n",
    "    Result of applying ``func`` along the given axis of the\n",
    "    DataFrame.\n",
    "\n",
    "See Also\n",
    "--------\n",
    "DataFrame.applymap: For elementwise operations.\n",
    "DataFrame.aggregate: Only perform aggregating type operations.\n",
    "DataFrame.transform: Only perform transforming type operations.\n",
    "\n",
    "Notes\n",
    "-----\n",
    "Functions that mutate the passed object can produce unexpected\n",
    "behavior or errors and are not supported. See :ref:`gotchas.udf-mutation`\n",
    "for more details.\n",
    "\n",
    "Examples\n",
    "--------\n",
    ">>> df = pd.DataFrame([[4, 9]] * 3, columns=['A', 'B'])\n",
    ">>> df\n",
    "   A  B\n",
    "0  4  9\n",
    "1  4  9\n",
    "2  4  9\n",
    "\n",
    "Using a numpy universal function (in this case the same as\n",
    "``np.sqrt(df)``):\n",
    "\n",
    ">>> df.apply(np.sqrt)\n",
    "     A    B\n",
    "0  2.0  3.0\n",
    "1  2.0  3.0\n",
    "2  2.0  3.0\n",
    "\n",
    "Using a reducing function on either axis\n",
    "\n",
    ">>> df.apply(np.sum, axis=0)\n",
    "A    12\n",
    "B    27\n",
    "dtype: int64\n",
    "\n",
    ">>> df.apply(np.sum, axis=1)\n",
    "0    13\n",
    "1    13\n",
    "2    13\n",
    "dtype: int64\n",
    "\n",
    "Returning a list-like will result in a Series\n",
    "\n",
    ">>> df.apply(lambda x: [1, 2], axis=1)\n",
    "0    [1, 2]\n",
    "1    [1, 2]\n",
    "2    [1, 2]\n",
    "dtype: object\n",
    "\n",
    "Passing ``result_type='expand'`` will expand list-like results\n",
    "to columns of a Dataframe\n",
    "\n",
    ">>> df.apply(lambda x: [1, 2], axis=1, result_type='expand')\n",
    "   0  1\n",
    "0  1  2\n",
    "1  1  2\n",
    "2  1  2\n",
    "\n",
    "Returning a Series inside the function is similar to passing\n",
    "``result_type='expand'``. The resulting column names\n",
    "will be the Series index.\n",
    "\n",
    ">>> df.apply(lambda x: pd.Series([1, 2], index=['foo', 'bar']), axis=1)\n",
    "   foo  bar\n",
    "0    1    2\n",
    "1    1    2\n",
    "2    1    2\n",
    "\n",
    "Passing ``result_type='broadcast'`` will ensure the same shape\n",
    "result, whether list-like or scalar is returned by the function,\n",
    "and broadcast it along the axis. The resulting column names will\n",
    "be the originals.\n",
    "\n",
    ">>> df.apply(lambda x: [1, 2], axis=1, result_type='broadcast')\n",
    "   A  B\n",
    "0  1  2\n",
    "1  1  2\n",
    "2  1  2\n",
    "\n",
    "</code>\n",
    "<a href='#top_phases'>back to header</a>\n",
    "</blockquote>\n",
    "</details>\n",
    "</li>\n",
    "</ul>\n",
    "</li>\n",
    "\n",
    "</ul>\n",
    "</details></li>\n",
    "<li><details open><summary style='list-style: none; cursor: pointer;'><strong><u>Cell # 18</u></strong></summary><small><a href=#18>goto cell # 18</a></small>\n",
    "<ul>\n",
    "\n",
    "<li> <b>pandas</b>\n",
    "<ul>\n",
    "<li>\n",
    "<details><summary style='list-style: none; cursor: pointer;'><u>pandas.core.series.Series.apply</u> | (No Args Found) </summary>\n",
    "<blockquote>\n",
    "<code>\n",
    "Invoke function on values of Series.\n",
    "\n",
    "Can be ufunc (a NumPy function that applies to the entire Series)\n",
    "or a Python function that only works on single values.\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "func : function\n",
    "    Python function or NumPy ufunc to apply.\n",
    "convert_dtype : bool, default True\n",
    "    Try to find better dtype for elementwise function results. If\n",
    "    False, leave as dtype=object. Note that the dtype is always\n",
    "    preserved for some extension array dtypes, such as Categorical.\n",
    "args : tuple\n",
    "    Positional arguments passed to func after the series value.\n",
    "**kwargs\n",
    "    Additional keyword arguments passed to func.\n",
    "\n",
    "Returns\n",
    "-------\n",
    "Series or DataFrame\n",
    "    If func returns a Series object the result will be a DataFrame.\n",
    "\n",
    "See Also\n",
    "--------\n",
    "Series.map: For element-wise operations.\n",
    "Series.agg: Only perform aggregating type operations.\n",
    "Series.transform: Only perform transforming type operations.\n",
    "\n",
    "Notes\n",
    "-----\n",
    "Functions that mutate the passed object can produce unexpected\n",
    "behavior or errors and are not supported. See :ref:`gotchas.udf-mutation`\n",
    "for more details.\n",
    "\n",
    "Examples\n",
    "--------\n",
    "Create a series with typical summer temperatures for each city.\n",
    "\n",
    ">>> s = pd.Series([20, 21, 12],\n",
    "...               index=['London', 'New York', 'Helsinki'])\n",
    ">>> s\n",
    "London      20\n",
    "New York    21\n",
    "Helsinki    12\n",
    "dtype: int64\n",
    "\n",
    "Square the values by defining a function and passing it as an\n",
    "argument to ``apply()``.\n",
    "\n",
    ">>> def square(x):\n",
    "...     return x ** 2\n",
    ">>> s.apply(square)\n",
    "London      400\n",
    "New York    441\n",
    "Helsinki    144\n",
    "dtype: int64\n",
    "\n",
    "Square the values by passing an anonymous function as an\n",
    "argument to ``apply()``.\n",
    "\n",
    ">>> s.apply(lambda x: x ** 2)\n",
    "London      400\n",
    "New York    441\n",
    "Helsinki    144\n",
    "dtype: int64\n",
    "\n",
    "Define a custom function that needs additional positional\n",
    "arguments and pass these additional arguments using the\n",
    "``args`` keyword.\n",
    "\n",
    ">>> def subtract_custom_value(x, custom_value):\n",
    "...     return x - custom_value\n",
    "\n",
    ">>> s.apply(subtract_custom_value, args=(5,))\n",
    "London      15\n",
    "New York    16\n",
    "Helsinki     7\n",
    "dtype: int64\n",
    "\n",
    "Define a custom function that takes keyword arguments\n",
    "and pass these arguments to ``apply``.\n",
    "\n",
    ">>> def add_custom_values(x, **kwargs):\n",
    "...     for month in kwargs:\n",
    "...         x += kwargs[month]\n",
    "...     return x\n",
    "\n",
    ">>> s.apply(add_custom_values, june=30, july=20, august=25)\n",
    "London      95\n",
    "New York    96\n",
    "Helsinki    87\n",
    "dtype: int64\n",
    "\n",
    "Use a function from the Numpy library.\n",
    "\n",
    ">>> s.apply(np.log)\n",
    "London      2.995732\n",
    "New York    3.044522\n",
    "Helsinki    2.484907\n",
    "dtype: float64\n",
    "\n",
    "</code>\n",
    "<a href='#top_phases'>back to header</a>\n",
    "</blockquote>\n",
    "</details>\n",
    "</li>\n",
    "<li>\n",
    "<details><summary style='list-style: none; cursor: pointer;'><u>pandas.core.frame.DataFrame.apply</u> | (No Args Found) </summary>\n",
    "<blockquote>\n",
    "<code>\n",
    "Apply a function along an axis of the DataFrame.\n",
    "\n",
    "Objects passed to the function are Series objects whose index is\n",
    "either the DataFrame's index (``axis=0``) or the DataFrame's columns\n",
    "(``axis=1``). By default (``result_type=None``), the final return type\n",
    "is inferred from the return type of the applied function. Otherwise,\n",
    "it depends on the `result_type` argument.\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "func : function\n",
    "    Function to apply to each column or row.\n",
    "axis : {0 or 'index', 1 or 'columns'}, default 0\n",
    "    Axis along which the function is applied:\n",
    "\n",
    "    * 0 or 'index': apply function to each column.\n",
    "    * 1 or 'columns': apply function to each row.\n",
    "\n",
    "raw : bool, default False\n",
    "    Determines if row or column is passed as a Series or ndarray object:\n",
    "\n",
    "    * ``False`` : passes each row or column as a Series to the\n",
    "      function.\n",
    "    * ``True`` : the passed function will receive ndarray objects\n",
    "      instead.\n",
    "      If you are just applying a NumPy reduction function this will\n",
    "      achieve much better performance.\n",
    "\n",
    "result_type : {'expand', 'reduce', 'broadcast', None}, default None\n",
    "    These only act when ``axis=1`` (columns):\n",
    "\n",
    "    * 'expand' : list-like results will be turned into columns.\n",
    "    * 'reduce' : returns a Series if possible rather than expanding\n",
    "      list-like results. This is the opposite of 'expand'.\n",
    "    * 'broadcast' : results will be broadcast to the original shape\n",
    "      of the DataFrame, the original index and columns will be\n",
    "      retained.\n",
    "\n",
    "    The default behaviour (None) depends on the return value of the\n",
    "    applied function: list-like results will be returned as a Series\n",
    "    of those. However if the apply function returns a Series these\n",
    "    are expanded to columns.\n",
    "args : tuple\n",
    "    Positional arguments to pass to `func` in addition to the\n",
    "    array/series.\n",
    "**kwargs\n",
    "    Additional keyword arguments to pass as keywords arguments to\n",
    "    `func`.\n",
    "\n",
    "Returns\n",
    "-------\n",
    "Series or DataFrame\n",
    "    Result of applying ``func`` along the given axis of the\n",
    "    DataFrame.\n",
    "\n",
    "See Also\n",
    "--------\n",
    "DataFrame.applymap: For elementwise operations.\n",
    "DataFrame.aggregate: Only perform aggregating type operations.\n",
    "DataFrame.transform: Only perform transforming type operations.\n",
    "\n",
    "Notes\n",
    "-----\n",
    "Functions that mutate the passed object can produce unexpected\n",
    "behavior or errors and are not supported. See :ref:`gotchas.udf-mutation`\n",
    "for more details.\n",
    "\n",
    "Examples\n",
    "--------\n",
    ">>> df = pd.DataFrame([[4, 9]] * 3, columns=['A', 'B'])\n",
    ">>> df\n",
    "   A  B\n",
    "0  4  9\n",
    "1  4  9\n",
    "2  4  9\n",
    "\n",
    "Using a numpy universal function (in this case the same as\n",
    "``np.sqrt(df)``):\n",
    "\n",
    ">>> df.apply(np.sqrt)\n",
    "     A    B\n",
    "0  2.0  3.0\n",
    "1  2.0  3.0\n",
    "2  2.0  3.0\n",
    "\n",
    "Using a reducing function on either axis\n",
    "\n",
    ">>> df.apply(np.sum, axis=0)\n",
    "A    12\n",
    "B    27\n",
    "dtype: int64\n",
    "\n",
    ">>> df.apply(np.sum, axis=1)\n",
    "0    13\n",
    "1    13\n",
    "2    13\n",
    "dtype: int64\n",
    "\n",
    "Returning a list-like will result in a Series\n",
    "\n",
    ">>> df.apply(lambda x: [1, 2], axis=1)\n",
    "0    [1, 2]\n",
    "1    [1, 2]\n",
    "2    [1, 2]\n",
    "dtype: object\n",
    "\n",
    "Passing ``result_type='expand'`` will expand list-like results\n",
    "to columns of a Dataframe\n",
    "\n",
    ">>> df.apply(lambda x: [1, 2], axis=1, result_type='expand')\n",
    "   0  1\n",
    "0  1  2\n",
    "1  1  2\n",
    "2  1  2\n",
    "\n",
    "Returning a Series inside the function is similar to passing\n",
    "``result_type='expand'``. The resulting column names\n",
    "will be the Series index.\n",
    "\n",
    ">>> df.apply(lambda x: pd.Series([1, 2], index=['foo', 'bar']), axis=1)\n",
    "   foo  bar\n",
    "0    1    2\n",
    "1    1    2\n",
    "2    1    2\n",
    "\n",
    "Passing ``result_type='broadcast'`` will ensure the same shape\n",
    "result, whether list-like or scalar is returned by the function,\n",
    "and broadcast it along the axis. The resulting column names will\n",
    "be the originals.\n",
    "\n",
    ">>> df.apply(lambda x: [1, 2], axis=1, result_type='broadcast')\n",
    "   A  B\n",
    "0  1  2\n",
    "1  1  2\n",
    "2  1  2\n",
    "\n",
    "</code>\n",
    "<a href='#top_phases'>back to header</a>\n",
    "</blockquote>\n",
    "</details>\n",
    "</li>\n",
    "</ul>\n",
    "</li>\n",
    "\n",
    "</ul>\n",
    "</details></li>\n",
    "<li><details open><summary style='list-style: none; cursor: pointer;'><strong><u>Cell # 25</u></strong></summary><small><a href=#25>goto cell # 25</a></small>\n",
    "<ul>\n",
    "\n",
    "<li> <b>pandas</b>\n",
    "<ul>\n",
    "<li>\n",
    "<details><summary style='list-style: none; cursor: pointer;'><u>pandas.core.tools.datetimes.to_datetime</u> | (No Args Found) </summary>\n",
    "<blockquote>\n",
    "<code>\n",
    "Convert argument to datetime.\n",
    "\n",
    "This function converts a scalar, array-like, :class:`Series` or\n",
    ":class:`DataFrame`/dict-like to a pandas datetime object.\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "arg : int, float, str, datetime, list, tuple, 1-d array, Series, DataFrame/dict-like\n",
    "    The object to convert to a datetime. If a :class:`DataFrame` is provided, the\n",
    "    method expects minimally the following columns: :const:`\"year\"`,\n",
    "    :const:`\"month\"`, :const:`\"day\"`.\n",
    "errors : {'ignore', 'raise', 'coerce'}, default 'raise'\n",
    "    - If :const:`'raise'`, then invalid parsing will raise an exception.\n",
    "    - If :const:`'coerce'`, then invalid parsing will be set as :const:`NaT`.\n",
    "    - If :const:`'ignore'`, then invalid parsing will return the input.\n",
    "dayfirst : bool, default False\n",
    "    Specify a date parse order if `arg` is str or is list-like.\n",
    "    If :const:`True`, parses dates with the day first, e.g. :const:`\"10/11/12\"`\n",
    "    is parsed as :const:`2012-11-10`.\n",
    "\n",
    "    .. warning::\n",
    "\n",
    "        ``dayfirst=True`` is not strict, but will prefer to parse\n",
    "        with day first. If a delimited date string cannot be parsed in\n",
    "        accordance with the given `dayfirst` option, e.g.\n",
    "        ``to_datetime(['31-12-2021'])``, then a warning will be shown.\n",
    "\n",
    "yearfirst : bool, default False\n",
    "    Specify a date parse order if `arg` is str or is list-like.\n",
    "\n",
    "    - If :const:`True` parses dates with the year first, e.g.\n",
    "      :const:`\"10/11/12\"` is parsed as :const:`2010-11-12`.\n",
    "    - If both `dayfirst` and `yearfirst` are :const:`True`, `yearfirst` is\n",
    "      preceded (same as :mod:`dateutil`).\n",
    "\n",
    "    .. warning::\n",
    "\n",
    "        ``yearfirst=True`` is not strict, but will prefer to parse\n",
    "        with year first.\n",
    "\n",
    "utc : bool, default None\n",
    "    Control timezone-related parsing, localization and conversion.\n",
    "\n",
    "    - If :const:`True`, the function *always* returns a timezone-aware\n",
    "      UTC-localized :class:`Timestamp`, :class:`Series` or\n",
    "      :class:`DatetimeIndex`. To do this, timezone-naive inputs are\n",
    "      *localized* as UTC, while timezone-aware inputs are *converted* to UTC.\n",
    "\n",
    "    - If :const:`False` (default), inputs will not be coerced to UTC.\n",
    "      Timezone-naive inputs will remain naive, while timezone-aware ones\n",
    "      will keep their time offsets. Limitations exist for mixed\n",
    "      offsets (typically, daylight savings), see :ref:`Examples\n",
    "      <to_datetime_tz_examples>` section for details.\n",
    "\n",
    "    See also: pandas general documentation about `timezone conversion and\n",
    "    localization\n",
    "    <https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html\n",
    "    #time-zone-handling>`_.\n",
    "\n",
    "format : str, default None\n",
    "    The strftime to parse time, e.g. :const:`\"%d/%m/%Y\"`. Note that\n",
    "    :const:`\"%f\"` will parse all the way up to nanoseconds. See\n",
    "    `strftime documentation\n",
    "    <https://docs.python.org/3/library/datetime.html\n",
    "    #strftime-and-strptime-behavior>`_ for more information on choices.\n",
    "exact : bool, default True\n",
    "    Control how `format` is used:\n",
    "\n",
    "    - If :const:`True`, require an exact `format` match.\n",
    "    - If :const:`False`, allow the `format` to match anywhere in the target\n",
    "      string.\n",
    "\n",
    "unit : str, default 'ns'\n",
    "    The unit of the arg (D,s,ms,us,ns) denote the unit, which is an\n",
    "    integer or float number. This will be based off the origin.\n",
    "    Example, with ``unit='ms'`` and ``origin='unix'`` (the default), this\n",
    "    would calculate the number of milliseconds to the unix epoch start.\n",
    "infer_datetime_format : bool, default False\n",
    "    If :const:`True` and no `format` is given, attempt to infer the format\n",
    "    of the datetime strings based on the first non-NaN element,\n",
    "    and if it can be inferred, switch to a faster method of parsing them.\n",
    "    In some cases this can increase the parsing speed by ~5-10x.\n",
    "origin : scalar, default 'unix'\n",
    "    Define the reference date. The numeric values would be parsed as number\n",
    "    of units (defined by `unit`) since this reference date.\n",
    "\n",
    "    - If :const:`'unix'` (or POSIX) time; origin is set to 1970-01-01.\n",
    "    - If :const:`'julian'`, unit must be :const:`'D'`, and origin is set to\n",
    "      beginning of Julian Calendar. Julian day number :const:`0` is assigned\n",
    "      to the day starting at noon on January 1, 4713 BC.\n",
    "    - If Timestamp convertible, origin is set to Timestamp identified by\n",
    "      origin.\n",
    "cache : bool, default True\n",
    "    If :const:`True`, use a cache of unique, converted dates to apply the\n",
    "    datetime conversion. May produce significant speed-up when parsing\n",
    "    duplicate date strings, especially ones with timezone offsets. The cache\n",
    "    is only used when there are at least 50 values. The presence of\n",
    "    out-of-bounds values will render the cache unusable and may slow down\n",
    "    parsing.\n",
    "\n",
    "    .. versionchanged:: 0.25.0\n",
    "        changed default value from :const:`False` to :const:`True`.\n",
    "\n",
    "Returns\n",
    "-------\n",
    "datetime\n",
    "    If parsing succeeded.\n",
    "    Return type depends on input (types in parenthesis correspond to\n",
    "    fallback in case of unsuccessful timezone or out-of-range timestamp\n",
    "    parsing):\n",
    "\n",
    "    - scalar: :class:`Timestamp` (or :class:`datetime.datetime`)\n",
    "    - array-like: :class:`DatetimeIndex` (or :class:`Series` with\n",
    "      :class:`object` dtype containing :class:`datetime.datetime`)\n",
    "    - Series: :class:`Series` of :class:`datetime64` dtype (or\n",
    "      :class:`Series` of :class:`object` dtype containing\n",
    "      :class:`datetime.datetime`)\n",
    "    - DataFrame: :class:`Series` of :class:`datetime64` dtype (or\n",
    "      :class:`Series` of :class:`object` dtype containing\n",
    "      :class:`datetime.datetime`)\n",
    "\n",
    "Raises\n",
    "------\n",
    "ParserError\n",
    "    When parsing a date from string fails.\n",
    "ValueError\n",
    "    When another datetime conversion error happens. For example when one\n",
    "    of 'year', 'month', day' columns is missing in a :class:`DataFrame`, or\n",
    "    when a Timezone-aware :class:`datetime.datetime` is found in an array-like\n",
    "    of mixed time offsets, and ``utc=False``.\n",
    "\n",
    "See Also\n",
    "--------\n",
    "DataFrame.astype : Cast argument to a specified dtype.\n",
    "to_timedelta : Convert argument to timedelta.\n",
    "convert_dtypes : Convert dtypes.\n",
    "\n",
    "Notes\n",
    "-----\n",
    "\n",
    "Many input types are supported, and lead to different output types:\n",
    "\n",
    "- **scalars** can be int, float, str, datetime object (from stdlib :mod:`datetime`\n",
    "  module or :mod:`numpy`). They are converted to :class:`Timestamp` when\n",
    "  possible, otherwise they are converted to :class:`datetime.datetime`.\n",
    "  None/NaN/null scalars are converted to :const:`NaT`.\n",
    "\n",
    "- **array-like** can contain int, float, str, datetime objects. They are\n",
    "  converted to :class:`DatetimeIndex` when possible, otherwise they are\n",
    "  converted to :class:`Index` with :class:`object` dtype, containing\n",
    "  :class:`datetime.datetime`. None/NaN/null entries are converted to\n",
    "  :const:`NaT` in both cases.\n",
    "\n",
    "- **Series** are converted to :class:`Series` with :class:`datetime64`\n",
    "  dtype when possible, otherwise they are converted to :class:`Series` with\n",
    "  :class:`object` dtype, containing :class:`datetime.datetime`. None/NaN/null\n",
    "  entries are converted to :const:`NaT` in both cases.\n",
    "\n",
    "- **DataFrame/dict-like** are converted to :class:`Series` with\n",
    "  :class:`datetime64` dtype. For each row a datetime is created from assembling\n",
    "  the various dataframe columns. Column keys can be common abbreviations\n",
    "  like [‘year’, ‘month’, ‘day’, ‘minute’, ‘second’, ‘ms’, ‘us’, ‘ns’]) or\n",
    "  plurals of the same.\n",
    "\n",
    "The following causes are responsible for :class:`datetime.datetime` objects\n",
    "being returned (possibly inside an :class:`Index` or a :class:`Series` with\n",
    ":class:`object` dtype) instead of a proper pandas designated type\n",
    "(:class:`Timestamp`, :class:`DatetimeIndex` or :class:`Series`\n",
    "with :class:`datetime64` dtype):\n",
    "\n",
    "- when any input element is before :const:`Timestamp.min` or after\n",
    "  :const:`Timestamp.max`, see `timestamp limitations\n",
    "  <https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html\n",
    "  #timeseries-timestamp-limits>`_.\n",
    "\n",
    "- when ``utc=False`` (default) and the input is an array-like or\n",
    "  :class:`Series` containing mixed naive/aware datetime, or aware with mixed\n",
    "  time offsets. Note that this happens in the (quite frequent) situation when\n",
    "  the timezone has a daylight savings policy. In that case you may wish to\n",
    "  use ``utc=True``.\n",
    "\n",
    "Examples\n",
    "--------\n",
    "\n",
    "**Handling various input formats**\n",
    "\n",
    "Assembling a datetime from multiple columns of a :class:`DataFrame`. The keys\n",
    "can be common abbreviations like ['year', 'month', 'day', 'minute', 'second',\n",
    "'ms', 'us', 'ns']) or plurals of the same\n",
    "\n",
    ">>> df = pd.DataFrame({'year': [2015, 2016],\n",
    "...                    'month': [2, 3],\n",
    "...                    'day': [4, 5]})\n",
    ">>> pd.to_datetime(df)\n",
    "0   2015-02-04\n",
    "1   2016-03-05\n",
    "dtype: datetime64[ns]\n",
    "\n",
    "Passing ``infer_datetime_format=True`` can often-times speedup a parsing\n",
    "if its not an ISO8601 format exactly, but in a regular format.\n",
    "\n",
    ">>> s = pd.Series(['3/11/2000', '3/12/2000', '3/13/2000'] * 1000)\n",
    ">>> s.head()\n",
    "0    3/11/2000\n",
    "1    3/12/2000\n",
    "2    3/13/2000\n",
    "3    3/11/2000\n",
    "4    3/12/2000\n",
    "dtype: object\n",
    "\n",
    ">>> %timeit pd.to_datetime(s, infer_datetime_format=True)  # doctest: +SKIP\n",
    "100 loops, best of 3: 10.4 ms per loop\n",
    "\n",
    ">>> %timeit pd.to_datetime(s, infer_datetime_format=False)  # doctest: +SKIP\n",
    "1 loop, best of 3: 471 ms per loop\n",
    "\n",
    "Using a unix epoch time\n",
    "\n",
    ">>> pd.to_datetime(1490195805, unit='s')\n",
    "Timestamp('2017-03-22 15:16:45')\n",
    ">>> pd.to_datetime(1490195805433502912, unit='ns')\n",
    "Timestamp('2017-03-22 15:16:45.433502912')\n",
    "\n",
    ".. warning:: For float arg, precision rounding might happen. To prevent\n",
    "    unexpected behavior use a fixed-width exact type.\n",
    "\n",
    "Using a non-unix epoch origin\n",
    "\n",
    ">>> pd.to_datetime([1, 2, 3], unit='D',\n",
    "...                origin=pd.Timestamp('1960-01-01'))\n",
    "DatetimeIndex(['1960-01-02', '1960-01-03', '1960-01-04'],\n",
    "              dtype='datetime64[ns]', freq=None)\n",
    "\n",
    "**Non-convertible date/times**\n",
    "\n",
    "If a date does not meet the `timestamp limitations\n",
    "<https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html\n",
    "timeseries-timestamp-limits>`_, passing ``errors='ignore'``\n",
    "will return the original input instead of raising any exception.\n",
    "\n",
    "Passing ``errors='coerce'`` will force an out-of-bounds date to :const:`NaT`,\n",
    "in addition to forcing non-dates (or non-parseable dates) to :const:`NaT`.\n",
    "\n",
    ">>> pd.to_datetime('13000101', format='%Y%m%d', errors='ignore')\n",
    "datetime.datetime(1300, 1, 1, 0, 0)\n",
    ">>> pd.to_datetime('13000101', format='%Y%m%d', errors='coerce')\n",
    "NaT\n",
    "\n",
    ".. _to_datetime_tz_examples:\n",
    "\n",
    "**Timezones and time offsets**\n",
    "\n",
    "The default behaviour (``utc=False``) is as follows:\n",
    "\n",
    "- Timezone-naive inputs are converted to timezone-naive :class:`DatetimeIndex`:\n",
    "\n",
    ">>> pd.to_datetime(['2018-10-26 12:00', '2018-10-26 13:00:15'])\n",
    "DatetimeIndex(['2018-10-26 12:00:00', '2018-10-26 13:00:15'],\n",
    "              dtype='datetime64[ns]', freq=None)\n",
    "\n",
    "- Timezone-aware inputs *with constant time offset* are converted to\n",
    "  timezone-aware :class:`DatetimeIndex`:\n",
    "\n",
    ">>> pd.to_datetime(['2018-10-26 12:00 -0500', '2018-10-26 13:00 -0500'])\n",
    "DatetimeIndex(['2018-10-26 12:00:00-05:00', '2018-10-26 13:00:00-05:00'],\n",
    "              dtype='datetime64[ns, pytz.FixedOffset(-300)]', freq=None)\n",
    "\n",
    "- However, timezone-aware inputs *with mixed time offsets* (for example\n",
    "  issued from a timezone with daylight savings, such as Europe/Paris)\n",
    "  are **not successfully converted** to a :class:`DatetimeIndex`. Instead a\n",
    "  simple :class:`Index` containing :class:`datetime.datetime` objects is\n",
    "  returned:\n",
    "\n",
    ">>> pd.to_datetime(['2020-10-25 02:00 +0200', '2020-10-25 04:00 +0100'])\n",
    "Index([2020-10-25 02:00:00+02:00, 2020-10-25 04:00:00+01:00],\n",
    "      dtype='object')\n",
    "\n",
    "- A mix of timezone-aware and timezone-naive inputs is converted to\n",
    "  a timezone-aware :class:`DatetimeIndex` if the offsets of the timezone-aware\n",
    "  are constant:\n",
    "\n",
    ">>> from datetime import datetime\n",
    ">>> pd.to_datetime([\"2020-01-01 01:00 -01:00\", datetime(2020, 1, 1, 3, 0)])\n",
    "DatetimeIndex(['2020-01-01 01:00:00-01:00', '2020-01-01 02:00:00-01:00'],\n",
    "              dtype='datetime64[ns, pytz.FixedOffset(-60)]', freq=None)\n",
    "\n",
    "- Finally, mixing timezone-aware strings and :class:`datetime.datetime` always\n",
    "  raises an error, even if the elements all have the same time offset.\n",
    "\n",
    ">>> from datetime import datetime, timezone, timedelta\n",
    ">>> d = datetime(2020, 1, 1, 18, tzinfo=timezone(-timedelta(hours=1)))\n",
    ">>> pd.to_datetime([\"2020-01-01 17:00 -0100\", d])\n",
    "Traceback (most recent call last):\n",
    "    ...\n",
    "ValueError: Tz-aware datetime.datetime cannot be converted to datetime64\n",
    "            unless utc=True\n",
    "\n",
    "|\n",
    "\n",
    "Setting ``utc=True`` solves most of the above issues:\n",
    "\n",
    "- Timezone-naive inputs are *localized* as UTC\n",
    "\n",
    ">>> pd.to_datetime(['2018-10-26 12:00', '2018-10-26 13:00'], utc=True)\n",
    "DatetimeIndex(['2018-10-26 12:00:00+00:00', '2018-10-26 13:00:00+00:00'],\n",
    "              dtype='datetime64[ns, UTC]', freq=None)\n",
    "\n",
    "- Timezone-aware inputs are *converted* to UTC (the output represents the\n",
    "  exact same datetime, but viewed from the UTC time offset `+00:00`).\n",
    "\n",
    ">>> pd.to_datetime(['2018-10-26 12:00 -0530', '2018-10-26 12:00 -0500'],\n",
    "...                utc=True)\n",
    "DatetimeIndex(['2018-10-26 17:30:00+00:00', '2018-10-26 17:00:00+00:00'],\n",
    "              dtype='datetime64[ns, UTC]', freq=None)\n",
    "\n",
    "- Inputs can contain both naive and aware, string or datetime, the above\n",
    "  rules still apply\n",
    "\n",
    ">>> pd.to_datetime(['2018-10-26 12:00', '2018-10-26 12:00 -0530',\n",
    "...                datetime(2020, 1, 1, 18),\n",
    "...                datetime(2020, 1, 1, 18,\n",
    "...                tzinfo=timezone(-timedelta(hours=1)))],\n",
    "...                utc=True)\n",
    "DatetimeIndex(['2018-10-26 12:00:00+00:00', '2018-10-26 17:30:00+00:00',\n",
    "               '2020-01-01 18:00:00+00:00', '2020-01-01 19:00:00+00:00'],\n",
    "              dtype='datetime64[ns, UTC]', freq=None)\n",
    "\n",
    "</code>\n",
    "<a href='#top_phases'>back to header</a>\n",
    "</blockquote>\n",
    "</details>\n",
    "</li>\n",
    "</ul>\n",
    "</li>\n",
    "\n",
    "</ul>\n",
    "</details></li>\n",
    "\n",
    "</ul>\n",
    "</details></li></ul>\n",
    "<ul><li><details><summary style='list-style: none;'><s>Feature Selection</s> (no calls found)</summary>\n",
    "<ul>\n",
    "\n",
    "None\n",
    "\n",
    "</ul>\n",
    "</details></li></ul>\n",
    "<li><details><summary style='list-style: none;'><h3><span style='color:#42a5f5'>Model Building and Training</span></h3></summary>\n",
    "<ul>\n",
    "\n",
    "None\n",
    "\n",
    "</ul>\n",
    "</details></li>\n",
    "<ul><li><details><summary style='list-style: none;'><s>Model Training</s> (no calls found)</summary>\n",
    "<ul>\n",
    "\n",
    "None\n",
    "\n",
    "</ul>\n",
    "</details></li></ul>\n",
    "<ul><li><details><summary style='list-style: none;'><s>Model Parameter Tuning</s> (no calls found)</summary>\n",
    "<ul>\n",
    "\n",
    "None\n",
    "\n",
    "</ul>\n",
    "</details></li></ul>\n",
    "<ul><li><details><summary style='list-style: none;'><s>Model Validation and Assembling</s> (no calls found)</summary>\n",
    "<ul>\n",
    "\n",
    "None\n",
    "\n",
    "</ul>\n",
    "</details></li></ul>\n",
    "</ul>\n",
    "<hr>\n",
    "\n",
    "<details><summary style='list-style: none; cursor: pointer;'><strong>View All ML API Calls in Notebook</strong></summary>\n",
    "<ul>\n",
    "\n",
    "<li> <b>datetime</b>\n",
    "<ul>\n",
    "<li>\n",
    "<details><summary style='list-style: none; cursor: pointer;'><u>datetime.time</u></summary>\n",
    "<blockquote>\n",
    "<code>\n",
    "time([hour[, minute[, second[, microsecond[, tzinfo]]]]]) --> a time object\n",
    "\n",
    "All arguments are optional. tzinfo may be None, or an instance of\n",
    "a tzinfo subclass. The remaining arguments may be ints.\n",
    "\n",
    "</code>\n",
    "<a href='#top_phases'>back to header</a>\n",
    "</blockquote>\n",
    "</details>\n",
    "</li>\n",
    "</ul>\n",
    "</li>\n",
    "<li> <b>pandas</b>\n",
    "<ul>\n",
    "<li>\n",
    "<details><summary style='list-style: none; cursor: pointer;'><u>pandas</u></summary>\n",
    "<blockquote>\n",
    "<code>\n",
    "pandas - a powerful data analysis and manipulation library for Python\n",
    "=====================================================================\n",
    "\n",
    "**pandas** is a Python package providing fast, flexible, and expressive data\n",
    "structures designed to make working with \"relational\" or \"labeled\" data both\n",
    "easy and intuitive. It aims to be the fundamental high-level building block for\n",
    "doing practical, **real world** data analysis in Python. Additionally, it has\n",
    "the broader goal of becoming **the most powerful and flexible open source data\n",
    "analysis / manipulation tool available in any language**. It is already well on\n",
    "its way toward this goal.\n",
    "\n",
    "Main Features\n",
    "-------------\n",
    "Here are just a few of the things that pandas does well:\n",
    "\n",
    "  - Easy handling of missing data in floating point as well as non-floating\n",
    "    point data.\n",
    "  - Size mutability: columns can be inserted and deleted from DataFrame and\n",
    "    higher dimensional objects\n",
    "  - Automatic and explicit data alignment: objects can be explicitly aligned\n",
    "    to a set of labels, or the user can simply ignore the labels and let\n",
    "    `Series`, `DataFrame`, etc. automatically align the data for you in\n",
    "    computations.\n",
    "  - Powerful, flexible group by functionality to perform split-apply-combine\n",
    "    operations on data sets, for both aggregating and transforming data.\n",
    "  - Make it easy to convert ragged, differently-indexed data in other Python\n",
    "    and NumPy data structures into DataFrame objects.\n",
    "  - Intelligent label-based slicing, fancy indexing, and subsetting of large\n",
    "    data sets.\n",
    "  - Intuitive merging and joining data sets.\n",
    "  - Flexible reshaping and pivoting of data sets.\n",
    "  - Hierarchical labeling of axes (possible to have multiple labels per tick).\n",
    "  - Robust IO tools for loading data from flat files (CSV and delimited),\n",
    "    Excel files, databases, and saving/loading data from the ultrafast HDF5\n",
    "    format.\n",
    "  - Time series-specific functionality: date range generation and frequency\n",
    "    conversion, moving window statistics, date shifting and lagging.\n",
    "\n",
    "</code>\n",
    "<a href='#top_phases'>back to header</a>\n",
    "</blockquote>\n",
    "</details>\n",
    "</li>\n",
    "<li>\n",
    "<details><summary style='list-style: none; cursor: pointer;'><u>pandas._libs.tslibs.nattype.NaTType</u></summary>\n",
    "<blockquote>\n",
    "<code>\n",
    "(N)ot-(A)-(T)ime, the time equivalent of NaN.\n",
    "\n",
    "</code>\n",
    "<a href='#top_phases'>back to header</a>\n",
    "</blockquote>\n",
    "</details>\n",
    "</li>\n",
    "<li>\n",
    "<details><summary style='list-style: none; cursor: pointer;'><u>pandas.core.frame.DataFrame</u></summary>\n",
    "<blockquote>\n",
    "<code>\n",
    "Two-dimensional, size-mutable, potentially heterogeneous tabular data.\n",
    "\n",
    "Data structure also contains labeled axes (rows and columns).\n",
    "Arithmetic operations align on both row and column labels. Can be\n",
    "thought of as a dict-like container for Series objects. The primary\n",
    "pandas data structure.\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "data : ndarray (structured or homogeneous), Iterable, dict, or DataFrame\n",
    "    Dict can contain Series, arrays, constants, dataclass or list-like objects. If\n",
    "    data is a dict, column order follows insertion-order. If a dict contains Series\n",
    "    which have an index defined, it is aligned by its index.\n",
    "\n",
    "    .. versionchanged:: 0.25.0\n",
    "       If data is a list of dicts, column order follows insertion-order.\n",
    "\n",
    "index : Index or array-like\n",
    "    Index to use for resulting frame. Will default to RangeIndex if\n",
    "    no indexing information part of input data and no index provided.\n",
    "columns : Index or array-like\n",
    "    Column labels to use for resulting frame when data does not have them,\n",
    "    defaulting to RangeIndex(0, 1, 2, ..., n). If data contains column labels,\n",
    "    will perform column selection instead.\n",
    "dtype : dtype, default None\n",
    "    Data type to force. Only a single dtype is allowed. If None, infer.\n",
    "copy : bool or None, default None\n",
    "    Copy data from inputs.\n",
    "    For dict data, the default of None behaves like ``copy=True``.  For DataFrame\n",
    "    or 2d ndarray input, the default of None behaves like ``copy=False``.\n",
    "\n",
    "    .. versionchanged:: 1.3.0\n",
    "\n",
    "See Also\n",
    "--------\n",
    "DataFrame.from_records : Constructor from tuples, also record arrays.\n",
    "DataFrame.from_dict : From dicts of Series, arrays, or dicts.\n",
    "read_csv : Read a comma-separated values (csv) file into DataFrame.\n",
    "read_table : Read general delimited file into DataFrame.\n",
    "read_clipboard : Read text from clipboard into DataFrame.\n",
    "\n",
    "Examples\n",
    "--------\n",
    "Constructing DataFrame from a dictionary.\n",
    "\n",
    ">>> d = {'col1': [1, 2], 'col2': [3, 4]}\n",
    ">>> df = pd.DataFrame(data=d)\n",
    ">>> df\n",
    "   col1  col2\n",
    "0     1     3\n",
    "1     2     4\n",
    "\n",
    "Notice that the inferred dtype is int64.\n",
    "\n",
    ">>> df.dtypes\n",
    "col1    int64\n",
    "col2    int64\n",
    "dtype: object\n",
    "\n",
    "To enforce a single dtype:\n",
    "\n",
    ">>> df = pd.DataFrame(data=d, dtype=np.int8)\n",
    ">>> df.dtypes\n",
    "col1    int8\n",
    "col2    int8\n",
    "dtype: object\n",
    "\n",
    "Constructing DataFrame from a dictionary including Series:\n",
    "\n",
    ">>> d = {'col1': [0, 1, 2, 3], 'col2': pd.Series([2, 3], index=[2, 3])}\n",
    ">>> pd.DataFrame(data=d, index=[0, 1, 2, 3])\n",
    "   col1  col2\n",
    "0     0   NaN\n",
    "1     1   NaN\n",
    "2     2   2.0\n",
    "3     3   3.0\n",
    "\n",
    "Constructing DataFrame from numpy ndarray:\n",
    "\n",
    ">>> df2 = pd.DataFrame(np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]]),\n",
    "...                    columns=['a', 'b', 'c'])\n",
    ">>> df2\n",
    "   a  b  c\n",
    "0  1  2  3\n",
    "1  4  5  6\n",
    "2  7  8  9\n",
    "\n",
    "Constructing DataFrame from a numpy ndarray that has labeled columns:\n",
    "\n",
    ">>> data = np.array([(1, 2, 3), (4, 5, 6), (7, 8, 9)],\n",
    "...                 dtype=[(\"a\", \"i4\"), (\"b\", \"i4\"), (\"c\", \"i4\")])\n",
    ">>> df3 = pd.DataFrame(data, columns=['c', 'a'])\n",
    "...\n",
    ">>> df3\n",
    "   c  a\n",
    "0  3  1\n",
    "1  6  4\n",
    "2  9  7\n",
    "\n",
    "Constructing DataFrame from dataclass:\n",
    "\n",
    ">>> from dataclasses import make_dataclass\n",
    ">>> Point = make_dataclass(\"Point\", [(\"x\", int), (\"y\", int)])\n",
    ">>> pd.DataFrame([Point(0, 0), Point(0, 3), Point(2, 3)])\n",
    "   x  y\n",
    "0  0  0\n",
    "1  0  3\n",
    "2  2  3\n",
    "\n",
    "</code>\n",
    "<a href='#top_phases'>back to header</a>\n",
    "</blockquote>\n",
    "</details>\n",
    "</li>\n",
    "<li>\n",
    "<details><summary style='list-style: none; cursor: pointer;'><u>pandas.core.frame.DataFrame.apply</u></summary>\n",
    "<blockquote>\n",
    "<code>\n",
    "Apply a function along an axis of the DataFrame.\n",
    "\n",
    "Objects passed to the function are Series objects whose index is\n",
    "either the DataFrame's index (``axis=0``) or the DataFrame's columns\n",
    "(``axis=1``). By default (``result_type=None``), the final return type\n",
    "is inferred from the return type of the applied function. Otherwise,\n",
    "it depends on the `result_type` argument.\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "func : function\n",
    "    Function to apply to each column or row.\n",
    "axis : {0 or 'index', 1 or 'columns'}, default 0\n",
    "    Axis along which the function is applied:\n",
    "\n",
    "    * 0 or 'index': apply function to each column.\n",
    "    * 1 or 'columns': apply function to each row.\n",
    "\n",
    "raw : bool, default False\n",
    "    Determines if row or column is passed as a Series or ndarray object:\n",
    "\n",
    "    * ``False`` : passes each row or column as a Series to the\n",
    "      function.\n",
    "    * ``True`` : the passed function will receive ndarray objects\n",
    "      instead.\n",
    "      If you are just applying a NumPy reduction function this will\n",
    "      achieve much better performance.\n",
    "\n",
    "result_type : {'expand', 'reduce', 'broadcast', None}, default None\n",
    "    These only act when ``axis=1`` (columns):\n",
    "\n",
    "    * 'expand' : list-like results will be turned into columns.\n",
    "    * 'reduce' : returns a Series if possible rather than expanding\n",
    "      list-like results. This is the opposite of 'expand'.\n",
    "    * 'broadcast' : results will be broadcast to the original shape\n",
    "      of the DataFrame, the original index and columns will be\n",
    "      retained.\n",
    "\n",
    "    The default behaviour (None) depends on the return value of the\n",
    "    applied function: list-like results will be returned as a Series\n",
    "    of those. However if the apply function returns a Series these\n",
    "    are expanded to columns.\n",
    "args : tuple\n",
    "    Positional arguments to pass to `func` in addition to the\n",
    "    array/series.\n",
    "**kwargs\n",
    "    Additional keyword arguments to pass as keywords arguments to\n",
    "    `func`.\n",
    "\n",
    "Returns\n",
    "-------\n",
    "Series or DataFrame\n",
    "    Result of applying ``func`` along the given axis of the\n",
    "    DataFrame.\n",
    "\n",
    "See Also\n",
    "--------\n",
    "DataFrame.applymap: For elementwise operations.\n",
    "DataFrame.aggregate: Only perform aggregating type operations.\n",
    "DataFrame.transform: Only perform transforming type operations.\n",
    "\n",
    "Notes\n",
    "-----\n",
    "Functions that mutate the passed object can produce unexpected\n",
    "behavior or errors and are not supported. See :ref:`gotchas.udf-mutation`\n",
    "for more details.\n",
    "\n",
    "Examples\n",
    "--------\n",
    ">>> df = pd.DataFrame([[4, 9]] * 3, columns=['A', 'B'])\n",
    ">>> df\n",
    "   A  B\n",
    "0  4  9\n",
    "1  4  9\n",
    "2  4  9\n",
    "\n",
    "Using a numpy universal function (in this case the same as\n",
    "``np.sqrt(df)``):\n",
    "\n",
    ">>> df.apply(np.sqrt)\n",
    "     A    B\n",
    "0  2.0  3.0\n",
    "1  2.0  3.0\n",
    "2  2.0  3.0\n",
    "\n",
    "Using a reducing function on either axis\n",
    "\n",
    ">>> df.apply(np.sum, axis=0)\n",
    "A    12\n",
    "B    27\n",
    "dtype: int64\n",
    "\n",
    ">>> df.apply(np.sum, axis=1)\n",
    "0    13\n",
    "1    13\n",
    "2    13\n",
    "dtype: int64\n",
    "\n",
    "Returning a list-like will result in a Series\n",
    "\n",
    ">>> df.apply(lambda x: [1, 2], axis=1)\n",
    "0    [1, 2]\n",
    "1    [1, 2]\n",
    "2    [1, 2]\n",
    "dtype: object\n",
    "\n",
    "Passing ``result_type='expand'`` will expand list-like results\n",
    "to columns of a Dataframe\n",
    "\n",
    ">>> df.apply(lambda x: [1, 2], axis=1, result_type='expand')\n",
    "   0  1\n",
    "0  1  2\n",
    "1  1  2\n",
    "2  1  2\n",
    "\n",
    "Returning a Series inside the function is similar to passing\n",
    "``result_type='expand'``. The resulting column names\n",
    "will be the Series index.\n",
    "\n",
    ">>> df.apply(lambda x: pd.Series([1, 2], index=['foo', 'bar']), axis=1)\n",
    "   foo  bar\n",
    "0    1    2\n",
    "1    1    2\n",
    "2    1    2\n",
    "\n",
    "Passing ``result_type='broadcast'`` will ensure the same shape\n",
    "result, whether list-like or scalar is returned by the function,\n",
    "and broadcast it along the axis. The resulting column names will\n",
    "be the originals.\n",
    "\n",
    ">>> df.apply(lambda x: [1, 2], axis=1, result_type='broadcast')\n",
    "   A  B\n",
    "0  1  2\n",
    "1  1  2\n",
    "2  1  2\n",
    "\n",
    "</code>\n",
    "<a href='#top_phases'>back to header</a>\n",
    "</blockquote>\n",
    "</details>\n",
    "</li>\n",
    "<li>\n",
    "<details><summary style='list-style: none; cursor: pointer;'><u>pandas.core.frame.DataFrame.isnull</u></summary>\n",
    "<blockquote>\n",
    "<code>\n",
    "DataFrame.isnull is an alias for DataFrame.isna.\n",
    "\n",
    "Detect missing values.\n",
    "\n",
    "Return a boolean same-sized object indicating if the values are NA.\n",
    "NA values, such as None or :attr:`numpy.NaN`, gets mapped to True\n",
    "values.\n",
    "Everything else gets mapped to False values. Characters such as empty\n",
    "strings ``''`` or :attr:`numpy.inf` are not considered NA values\n",
    "(unless you set ``pandas.options.mode.use_inf_as_na = True``).\n",
    "\n",
    "Returns\n",
    "-------\n",
    "DataFrame\n",
    "    Mask of bool values for each element in DataFrame that\n",
    "    indicates whether an element is an NA value.\n",
    "\n",
    "See Also\n",
    "--------\n",
    "DataFrame.isnull : Alias of isna.\n",
    "DataFrame.notna : Boolean inverse of isna.\n",
    "DataFrame.dropna : Omit axes labels with missing values.\n",
    "isna : Top-level isna.\n",
    "\n",
    "Examples\n",
    "--------\n",
    "Show which entries in a DataFrame are NA.\n",
    "\n",
    ">>> df = pd.DataFrame(dict(age=[5, 6, np.NaN],\n",
    "...                    born=[pd.NaT, pd.Timestamp('1939-05-27'),\n",
    "...                          pd.Timestamp('1940-04-25')],\n",
    "...                    name=['Alfred', 'Batman', ''],\n",
    "...                    toy=[None, 'Batmobile', 'Joker']))\n",
    ">>> df\n",
    "   age       born    name        toy\n",
    "0  5.0        NaT  Alfred       None\n",
    "1  6.0 1939-05-27  Batman  Batmobile\n",
    "2  NaN 1940-04-25              Joker\n",
    "\n",
    ">>> df.isna()\n",
    "     age   born   name    toy\n",
    "0  False   True  False   True\n",
    "1  False  False  False  False\n",
    "2   True  False  False  False\n",
    "\n",
    "Show which entries in a Series are NA.\n",
    "\n",
    ">>> ser = pd.Series([5, 6, np.NaN])\n",
    ">>> ser\n",
    "0    5.0\n",
    "1    6.0\n",
    "2    NaN\n",
    "dtype: float64\n",
    "\n",
    ">>> ser.isna()\n",
    "0    False\n",
    "1    False\n",
    "2     True\n",
    "dtype: bool\n",
    "\n",
    "</code>\n",
    "<a href='#top_phases'>back to header</a>\n",
    "</blockquote>\n",
    "</details>\n",
    "</li>\n",
    "<li>\n",
    "<details><summary style='list-style: none; cursor: pointer;'><u>pandas.core.generic.NDFrame._add_numeric_operations.<locals>.sum</u></summary>\n",
    "<blockquote>\n",
    "<code>\n",
    "Return the sum of the values over the requested axis.\n",
    "\n",
    "This is equivalent to the method ``numpy.sum``.\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "axis : {index (0), columns (1)}\n",
    "    Axis for the function to be applied on.\n",
    "skipna : bool, default True\n",
    "    Exclude NA/null values when computing the result.\n",
    "level : int or level name, default None\n",
    "    If the axis is a MultiIndex (hierarchical), count along a\n",
    "    particular level, collapsing into a Series.\n",
    "numeric_only : bool, default None\n",
    "    Include only float, int, boolean columns. If None, will attempt to use\n",
    "    everything, then use only numeric data. Not implemented for Series.\n",
    "min_count : int, default 0\n",
    "    The required number of valid values to perform the operation. If fewer than\n",
    "    ``min_count`` non-NA values are present the result will be NA.\n",
    "**kwargs\n",
    "    Additional keyword arguments to be passed to the function.\n",
    "\n",
    "Returns\n",
    "-------\n",
    "Series or DataFrame (if level specified)\n",
    "\n",
    "See Also\n",
    "--------\n",
    "Series.sum : Return the sum.\n",
    "Series.min : Return the minimum.\n",
    "Series.max : Return the maximum.\n",
    "Series.idxmin : Return the index of the minimum.\n",
    "Series.idxmax : Return the index of the maximum.\n",
    "DataFrame.sum : Return the sum over the requested axis.\n",
    "DataFrame.min : Return the minimum over the requested axis.\n",
    "DataFrame.max : Return the maximum over the requested axis.\n",
    "DataFrame.idxmin : Return the index of the minimum over the requested axis.\n",
    "DataFrame.idxmax : Return the index of the maximum over the requested axis.\n",
    "\n",
    "Examples\n",
    "--------\n",
    ">>> idx = pd.MultiIndex.from_arrays([\n",
    "...     ['warm', 'warm', 'cold', 'cold'],\n",
    "...     ['dog', 'falcon', 'fish', 'spider']],\n",
    "...     names=['blooded', 'animal'])\n",
    ">>> s = pd.Series([4, 2, 0, 8], name='legs', index=idx)\n",
    ">>> s\n",
    "blooded  animal\n",
    "warm     dog       4\n",
    "         falcon    2\n",
    "cold     fish      0\n",
    "         spider    8\n",
    "Name: legs, dtype: int64\n",
    "\n",
    ">>> s.sum()\n",
    "14\n",
    "\n",
    "By default, the sum of an empty or all-NA Series is ``0``.\n",
    "\n",
    ">>> pd.Series([], dtype=\"float64\").sum()  # min_count=0 is the default\n",
    "0.0\n",
    "\n",
    "This can be controlled with the ``min_count`` parameter. For example, if\n",
    "you'd like the sum of an empty series to be NaN, pass ``min_count=1``.\n",
    "\n",
    ">>> pd.Series([], dtype=\"float64\").sum(min_count=1)\n",
    "nan\n",
    "\n",
    "Thanks to the ``skipna`` parameter, ``min_count`` handles all-NA and\n",
    "empty series identically.\n",
    "\n",
    ">>> pd.Series([np.nan]).sum()\n",
    "0.0\n",
    "\n",
    ">>> pd.Series([np.nan]).sum(min_count=1)\n",
    "nan\n",
    "\n",
    "</code>\n",
    "<a href='#top_phases'>back to header</a>\n",
    "</blockquote>\n",
    "</details>\n",
    "</li>\n",
    "<li>\n",
    "<details><summary style='list-style: none; cursor: pointer;'><u>pandas.core.generic.NDFrame.head</u></summary>\n",
    "<blockquote>\n",
    "<code>\n",
    "Return the first `n` rows.\n",
    "\n",
    "This function returns the first `n` rows for the object based\n",
    "on position. It is useful for quickly testing if your object\n",
    "has the right type of data in it.\n",
    "\n",
    "For negative values of `n`, this function returns all rows except\n",
    "the last `n` rows, equivalent to ``df[:-n]``.\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "n : int, default 5\n",
    "    Number of rows to select.\n",
    "\n",
    "Returns\n",
    "-------\n",
    "same type as caller\n",
    "    The first `n` rows of the caller object.\n",
    "\n",
    "See Also\n",
    "--------\n",
    "DataFrame.tail: Returns the last `n` rows.\n",
    "\n",
    "Examples\n",
    "--------\n",
    ">>> df = pd.DataFrame({'animal': ['alligator', 'bee', 'falcon', 'lion',\n",
    "...                    'monkey', 'parrot', 'shark', 'whale', 'zebra']})\n",
    ">>> df\n",
    "      animal\n",
    "0  alligator\n",
    "1        bee\n",
    "2     falcon\n",
    "3       lion\n",
    "4     monkey\n",
    "5     parrot\n",
    "6      shark\n",
    "7      whale\n",
    "8      zebra\n",
    "\n",
    "Viewing the first 5 lines\n",
    "\n",
    ">>> df.head()\n",
    "      animal\n",
    "0  alligator\n",
    "1        bee\n",
    "2     falcon\n",
    "3       lion\n",
    "4     monkey\n",
    "\n",
    "Viewing the first `n` lines (three in this case)\n",
    "\n",
    ">>> df.head(3)\n",
    "      animal\n",
    "0  alligator\n",
    "1        bee\n",
    "2     falcon\n",
    "\n",
    "For negative values of `n`\n",
    "\n",
    ">>> df.head(-3)\n",
    "      animal\n",
    "0  alligator\n",
    "1        bee\n",
    "2     falcon\n",
    "3       lion\n",
    "4     monkey\n",
    "5     parrot\n",
    "\n",
    "</code>\n",
    "<a href='#top_phases'>back to header</a>\n",
    "</blockquote>\n",
    "</details>\n",
    "</li>\n",
    "<li>\n",
    "<details><summary style='list-style: none; cursor: pointer;'><u>pandas.core.indexes.datetimes.DatetimeIndex</u></summary>\n",
    "<blockquote>\n",
    "<code>\n",
    "Immutable ndarray-like of datetime64 data.\n",
    "\n",
    "Represented internally as int64, and which can be boxed to Timestamp objects\n",
    "that are subclasses of datetime and carry metadata.\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "data : array-like (1-dimensional), optional\n",
    "    Optional datetime-like data to construct index with.\n",
    "freq : str or pandas offset object, optional\n",
    "    One of pandas date offset strings or corresponding objects. The string\n",
    "    'infer' can be passed in order to set the frequency of the index as the\n",
    "    inferred frequency upon creation.\n",
    "tz : pytz.timezone or dateutil.tz.tzfile or datetime.tzinfo or str\n",
    "    Set the Timezone of the data.\n",
    "normalize : bool, default False\n",
    "    Normalize start/end dates to midnight before generating date range.\n",
    "closed : {'left', 'right'}, optional\n",
    "    Set whether to include `start` and `end` that are on the\n",
    "    boundary. The default includes boundary points on either end.\n",
    "ambiguous : 'infer', bool-ndarray, 'NaT', default 'raise'\n",
    "    When clocks moved backward due to DST, ambiguous times may arise.\n",
    "    For example in Central European Time (UTC+01), when going from 03:00\n",
    "    DST to 02:00 non-DST, 02:30:00 local time occurs both at 00:30:00 UTC\n",
    "    and at 01:30:00 UTC. In such a situation, the `ambiguous` parameter\n",
    "    dictates how ambiguous times should be handled.\n",
    "\n",
    "    - 'infer' will attempt to infer fall dst-transition hours based on\n",
    "      order\n",
    "    - bool-ndarray where True signifies a DST time, False signifies a\n",
    "      non-DST time (note that this flag is only applicable for ambiguous\n",
    "      times)\n",
    "    - 'NaT' will return NaT where there are ambiguous times\n",
    "    - 'raise' will raise an AmbiguousTimeError if there are ambiguous times.\n",
    "dayfirst : bool, default False\n",
    "    If True, parse dates in `data` with the day first order.\n",
    "yearfirst : bool, default False\n",
    "    If True parse dates in `data` with the year first order.\n",
    "dtype : numpy.dtype or DatetimeTZDtype or str, default None\n",
    "    Note that the only NumPy dtype allowed is ‘datetime64[ns]’.\n",
    "copy : bool, default False\n",
    "    Make a copy of input ndarray.\n",
    "name : label, default None\n",
    "    Name to be stored in the index.\n",
    "\n",
    "Attributes\n",
    "----------\n",
    "year\n",
    "month\n",
    "day\n",
    "hour\n",
    "minute\n",
    "second\n",
    "microsecond\n",
    "nanosecond\n",
    "date\n",
    "time\n",
    "timetz\n",
    "dayofyear\n",
    "day_of_year\n",
    "weekofyear\n",
    "week\n",
    "dayofweek\n",
    "day_of_week\n",
    "weekday\n",
    "quarter\n",
    "tz\n",
    "freq\n",
    "freqstr\n",
    "is_month_start\n",
    "is_month_end\n",
    "is_quarter_start\n",
    "is_quarter_end\n",
    "is_year_start\n",
    "is_year_end\n",
    "is_leap_year\n",
    "inferred_freq\n",
    "\n",
    "Methods\n",
    "-------\n",
    "normalize\n",
    "strftime\n",
    "snap\n",
    "tz_convert\n",
    "tz_localize\n",
    "round\n",
    "floor\n",
    "ceil\n",
    "to_period\n",
    "to_perioddelta\n",
    "to_pydatetime\n",
    "to_series\n",
    "to_frame\n",
    "month_name\n",
    "day_name\n",
    "mean\n",
    "std\n",
    "\n",
    "See Also\n",
    "--------\n",
    "Index : The base pandas Index type.\n",
    "TimedeltaIndex : Index of timedelta64 data.\n",
    "PeriodIndex : Index of Period data.\n",
    "to_datetime : Convert argument to datetime.\n",
    "date_range : Create a fixed-frequency DatetimeIndex.\n",
    "\n",
    "Notes\n",
    "-----\n",
    "To learn more about the frequency strings, please see `this link\n",
    "<https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases>`__.\n",
    "\n",
    "</code>\n",
    "<a href='#top_phases'>back to header</a>\n",
    "</blockquote>\n",
    "</details>\n",
    "</li>\n",
    "<li>\n",
    "<details><summary style='list-style: none; cursor: pointer;'><u>pandas.core.series.Series</u></summary>\n",
    "<blockquote>\n",
    "<code>\n",
    "One-dimensional ndarray with axis labels (including time series).\n",
    "\n",
    "Labels need not be unique but must be a hashable type. The object\n",
    "supports both integer- and label-based indexing and provides a host of\n",
    "methods for performing operations involving the index. Statistical\n",
    "methods from ndarray have been overridden to automatically exclude\n",
    "missing data (currently represented as NaN).\n",
    "\n",
    "Operations between Series (+, -, /, \\*, \\*\\*) align values based on their\n",
    "associated index values-- they need not be the same length. The result\n",
    "index will be the sorted union of the two indexes.\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "data : array-like, Iterable, dict, or scalar value\n",
    "    Contains data stored in Series. If data is a dict, argument order is\n",
    "    maintained.\n",
    "index : array-like or Index (1d)\n",
    "    Values must be hashable and have the same length as `data`.\n",
    "    Non-unique index values are allowed. Will default to\n",
    "    RangeIndex (0, 1, 2, ..., n) if not provided. If data is dict-like\n",
    "    and index is None, then the keys in the data are used as the index. If the\n",
    "    index is not None, the resulting Series is reindexed with the index values.\n",
    "dtype : str, numpy.dtype, or ExtensionDtype, optional\n",
    "    Data type for the output Series. If not specified, this will be\n",
    "    inferred from `data`.\n",
    "    See the :ref:`user guide <basics.dtypes>` for more usages.\n",
    "name : str, optional\n",
    "    The name to give to the Series.\n",
    "copy : bool, default False\n",
    "    Copy input data. Only affects Series or 1d ndarray input. See examples.\n",
    "\n",
    "Examples\n",
    "--------\n",
    "Constructing Series from a dictionary with an Index specified\n",
    "\n",
    ">>> d = {'a': 1, 'b': 2, 'c': 3}\n",
    ">>> ser = pd.Series(data=d, index=['a', 'b', 'c'])\n",
    ">>> ser\n",
    "a   1\n",
    "b   2\n",
    "c   3\n",
    "dtype: int64\n",
    "\n",
    "The keys of the dictionary match with the Index values, hence the Index\n",
    "values have no effect.\n",
    "\n",
    ">>> d = {'a': 1, 'b': 2, 'c': 3}\n",
    ">>> ser = pd.Series(data=d, index=['x', 'y', 'z'])\n",
    ">>> ser\n",
    "x   NaN\n",
    "y   NaN\n",
    "z   NaN\n",
    "dtype: float64\n",
    "\n",
    "Note that the Index is first build with the keys from the dictionary.\n",
    "After this the Series is reindexed with the given Index values, hence we\n",
    "get all NaN as a result.\n",
    "\n",
    "Constructing Series from a list with `copy=False`.\n",
    "\n",
    ">>> r = [1, 2]\n",
    ">>> ser = pd.Series(r, copy=False)\n",
    ">>> ser.iloc[0] = 999\n",
    ">>> r\n",
    "[1, 2]\n",
    ">>> ser\n",
    "0    999\n",
    "1      2\n",
    "dtype: int64\n",
    "\n",
    "Due to input data type the Series has a `copy` of\n",
    "the original data even though `copy=False`, so\n",
    "the data is unchanged.\n",
    "\n",
    "Constructing Series from a 1d ndarray with `copy=False`.\n",
    "\n",
    ">>> r = np.array([1, 2])\n",
    ">>> ser = pd.Series(r, copy=False)\n",
    ">>> ser.iloc[0] = 999\n",
    ">>> r\n",
    "array([999,   2])\n",
    ">>> ser\n",
    "0    999\n",
    "1      2\n",
    "dtype: int64\n",
    "\n",
    "Due to input data type the Series has a `view` on\n",
    "the original data, so\n",
    "the data is changed as well.\n",
    "\n",
    "</code>\n",
    "<a href='#top_phases'>back to header</a>\n",
    "</blockquote>\n",
    "</details>\n",
    "</li>\n",
    "<li>\n",
    "<details><summary style='list-style: none; cursor: pointer;'><u>pandas.core.series.Series.apply</u></summary>\n",
    "<blockquote>\n",
    "<code>\n",
    "Invoke function on values of Series.\n",
    "\n",
    "Can be ufunc (a NumPy function that applies to the entire Series)\n",
    "or a Python function that only works on single values.\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "func : function\n",
    "    Python function or NumPy ufunc to apply.\n",
    "convert_dtype : bool, default True\n",
    "    Try to find better dtype for elementwise function results. If\n",
    "    False, leave as dtype=object. Note that the dtype is always\n",
    "    preserved for some extension array dtypes, such as Categorical.\n",
    "args : tuple\n",
    "    Positional arguments passed to func after the series value.\n",
    "**kwargs\n",
    "    Additional keyword arguments passed to func.\n",
    "\n",
    "Returns\n",
    "-------\n",
    "Series or DataFrame\n",
    "    If func returns a Series object the result will be a DataFrame.\n",
    "\n",
    "See Also\n",
    "--------\n",
    "Series.map: For element-wise operations.\n",
    "Series.agg: Only perform aggregating type operations.\n",
    "Series.transform: Only perform transforming type operations.\n",
    "\n",
    "Notes\n",
    "-----\n",
    "Functions that mutate the passed object can produce unexpected\n",
    "behavior or errors and are not supported. See :ref:`gotchas.udf-mutation`\n",
    "for more details.\n",
    "\n",
    "Examples\n",
    "--------\n",
    "Create a series with typical summer temperatures for each city.\n",
    "\n",
    ">>> s = pd.Series([20, 21, 12],\n",
    "...               index=['London', 'New York', 'Helsinki'])\n",
    ">>> s\n",
    "London      20\n",
    "New York    21\n",
    "Helsinki    12\n",
    "dtype: int64\n",
    "\n",
    "Square the values by defining a function and passing it as an\n",
    "argument to ``apply()``.\n",
    "\n",
    ">>> def square(x):\n",
    "...     return x ** 2\n",
    ">>> s.apply(square)\n",
    "London      400\n",
    "New York    441\n",
    "Helsinki    144\n",
    "dtype: int64\n",
    "\n",
    "Square the values by passing an anonymous function as an\n",
    "argument to ``apply()``.\n",
    "\n",
    ">>> s.apply(lambda x: x ** 2)\n",
    "London      400\n",
    "New York    441\n",
    "Helsinki    144\n",
    "dtype: int64\n",
    "\n",
    "Define a custom function that needs additional positional\n",
    "arguments and pass these additional arguments using the\n",
    "``args`` keyword.\n",
    "\n",
    ">>> def subtract_custom_value(x, custom_value):\n",
    "...     return x - custom_value\n",
    "\n",
    ">>> s.apply(subtract_custom_value, args=(5,))\n",
    "London      15\n",
    "New York    16\n",
    "Helsinki     7\n",
    "dtype: int64\n",
    "\n",
    "Define a custom function that takes keyword arguments\n",
    "and pass these arguments to ``apply``.\n",
    "\n",
    ">>> def add_custom_values(x, **kwargs):\n",
    "...     for month in kwargs:\n",
    "...         x += kwargs[month]\n",
    "...     return x\n",
    "\n",
    ">>> s.apply(add_custom_values, june=30, july=20, august=25)\n",
    "London      95\n",
    "New York    96\n",
    "Helsinki    87\n",
    "dtype: int64\n",
    "\n",
    "Use a function from the Numpy library.\n",
    "\n",
    ">>> s.apply(np.log)\n",
    "London      2.995732\n",
    "New York    3.044522\n",
    "Helsinki    2.484907\n",
    "dtype: float64\n",
    "\n",
    "</code>\n",
    "<a href='#top_phases'>back to header</a>\n",
    "</blockquote>\n",
    "</details>\n",
    "</li>\n",
    "<li>\n",
    "<details><summary style='list-style: none; cursor: pointer;'><u>pandas.core.tools.datetimes.to_datetime</u></summary>\n",
    "<blockquote>\n",
    "<code>\n",
    "Convert argument to datetime.\n",
    "\n",
    "This function converts a scalar, array-like, :class:`Series` or\n",
    ":class:`DataFrame`/dict-like to a pandas datetime object.\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "arg : int, float, str, datetime, list, tuple, 1-d array, Series, DataFrame/dict-like\n",
    "    The object to convert to a datetime. If a :class:`DataFrame` is provided, the\n",
    "    method expects minimally the following columns: :const:`\"year\"`,\n",
    "    :const:`\"month\"`, :const:`\"day\"`.\n",
    "errors : {'ignore', 'raise', 'coerce'}, default 'raise'\n",
    "    - If :const:`'raise'`, then invalid parsing will raise an exception.\n",
    "    - If :const:`'coerce'`, then invalid parsing will be set as :const:`NaT`.\n",
    "    - If :const:`'ignore'`, then invalid parsing will return the input.\n",
    "dayfirst : bool, default False\n",
    "    Specify a date parse order if `arg` is str or is list-like.\n",
    "    If :const:`True`, parses dates with the day first, e.g. :const:`\"10/11/12\"`\n",
    "    is parsed as :const:`2012-11-10`.\n",
    "\n",
    "    .. warning::\n",
    "\n",
    "        ``dayfirst=True`` is not strict, but will prefer to parse\n",
    "        with day first. If a delimited date string cannot be parsed in\n",
    "        accordance with the given `dayfirst` option, e.g.\n",
    "        ``to_datetime(['31-12-2021'])``, then a warning will be shown.\n",
    "\n",
    "yearfirst : bool, default False\n",
    "    Specify a date parse order if `arg` is str or is list-like.\n",
    "\n",
    "    - If :const:`True` parses dates with the year first, e.g.\n",
    "      :const:`\"10/11/12\"` is parsed as :const:`2010-11-12`.\n",
    "    - If both `dayfirst` and `yearfirst` are :const:`True`, `yearfirst` is\n",
    "      preceded (same as :mod:`dateutil`).\n",
    "\n",
    "    .. warning::\n",
    "\n",
    "        ``yearfirst=True`` is not strict, but will prefer to parse\n",
    "        with year first.\n",
    "\n",
    "utc : bool, default None\n",
    "    Control timezone-related parsing, localization and conversion.\n",
    "\n",
    "    - If :const:`True`, the function *always* returns a timezone-aware\n",
    "      UTC-localized :class:`Timestamp`, :class:`Series` or\n",
    "      :class:`DatetimeIndex`. To do this, timezone-naive inputs are\n",
    "      *localized* as UTC, while timezone-aware inputs are *converted* to UTC.\n",
    "\n",
    "    - If :const:`False` (default), inputs will not be coerced to UTC.\n",
    "      Timezone-naive inputs will remain naive, while timezone-aware ones\n",
    "      will keep their time offsets. Limitations exist for mixed\n",
    "      offsets (typically, daylight savings), see :ref:`Examples\n",
    "      <to_datetime_tz_examples>` section for details.\n",
    "\n",
    "    See also: pandas general documentation about `timezone conversion and\n",
    "    localization\n",
    "    <https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html\n",
    "    #time-zone-handling>`_.\n",
    "\n",
    "format : str, default None\n",
    "    The strftime to parse time, e.g. :const:`\"%d/%m/%Y\"`. Note that\n",
    "    :const:`\"%f\"` will parse all the way up to nanoseconds. See\n",
    "    `strftime documentation\n",
    "    <https://docs.python.org/3/library/datetime.html\n",
    "    #strftime-and-strptime-behavior>`_ for more information on choices.\n",
    "exact : bool, default True\n",
    "    Control how `format` is used:\n",
    "\n",
    "    - If :const:`True`, require an exact `format` match.\n",
    "    - If :const:`False`, allow the `format` to match anywhere in the target\n",
    "      string.\n",
    "\n",
    "unit : str, default 'ns'\n",
    "    The unit of the arg (D,s,ms,us,ns) denote the unit, which is an\n",
    "    integer or float number. This will be based off the origin.\n",
    "    Example, with ``unit='ms'`` and ``origin='unix'`` (the default), this\n",
    "    would calculate the number of milliseconds to the unix epoch start.\n",
    "infer_datetime_format : bool, default False\n",
    "    If :const:`True` and no `format` is given, attempt to infer the format\n",
    "    of the datetime strings based on the first non-NaN element,\n",
    "    and if it can be inferred, switch to a faster method of parsing them.\n",
    "    In some cases this can increase the parsing speed by ~5-10x.\n",
    "origin : scalar, default 'unix'\n",
    "    Define the reference date. The numeric values would be parsed as number\n",
    "    of units (defined by `unit`) since this reference date.\n",
    "\n",
    "    - If :const:`'unix'` (or POSIX) time; origin is set to 1970-01-01.\n",
    "    - If :const:`'julian'`, unit must be :const:`'D'`, and origin is set to\n",
    "      beginning of Julian Calendar. Julian day number :const:`0` is assigned\n",
    "      to the day starting at noon on January 1, 4713 BC.\n",
    "    - If Timestamp convertible, origin is set to Timestamp identified by\n",
    "      origin.\n",
    "cache : bool, default True\n",
    "    If :const:`True`, use a cache of unique, converted dates to apply the\n",
    "    datetime conversion. May produce significant speed-up when parsing\n",
    "    duplicate date strings, especially ones with timezone offsets. The cache\n",
    "    is only used when there are at least 50 values. The presence of\n",
    "    out-of-bounds values will render the cache unusable and may slow down\n",
    "    parsing.\n",
    "\n",
    "    .. versionchanged:: 0.25.0\n",
    "        changed default value from :const:`False` to :const:`True`.\n",
    "\n",
    "Returns\n",
    "-------\n",
    "datetime\n",
    "    If parsing succeeded.\n",
    "    Return type depends on input (types in parenthesis correspond to\n",
    "    fallback in case of unsuccessful timezone or out-of-range timestamp\n",
    "    parsing):\n",
    "\n",
    "    - scalar: :class:`Timestamp` (or :class:`datetime.datetime`)\n",
    "    - array-like: :class:`DatetimeIndex` (or :class:`Series` with\n",
    "      :class:`object` dtype containing :class:`datetime.datetime`)\n",
    "    - Series: :class:`Series` of :class:`datetime64` dtype (or\n",
    "      :class:`Series` of :class:`object` dtype containing\n",
    "      :class:`datetime.datetime`)\n",
    "    - DataFrame: :class:`Series` of :class:`datetime64` dtype (or\n",
    "      :class:`Series` of :class:`object` dtype containing\n",
    "      :class:`datetime.datetime`)\n",
    "\n",
    "Raises\n",
    "------\n",
    "ParserError\n",
    "    When parsing a date from string fails.\n",
    "ValueError\n",
    "    When another datetime conversion error happens. For example when one\n",
    "    of 'year', 'month', day' columns is missing in a :class:`DataFrame`, or\n",
    "    when a Timezone-aware :class:`datetime.datetime` is found in an array-like\n",
    "    of mixed time offsets, and ``utc=False``.\n",
    "\n",
    "See Also\n",
    "--------\n",
    "DataFrame.astype : Cast argument to a specified dtype.\n",
    "to_timedelta : Convert argument to timedelta.\n",
    "convert_dtypes : Convert dtypes.\n",
    "\n",
    "Notes\n",
    "-----\n",
    "\n",
    "Many input types are supported, and lead to different output types:\n",
    "\n",
    "- **scalars** can be int, float, str, datetime object (from stdlib :mod:`datetime`\n",
    "  module or :mod:`numpy`). They are converted to :class:`Timestamp` when\n",
    "  possible, otherwise they are converted to :class:`datetime.datetime`.\n",
    "  None/NaN/null scalars are converted to :const:`NaT`.\n",
    "\n",
    "- **array-like** can contain int, float, str, datetime objects. They are\n",
    "  converted to :class:`DatetimeIndex` when possible, otherwise they are\n",
    "  converted to :class:`Index` with :class:`object` dtype, containing\n",
    "  :class:`datetime.datetime`. None/NaN/null entries are converted to\n",
    "  :const:`NaT` in both cases.\n",
    "\n",
    "- **Series** are converted to :class:`Series` with :class:`datetime64`\n",
    "  dtype when possible, otherwise they are converted to :class:`Series` with\n",
    "  :class:`object` dtype, containing :class:`datetime.datetime`. None/NaN/null\n",
    "  entries are converted to :const:`NaT` in both cases.\n",
    "\n",
    "- **DataFrame/dict-like** are converted to :class:`Series` with\n",
    "  :class:`datetime64` dtype. For each row a datetime is created from assembling\n",
    "  the various dataframe columns. Column keys can be common abbreviations\n",
    "  like [‘year’, ‘month’, ‘day’, ‘minute’, ‘second’, ‘ms’, ‘us’, ‘ns’]) or\n",
    "  plurals of the same.\n",
    "\n",
    "The following causes are responsible for :class:`datetime.datetime` objects\n",
    "being returned (possibly inside an :class:`Index` or a :class:`Series` with\n",
    ":class:`object` dtype) instead of a proper pandas designated type\n",
    "(:class:`Timestamp`, :class:`DatetimeIndex` or :class:`Series`\n",
    "with :class:`datetime64` dtype):\n",
    "\n",
    "- when any input element is before :const:`Timestamp.min` or after\n",
    "  :const:`Timestamp.max`, see `timestamp limitations\n",
    "  <https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html\n",
    "  #timeseries-timestamp-limits>`_.\n",
    "\n",
    "- when ``utc=False`` (default) and the input is an array-like or\n",
    "  :class:`Series` containing mixed naive/aware datetime, or aware with mixed\n",
    "  time offsets. Note that this happens in the (quite frequent) situation when\n",
    "  the timezone has a daylight savings policy. In that case you may wish to\n",
    "  use ``utc=True``.\n",
    "\n",
    "Examples\n",
    "--------\n",
    "\n",
    "**Handling various input formats**\n",
    "\n",
    "Assembling a datetime from multiple columns of a :class:`DataFrame`. The keys\n",
    "can be common abbreviations like ['year', 'month', 'day', 'minute', 'second',\n",
    "'ms', 'us', 'ns']) or plurals of the same\n",
    "\n",
    ">>> df = pd.DataFrame({'year': [2015, 2016],\n",
    "...                    'month': [2, 3],\n",
    "...                    'day': [4, 5]})\n",
    ">>> pd.to_datetime(df)\n",
    "0   2015-02-04\n",
    "1   2016-03-05\n",
    "dtype: datetime64[ns]\n",
    "\n",
    "Passing ``infer_datetime_format=True`` can often-times speedup a parsing\n",
    "if its not an ISO8601 format exactly, but in a regular format.\n",
    "\n",
    ">>> s = pd.Series(['3/11/2000', '3/12/2000', '3/13/2000'] * 1000)\n",
    ">>> s.head()\n",
    "0    3/11/2000\n",
    "1    3/12/2000\n",
    "2    3/13/2000\n",
    "3    3/11/2000\n",
    "4    3/12/2000\n",
    "dtype: object\n",
    "\n",
    ">>> %timeit pd.to_datetime(s, infer_datetime_format=True)  # doctest: +SKIP\n",
    "100 loops, best of 3: 10.4 ms per loop\n",
    "\n",
    ">>> %timeit pd.to_datetime(s, infer_datetime_format=False)  # doctest: +SKIP\n",
    "1 loop, best of 3: 471 ms per loop\n",
    "\n",
    "Using a unix epoch time\n",
    "\n",
    ">>> pd.to_datetime(1490195805, unit='s')\n",
    "Timestamp('2017-03-22 15:16:45')\n",
    ">>> pd.to_datetime(1490195805433502912, unit='ns')\n",
    "Timestamp('2017-03-22 15:16:45.433502912')\n",
    "\n",
    ".. warning:: For float arg, precision rounding might happen. To prevent\n",
    "    unexpected behavior use a fixed-width exact type.\n",
    "\n",
    "Using a non-unix epoch origin\n",
    "\n",
    ">>> pd.to_datetime([1, 2, 3], unit='D',\n",
    "...                origin=pd.Timestamp('1960-01-01'))\n",
    "DatetimeIndex(['1960-01-02', '1960-01-03', '1960-01-04'],\n",
    "              dtype='datetime64[ns]', freq=None)\n",
    "\n",
    "**Non-convertible date/times**\n",
    "\n",
    "If a date does not meet the `timestamp limitations\n",
    "<https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html\n",
    "timeseries-timestamp-limits>`_, passing ``errors='ignore'``\n",
    "will return the original input instead of raising any exception.\n",
    "\n",
    "Passing ``errors='coerce'`` will force an out-of-bounds date to :const:`NaT`,\n",
    "in addition to forcing non-dates (or non-parseable dates) to :const:`NaT`.\n",
    "\n",
    ">>> pd.to_datetime('13000101', format='%Y%m%d', errors='ignore')\n",
    "datetime.datetime(1300, 1, 1, 0, 0)\n",
    ">>> pd.to_datetime('13000101', format='%Y%m%d', errors='coerce')\n",
    "NaT\n",
    "\n",
    ".. _to_datetime_tz_examples:\n",
    "\n",
    "**Timezones and time offsets**\n",
    "\n",
    "The default behaviour (``utc=False``) is as follows:\n",
    "\n",
    "- Timezone-naive inputs are converted to timezone-naive :class:`DatetimeIndex`:\n",
    "\n",
    ">>> pd.to_datetime(['2018-10-26 12:00', '2018-10-26 13:00:15'])\n",
    "DatetimeIndex(['2018-10-26 12:00:00', '2018-10-26 13:00:15'],\n",
    "              dtype='datetime64[ns]', freq=None)\n",
    "\n",
    "- Timezone-aware inputs *with constant time offset* are converted to\n",
    "  timezone-aware :class:`DatetimeIndex`:\n",
    "\n",
    ">>> pd.to_datetime(['2018-10-26 12:00 -0500', '2018-10-26 13:00 -0500'])\n",
    "DatetimeIndex(['2018-10-26 12:00:00-05:00', '2018-10-26 13:00:00-05:00'],\n",
    "              dtype='datetime64[ns, pytz.FixedOffset(-300)]', freq=None)\n",
    "\n",
    "- However, timezone-aware inputs *with mixed time offsets* (for example\n",
    "  issued from a timezone with daylight savings, such as Europe/Paris)\n",
    "  are **not successfully converted** to a :class:`DatetimeIndex`. Instead a\n",
    "  simple :class:`Index` containing :class:`datetime.datetime` objects is\n",
    "  returned:\n",
    "\n",
    ">>> pd.to_datetime(['2020-10-25 02:00 +0200', '2020-10-25 04:00 +0100'])\n",
    "Index([2020-10-25 02:00:00+02:00, 2020-10-25 04:00:00+01:00],\n",
    "      dtype='object')\n",
    "\n",
    "- A mix of timezone-aware and timezone-naive inputs is converted to\n",
    "  a timezone-aware :class:`DatetimeIndex` if the offsets of the timezone-aware\n",
    "  are constant:\n",
    "\n",
    ">>> from datetime import datetime\n",
    ">>> pd.to_datetime([\"2020-01-01 01:00 -01:00\", datetime(2020, 1, 1, 3, 0)])\n",
    "DatetimeIndex(['2020-01-01 01:00:00-01:00', '2020-01-01 02:00:00-01:00'],\n",
    "              dtype='datetime64[ns, pytz.FixedOffset(-60)]', freq=None)\n",
    "\n",
    "- Finally, mixing timezone-aware strings and :class:`datetime.datetime` always\n",
    "  raises an error, even if the elements all have the same time offset.\n",
    "\n",
    ">>> from datetime import datetime, timezone, timedelta\n",
    ">>> d = datetime(2020, 1, 1, 18, tzinfo=timezone(-timedelta(hours=1)))\n",
    ">>> pd.to_datetime([\"2020-01-01 17:00 -0100\", d])\n",
    "Traceback (most recent call last):\n",
    "    ...\n",
    "ValueError: Tz-aware datetime.datetime cannot be converted to datetime64\n",
    "            unless utc=True\n",
    "\n",
    "|\n",
    "\n",
    "Setting ``utc=True`` solves most of the above issues:\n",
    "\n",
    "- Timezone-naive inputs are *localized* as UTC\n",
    "\n",
    ">>> pd.to_datetime(['2018-10-26 12:00', '2018-10-26 13:00'], utc=True)\n",
    "DatetimeIndex(['2018-10-26 12:00:00+00:00', '2018-10-26 13:00:00+00:00'],\n",
    "              dtype='datetime64[ns, UTC]', freq=None)\n",
    "\n",
    "- Timezone-aware inputs are *converted* to UTC (the output represents the\n",
    "  exact same datetime, but viewed from the UTC time offset `+00:00`).\n",
    "\n",
    ">>> pd.to_datetime(['2018-10-26 12:00 -0530', '2018-10-26 12:00 -0500'],\n",
    "...                utc=True)\n",
    "DatetimeIndex(['2018-10-26 17:30:00+00:00', '2018-10-26 17:00:00+00:00'],\n",
    "              dtype='datetime64[ns, UTC]', freq=None)\n",
    "\n",
    "- Inputs can contain both naive and aware, string or datetime, the above\n",
    "  rules still apply\n",
    "\n",
    ">>> pd.to_datetime(['2018-10-26 12:00', '2018-10-26 12:00 -0530',\n",
    "...                datetime(2020, 1, 1, 18),\n",
    "...                datetime(2020, 1, 1, 18,\n",
    "...                tzinfo=timezone(-timedelta(hours=1)))],\n",
    "...                utc=True)\n",
    "DatetimeIndex(['2018-10-26 12:00:00+00:00', '2018-10-26 17:30:00+00:00',\n",
    "               '2020-01-01 18:00:00+00:00', '2020-01-01 19:00:00+00:00'],\n",
    "              dtype='datetime64[ns, UTC]', freq=None)\n",
    "\n",
    "</code>\n",
    "<a href='#top_phases'>back to header</a>\n",
    "</blockquote>\n",
    "</details>\n",
    "</li>\n",
    "<li>\n",
    "<details><summary style='list-style: none; cursor: pointer;'><u>pandas.io.parsers.readers.read_csv</u></summary>\n",
    "<blockquote>\n",
    "<code>\n",
    "Read a comma-separated values (csv) file into DataFrame.\n",
    "\n",
    "Also supports optionally iterating or breaking of the file\n",
    "into chunks.\n",
    "\n",
    "Additional help can be found in the online docs for\n",
    "`IO Tools <https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html>`_.\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "filepath_or_buffer : str, path object or file-like object\n",
    "    Any valid string path is acceptable. The string could be a URL. Valid\n",
    "    URL schemes include http, ftp, s3, gs, and file. For file URLs, a host is\n",
    "    expected. A local file could be: file://localhost/path/to/table.csv.\n",
    "\n",
    "    If you want to pass in a path object, pandas accepts any ``os.PathLike``.\n",
    "\n",
    "    By file-like object, we refer to objects with a ``read()`` method, such as\n",
    "    a file handle (e.g. via builtin ``open`` function) or ``StringIO``.\n",
    "sep : str, default ','\n",
    "    Delimiter to use. If sep is None, the C engine cannot automatically detect\n",
    "    the separator, but the Python parsing engine can, meaning the latter will\n",
    "    be used and automatically detect the separator by Python's builtin sniffer\n",
    "    tool, ``csv.Sniffer``. In addition, separators longer than 1 character and\n",
    "    different from ``'\\s+'`` will be interpreted as regular expressions and\n",
    "    will also force the use of the Python parsing engine. Note that regex\n",
    "    delimiters are prone to ignoring quoted data. Regex example: ``'\\r\\t'``.\n",
    "delimiter : str, default ``None``\n",
    "    Alias for sep.\n",
    "header : int, list of int, None, default 'infer'\n",
    "    Row number(s) to use as the column names, and the start of the\n",
    "    data.  Default behavior is to infer the column names: if no names\n",
    "    are passed the behavior is identical to ``header=0`` and column\n",
    "    names are inferred from the first line of the file, if column\n",
    "    names are passed explicitly then the behavior is identical to\n",
    "    ``header=None``. Explicitly pass ``header=0`` to be able to\n",
    "    replace existing names. The header can be a list of integers that\n",
    "    specify row locations for a multi-index on the columns\n",
    "    e.g. [0,1,3]. Intervening rows that are not specified will be\n",
    "    skipped (e.g. 2 in this example is skipped). Note that this\n",
    "    parameter ignores commented lines and empty lines if\n",
    "    ``skip_blank_lines=True``, so ``header=0`` denotes the first line of\n",
    "    data rather than the first line of the file.\n",
    "names : array-like, optional\n",
    "    List of column names to use. If the file contains a header row,\n",
    "    then you should explicitly pass ``header=0`` to override the column names.\n",
    "    Duplicates in this list are not allowed.\n",
    "index_col : int, str, sequence of int / str, or False, optional, default ``None``\n",
    "  Column(s) to use as the row labels of the ``DataFrame``, either given as\n",
    "  string name or column index. If a sequence of int / str is given, a\n",
    "  MultiIndex is used.\n",
    "\n",
    "  Note: ``index_col=False`` can be used to force pandas to *not* use the first\n",
    "  column as the index, e.g. when you have a malformed file with delimiters at\n",
    "  the end of each line.\n",
    "usecols : list-like or callable, optional\n",
    "    Return a subset of the columns. If list-like, all elements must either\n",
    "    be positional (i.e. integer indices into the document columns) or strings\n",
    "    that correspond to column names provided either by the user in `names` or\n",
    "    inferred from the document header row(s). If ``names`` are given, the document\n",
    "    header row(s) are not taken into account. For example, a valid list-like\n",
    "    `usecols` parameter would be ``[0, 1, 2]`` or ``['foo', 'bar', 'baz']``.\n",
    "    Element order is ignored, so ``usecols=[0, 1]`` is the same as ``[1, 0]``.\n",
    "    To instantiate a DataFrame from ``data`` with element order preserved use\n",
    "    ``pd.read_csv(data, usecols=['foo', 'bar'])[['foo', 'bar']]`` for columns\n",
    "    in ``['foo', 'bar']`` order or\n",
    "    ``pd.read_csv(data, usecols=['foo', 'bar'])[['bar', 'foo']]``\n",
    "    for ``['bar', 'foo']`` order.\n",
    "\n",
    "    If callable, the callable function will be evaluated against the column\n",
    "    names, returning names where the callable function evaluates to True. An\n",
    "    example of a valid callable argument would be ``lambda x: x.upper() in\n",
    "    ['AAA', 'BBB', 'DDD']``. Using this parameter results in much faster\n",
    "    parsing time and lower memory usage.\n",
    "squeeze : bool, default False\n",
    "    If the parsed data only contains one column then return a Series.\n",
    "\n",
    "    .. deprecated:: 1.4.0\n",
    "        Append ``.squeeze(\"columns\")`` to the call to ``read_csv`` to squeeze\n",
    "        the data.\n",
    "prefix : str, optional\n",
    "    Prefix to add to column numbers when no header, e.g. 'X' for X0, X1, ...\n",
    "\n",
    "    .. deprecated:: 1.4.0\n",
    "       Use a list comprehension on the DataFrame's columns after calling ``read_csv``.\n",
    "mangle_dupe_cols : bool, default True\n",
    "    Duplicate columns will be specified as 'X', 'X.1', ...'X.N', rather than\n",
    "    'X'...'X'. Passing in False will cause data to be overwritten if there\n",
    "    are duplicate names in the columns.\n",
    "dtype : Type name or dict of column -> type, optional\n",
    "    Data type for data or columns. E.g. {'a': np.float64, 'b': np.int32,\n",
    "    'c': 'Int64'}\n",
    "    Use `str` or `object` together with suitable `na_values` settings\n",
    "    to preserve and not interpret dtype.\n",
    "    If converters are specified, they will be applied INSTEAD\n",
    "    of dtype conversion.\n",
    "engine : {'c', 'python', 'pyarrow'}, optional\n",
    "    Parser engine to use. The C and pyarrow engines are faster, while the python engine\n",
    "    is currently more feature-complete. Multithreading is currently only supported by\n",
    "    the pyarrow engine.\n",
    "\n",
    "    .. versionadded:: 1.4.0\n",
    "\n",
    "        The \"pyarrow\" engine was added as an *experimental* engine, and some features\n",
    "        are unsupported, or may not work correctly, with this engine.\n",
    "converters : dict, optional\n",
    "    Dict of functions for converting values in certain columns. Keys can either\n",
    "    be integers or column labels.\n",
    "true_values : list, optional\n",
    "    Values to consider as True.\n",
    "false_values : list, optional\n",
    "    Values to consider as False.\n",
    "skipinitialspace : bool, default False\n",
    "    Skip spaces after delimiter.\n",
    "skiprows : list-like, int or callable, optional\n",
    "    Line numbers to skip (0-indexed) or number of lines to skip (int)\n",
    "    at the start of the file.\n",
    "\n",
    "    If callable, the callable function will be evaluated against the row\n",
    "    indices, returning True if the row should be skipped and False otherwise.\n",
    "    An example of a valid callable argument would be ``lambda x: x in [0, 2]``.\n",
    "skipfooter : int, default 0\n",
    "    Number of lines at bottom of file to skip (Unsupported with engine='c').\n",
    "nrows : int, optional\n",
    "    Number of rows of file to read. Useful for reading pieces of large files.\n",
    "na_values : scalar, str, list-like, or dict, optional\n",
    "    Additional strings to recognize as NA/NaN. If dict passed, specific\n",
    "    per-column NA values.  By default the following values are interpreted as\n",
    "    NaN: '', '#N/A', '#N/A N/A', '#NA', '-1.#IND', '-1.#QNAN', '-NaN', '-nan',\n",
    "    '1.#IND', '1.#QNAN', '<NA>', 'N/A', 'NA', 'NULL', 'NaN', 'n/a',\n",
    "    'nan', 'null'.\n",
    "keep_default_na : bool, default True\n",
    "    Whether or not to include the default NaN values when parsing the data.\n",
    "    Depending on whether `na_values` is passed in, the behavior is as follows:\n",
    "\n",
    "    * If `keep_default_na` is True, and `na_values` are specified, `na_values`\n",
    "      is appended to the default NaN values used for parsing.\n",
    "    * If `keep_default_na` is True, and `na_values` are not specified, only\n",
    "      the default NaN values are used for parsing.\n",
    "    * If `keep_default_na` is False, and `na_values` are specified, only\n",
    "      the NaN values specified `na_values` are used for parsing.\n",
    "    * If `keep_default_na` is False, and `na_values` are not specified, no\n",
    "      strings will be parsed as NaN.\n",
    "\n",
    "    Note that if `na_filter` is passed in as False, the `keep_default_na` and\n",
    "    `na_values` parameters will be ignored.\n",
    "na_filter : bool, default True\n",
    "    Detect missing value markers (empty strings and the value of na_values). In\n",
    "    data without any NAs, passing na_filter=False can improve the performance\n",
    "    of reading a large file.\n",
    "verbose : bool, default False\n",
    "    Indicate number of NA values placed in non-numeric columns.\n",
    "skip_blank_lines : bool, default True\n",
    "    If True, skip over blank lines rather than interpreting as NaN values.\n",
    "parse_dates : bool or list of int or names or list of lists or dict, default False\n",
    "    The behavior is as follows:\n",
    "\n",
    "    * boolean. If True -> try parsing the index.\n",
    "    * list of int or names. e.g. If [1, 2, 3] -> try parsing columns 1, 2, 3\n",
    "      each as a separate date column.\n",
    "    * list of lists. e.g.  If [[1, 3]] -> combine columns 1 and 3 and parse as\n",
    "      a single date column.\n",
    "    * dict, e.g. {'foo' : [1, 3]} -> parse columns 1, 3 as date and call\n",
    "      result 'foo'\n",
    "\n",
    "    If a column or index cannot be represented as an array of datetimes,\n",
    "    say because of an unparsable value or a mixture of timezones, the column\n",
    "    or index will be returned unaltered as an object data type. For\n",
    "    non-standard datetime parsing, use ``pd.to_datetime`` after\n",
    "    ``pd.read_csv``. To parse an index or column with a mixture of timezones,\n",
    "    specify ``date_parser`` to be a partially-applied\n",
    "    :func:`pandas.to_datetime` with ``utc=True``. See\n",
    "    :ref:`io.csv.mixed_timezones` for more.\n",
    "\n",
    "    Note: A fast-path exists for iso8601-formatted dates.\n",
    "infer_datetime_format : bool, default False\n",
    "    If True and `parse_dates` is enabled, pandas will attempt to infer the\n",
    "    format of the datetime strings in the columns, and if it can be inferred,\n",
    "    switch to a faster method of parsing them. In some cases this can increase\n",
    "    the parsing speed by 5-10x.\n",
    "keep_date_col : bool, default False\n",
    "    If True and `parse_dates` specifies combining multiple columns then\n",
    "    keep the original columns.\n",
    "date_parser : function, optional\n",
    "    Function to use for converting a sequence of string columns to an array of\n",
    "    datetime instances. The default uses ``dateutil.parser.parser`` to do the\n",
    "    conversion. Pandas will try to call `date_parser` in three different ways,\n",
    "    advancing to the next if an exception occurs: 1) Pass one or more arrays\n",
    "    (as defined by `parse_dates`) as arguments; 2) concatenate (row-wise) the\n",
    "    string values from the columns defined by `parse_dates` into a single array\n",
    "    and pass that; and 3) call `date_parser` once for each row using one or\n",
    "    more strings (corresponding to the columns defined by `parse_dates`) as\n",
    "    arguments.\n",
    "dayfirst : bool, default False\n",
    "    DD/MM format dates, international and European format.\n",
    "cache_dates : bool, default True\n",
    "    If True, use a cache of unique, converted dates to apply the datetime\n",
    "    conversion. May produce significant speed-up when parsing duplicate\n",
    "    date strings, especially ones with timezone offsets.\n",
    "\n",
    "    .. versionadded:: 0.25.0\n",
    "iterator : bool, default False\n",
    "    Return TextFileReader object for iteration or getting chunks with\n",
    "    ``get_chunk()``.\n",
    "\n",
    "    .. versionchanged:: 1.2\n",
    "\n",
    "       ``TextFileReader`` is a context manager.\n",
    "chunksize : int, optional\n",
    "    Return TextFileReader object for iteration.\n",
    "    See the `IO Tools docs\n",
    "    <https://pandas.pydata.org/pandas-docs/stable/io.html#io-chunking>`_\n",
    "    for more information on ``iterator`` and ``chunksize``.\n",
    "\n",
    "    .. versionchanged:: 1.2\n",
    "\n",
    "       ``TextFileReader`` is a context manager.\n",
    "compression : str or dict, default 'infer'\n",
    "    For on-the-fly decompression of on-disk data. If 'infer' and '%s' is\n",
    "    path-like, then detect compression from the following extensions: '.gz',\n",
    "    '.bz2', '.zip', '.xz', or '.zst' (otherwise no compression). If using\n",
    "    'zip', the ZIP file must contain only one data file to be read in. Set to\n",
    "    ``None`` for no decompression. Can also be a dict with key ``'method'`` set\n",
    "    to one of {``'zip'``, ``'gzip'``, ``'bz2'``, ``'zstd'``} and other\n",
    "    key-value pairs are forwarded to ``zipfile.ZipFile``, ``gzip.GzipFile``,\n",
    "    ``bz2.BZ2File``, or ``zstandard.ZstdDecompressor``, respectively. As an\n",
    "    example, the following could be passed for Zstandard decompression using a\n",
    "    custom compression dictionary:\n",
    "    ``compression={'method': 'zstd', 'dict_data': my_compression_dict}``.\n",
    "\n",
    "    .. versionchanged:: 1.4.0 Zstandard support.\n",
    "\n",
    "thousands : str, optional\n",
    "    Thousands separator.\n",
    "decimal : str, default '.'\n",
    "    Character to recognize as decimal point (e.g. use ',' for European data).\n",
    "lineterminator : str (length 1), optional\n",
    "    Character to break file into lines. Only valid with C parser.\n",
    "quotechar : str (length 1), optional\n",
    "    The character used to denote the start and end of a quoted item. Quoted\n",
    "    items can include the delimiter and it will be ignored.\n",
    "quoting : int or csv.QUOTE_* instance, default 0\n",
    "    Control field quoting behavior per ``csv.QUOTE_*`` constants. Use one of\n",
    "    QUOTE_MINIMAL (0), QUOTE_ALL (1), QUOTE_NONNUMERIC (2) or QUOTE_NONE (3).\n",
    "doublequote : bool, default ``True``\n",
    "   When quotechar is specified and quoting is not ``QUOTE_NONE``, indicate\n",
    "   whether or not to interpret two consecutive quotechar elements INSIDE a\n",
    "   field as a single ``quotechar`` element.\n",
    "escapechar : str (length 1), optional\n",
    "    One-character string used to escape other characters.\n",
    "comment : str, optional\n",
    "    Indicates remainder of line should not be parsed. If found at the beginning\n",
    "    of a line, the line will be ignored altogether. This parameter must be a\n",
    "    single character. Like empty lines (as long as ``skip_blank_lines=True``),\n",
    "    fully commented lines are ignored by the parameter `header` but not by\n",
    "    `skiprows`. For example, if ``comment='#'``, parsing\n",
    "    ``#empty\\na,b,c\\n1,2,3`` with ``header=0`` will result in 'a,b,c' being\n",
    "    treated as the header.\n",
    "encoding : str, optional\n",
    "    Encoding to use for UTF when reading/writing (ex. 'utf-8'). `List of Python\n",
    "    standard encodings\n",
    "    <https://docs.python.org/3/library/codecs.html#standard-encodings>`_ .\n",
    "\n",
    "    .. versionchanged:: 1.2\n",
    "\n",
    "       When ``encoding`` is ``None``, ``errors=\"replace\"`` is passed to\n",
    "       ``open()``. Otherwise, ``errors=\"strict\"`` is passed to ``open()``.\n",
    "       This behavior was previously only the case for ``engine=\"python\"``.\n",
    "\n",
    "    .. versionchanged:: 1.3.0\n",
    "\n",
    "       ``encoding_errors`` is a new argument. ``encoding`` has no longer an\n",
    "       influence on how encoding errors are handled.\n",
    "\n",
    "encoding_errors : str, optional, default \"strict\"\n",
    "    How encoding errors are treated. `List of possible values\n",
    "    <https://docs.python.org/3/library/codecs.html#error-handlers>`_ .\n",
    "\n",
    "    .. versionadded:: 1.3.0\n",
    "\n",
    "dialect : str or csv.Dialect, optional\n",
    "    If provided, this parameter will override values (default or not) for the\n",
    "    following parameters: `delimiter`, `doublequote`, `escapechar`,\n",
    "    `skipinitialspace`, `quotechar`, and `quoting`. If it is necessary to\n",
    "    override values, a ParserWarning will be issued. See csv.Dialect\n",
    "    documentation for more details.\n",
    "error_bad_lines : bool, optional, default ``None``\n",
    "    Lines with too many fields (e.g. a csv line with too many commas) will by\n",
    "    default cause an exception to be raised, and no DataFrame will be returned.\n",
    "    If False, then these \"bad lines\" will be dropped from the DataFrame that is\n",
    "    returned.\n",
    "\n",
    "    .. deprecated:: 1.3.0\n",
    "       The ``on_bad_lines`` parameter should be used instead to specify behavior upon\n",
    "       encountering a bad line instead.\n",
    "warn_bad_lines : bool, optional, default ``None``\n",
    "    If error_bad_lines is False, and warn_bad_lines is True, a warning for each\n",
    "    \"bad line\" will be output.\n",
    "\n",
    "    .. deprecated:: 1.3.0\n",
    "       The ``on_bad_lines`` parameter should be used instead to specify behavior upon\n",
    "       encountering a bad line instead.\n",
    "on_bad_lines : {'error', 'warn', 'skip'} or callable, default 'error'\n",
    "    Specifies what to do upon encountering a bad line (a line with too many fields).\n",
    "    Allowed values are :\n",
    "\n",
    "        - 'error', raise an Exception when a bad line is encountered.\n",
    "        - 'warn', raise a warning when a bad line is encountered and skip that line.\n",
    "        - 'skip', skip bad lines without raising or warning when they are encountered.\n",
    "\n",
    "    .. versionadded:: 1.3.0\n",
    "\n",
    "        - callable, function with signature\n",
    "          ``(bad_line: list[str]) -> list[str] | None`` that will process a single\n",
    "          bad line. ``bad_line`` is a list of strings split by the ``sep``.\n",
    "          If the function returns ``None``, the bad line will be ignored.\n",
    "          If the function returns a new list of strings with more elements than\n",
    "          expected, a ``ParserWarning`` will be emitted while dropping extra elements.\n",
    "          Only supported when ``engine=\"python\"``\n",
    "\n",
    "    .. versionadded:: 1.4.0\n",
    "\n",
    "delim_whitespace : bool, default False\n",
    "    Specifies whether or not whitespace (e.g. ``' '`` or ``'    '``) will be\n",
    "    used as the sep. Equivalent to setting ``sep='\\s+'``. If this option\n",
    "    is set to True, nothing should be passed in for the ``delimiter``\n",
    "    parameter.\n",
    "low_memory : bool, default True\n",
    "    Internally process the file in chunks, resulting in lower memory use\n",
    "    while parsing, but possibly mixed type inference.  To ensure no mixed\n",
    "    types either set False, or specify the type with the `dtype` parameter.\n",
    "    Note that the entire file is read into a single DataFrame regardless,\n",
    "    use the `chunksize` or `iterator` parameter to return the data in chunks.\n",
    "    (Only valid with C parser).\n",
    "memory_map : bool, default False\n",
    "    If a filepath is provided for `filepath_or_buffer`, map the file object\n",
    "    directly onto memory and access the data directly from there. Using this\n",
    "    option can improve performance because there is no longer any I/O overhead.\n",
    "float_precision : str, optional\n",
    "    Specifies which converter the C engine should use for floating-point\n",
    "    values. The options are ``None`` or 'high' for the ordinary converter,\n",
    "    'legacy' for the original lower precision pandas converter, and\n",
    "    'round_trip' for the round-trip converter.\n",
    "\n",
    "    .. versionchanged:: 1.2\n",
    "\n",
    "storage_options : dict, optional\n",
    "    Extra options that make sense for a particular storage connection, e.g.\n",
    "    host, port, username, password, etc. For HTTP(S) URLs the key-value pairs\n",
    "    are forwarded to ``urllib`` as header options. For other URLs (e.g.\n",
    "    starting with \"s3://\", and \"gcs://\") the key-value pairs are forwarded to\n",
    "    ``fsspec``. Please see ``fsspec`` and ``urllib`` for more details.\n",
    "\n",
    "    .. versionadded:: 1.2\n",
    "\n",
    "Returns\n",
    "-------\n",
    "DataFrame or TextParser\n",
    "    A comma-separated values (csv) file is returned as two-dimensional\n",
    "    data structure with labeled axes.\n",
    "\n",
    "See Also\n",
    "--------\n",
    "DataFrame.to_csv : Write DataFrame to a comma-separated values (csv) file.\n",
    "read_csv : Read a comma-separated values (csv) file into DataFrame.\n",
    "read_fwf : Read a table of fixed-width formatted lines into DataFrame.\n",
    "\n",
    "Examples\n",
    "--------\n",
    ">>> pd.read_csv('data.csv')  # doctest: +SKIP\n",
    "\n",
    "</code>\n",
    "<a href='#top_phases'>back to header</a>\n",
    "</blockquote>\n",
    "</details>\n",
    "</li>\n",
    "</ul>\n",
    "</li>\n",
    "\n",
    "</ul>\n",
    "</details>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a85429a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<div> <h3 class='hg'>1. Data Preparation | Library Loading</h3>  <a id='1'></a><small><a href='#top_phases'>back to top</a></small><details><summary style='list-style: none; cursor: pointer;'><u>View function calls</u></summary>\n",
    "<ul>\n",
    "\n",
    "<li> <strong class='hglib'>pandas</strong>\n",
    "<ul>\n",
    "<li>\n",
    "<details><summary style='list-style: none; cursor: pointer;'><u>pandas.io.parsers.readers.read_csv</u></summary>\n",
    "<blockquote>\n",
    "<code>\n",
    "Read a comma-separated values (csv) file into DataFrame.\n",
    "\n",
    "Also supports optionally iterating or breaking of the file\n",
    "into chunks.\n",
    "\n",
    "Additional help can be found in the online docs for\n",
    "`IO Tools <https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html>`_.\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "filepath_or_buffer : str, path object or file-like object\n",
    "    Any valid string path is acceptable. The string could be a URL. Valid\n",
    "    URL schemes include http, ftp, s3, gs, and file. For file URLs, a host is\n",
    "    expected. A local file could be: file://localhost/path/to/table.csv.\n",
    "\n",
    "    If you want to pass in a path object, pandas accepts any ``os.PathLike``.\n",
    "\n",
    "    By file-like object, we refer to objects with a ``read()`` method, such as\n",
    "    a file handle (e.g. via builtin ``open`` function) or ``StringIO``.\n",
    "sep : str, default ','\n",
    "    Delimiter to use. If sep is None, the C engine cannot automatically detect\n",
    "    the separator, but the Python parsing engine can, meaning the latter will\n",
    "    be used and automatically detect the separator by Python's builtin sniffer\n",
    "    tool, ``csv.Sniffer``. In addition, separators longer than 1 character and\n",
    "    different from ``'\\s+'`` will be interpreted as regular expressions and\n",
    "    will also force the use of the Python parsing engine. Note that regex\n",
    "    delimiters are prone to ignoring quoted data. Regex example: ``'\\r\\t'``.\n",
    "delimiter : str, default ``None``\n",
    "    Alias for sep.\n",
    "header : int, list of int, None, default 'infer'\n",
    "    Row number(s) to use as the column names, and the start of the\n",
    "    data.  Default behavior is to infer the column names: if no names\n",
    "    are passed the behavior is identical to ``header=0`` and column\n",
    "    names are inferred from the first line of the file, if column\n",
    "    names are passed explicitly then the behavior is identical to\n",
    "    ``header=None``. Explicitly pass ``header=0`` to be able to\n",
    "    replace existing names. The header can be a list of integers that\n",
    "    specify row locations for a multi-index on the columns\n",
    "    e.g. [0,1,3]. Intervening rows that are not specified will be\n",
    "    skipped (e.g. 2 in this example is skipped). Note that this\n",
    "    parameter ignores commented lines and empty lines if\n",
    "    ``skip_blank_lines=True``, so ``header=0`` denotes the first line of\n",
    "    data rather than the first line of the file.\n",
    "names : array-like, optional\n",
    "    List of column names to use. If the file contains a header row,\n",
    "    then you should explicitly pass ``header=0`` to override the column names.\n",
    "    Duplicates in this list are not allowed.\n",
    "index_col : int, str, sequence of int / str, or False, optional, default ``None``\n",
    "  Column(s) to use as the row labels of the ``DataFrame``, either given as\n",
    "  string name or column index. If a sequence of int / str is given, a\n",
    "  MultiIndex is used.\n",
    "\n",
    "  Note: ``index_col=False`` can be used to force pandas to *not* use the first\n",
    "  column as the index, e.g. when you have a malformed file with delimiters at\n",
    "  the end of each line.\n",
    "usecols : list-like or callable, optional\n",
    "    Return a subset of the columns. If list-like, all elements must either\n",
    "    be positional (i.e. integer indices into the document columns) or strings\n",
    "    that correspond to column names provided either by the user in `names` or\n",
    "    inferred from the document header row(s). If ``names`` are given, the document\n",
    "    header row(s) are not taken into account. For example, a valid list-like\n",
    "    `usecols` parameter would be ``[0, 1, 2]`` or ``['foo', 'bar', 'baz']``.\n",
    "    Element order is ignored, so ``usecols=[0, 1]`` is the same as ``[1, 0]``.\n",
    "    To instantiate a DataFrame from ``data`` with element order preserved use\n",
    "    ``pd.read_csv(data, usecols=['foo', 'bar'])[['foo', 'bar']]`` for columns\n",
    "    in ``['foo', 'bar']`` order or\n",
    "    ``pd.read_csv(data, usecols=['foo', 'bar'])[['bar', 'foo']]``\n",
    "    for ``['bar', 'foo']`` order.\n",
    "\n",
    "    If callable, the callable function will be evaluated against the column\n",
    "    names, returning names where the callable function evaluates to True. An\n",
    "    example of a valid callable argument would be ``lambda x: x.upper() in\n",
    "    ['AAA', 'BBB', 'DDD']``. Using this parameter results in much faster\n",
    "    parsing time and lower memory usage.\n",
    "squeeze : bool, default False\n",
    "    If the parsed data only contains one column then return a Series.\n",
    "\n",
    "    .. deprecated:: 1.4.0\n",
    "        Append ``.squeeze(\"columns\")`` to the call to ``read_csv`` to squeeze\n",
    "        the data.\n",
    "prefix : str, optional\n",
    "    Prefix to add to column numbers when no header, e.g. 'X' for X0, X1, ...\n",
    "\n",
    "    .. deprecated:: 1.4.0\n",
    "       Use a list comprehension on the DataFrame's columns after calling ``read_csv``.\n",
    "mangle_dupe_cols : bool, default True\n",
    "    Duplicate columns will be specified as 'X', 'X.1', ...'X.N', rather than\n",
    "    'X'...'X'. Passing in False will cause data to be overwritten if there\n",
    "    are duplicate names in the columns.\n",
    "dtype : Type name or dict of column -> type, optional\n",
    "    Data type for data or columns. E.g. {'a': np.float64, 'b': np.int32,\n",
    "    'c': 'Int64'}\n",
    "    Use `str` or `object` together with suitable `na_values` settings\n",
    "    to preserve and not interpret dtype.\n",
    "    If converters are specified, they will be applied INSTEAD\n",
    "    of dtype conversion.\n",
    "engine : {'c', 'python', 'pyarrow'}, optional\n",
    "    Parser engine to use. The C and pyarrow engines are faster, while the python engine\n",
    "    is currently more feature-complete. Multithreading is currently only supported by\n",
    "    the pyarrow engine.\n",
    "\n",
    "    .. versionadded:: 1.4.0\n",
    "\n",
    "        The \"pyarrow\" engine was added as an *experimental* engine, and some features\n",
    "        are unsupported, or may not work correctly, with this engine.\n",
    "converters : dict, optional\n",
    "    Dict of functions for converting values in certain columns. Keys can either\n",
    "    be integers or column labels.\n",
    "true_values : list, optional\n",
    "    Values to consider as True.\n",
    "false_values : list, optional\n",
    "    Values to consider as False.\n",
    "skipinitialspace : bool, default False\n",
    "    Skip spaces after delimiter.\n",
    "skiprows : list-like, int or callable, optional\n",
    "    Line numbers to skip (0-indexed) or number of lines to skip (int)\n",
    "    at the start of the file.\n",
    "\n",
    "    If callable, the callable function will be evaluated against the row\n",
    "    indices, returning True if the row should be skipped and False otherwise.\n",
    "    An example of a valid callable argument would be ``lambda x: x in [0, 2]``.\n",
    "skipfooter : int, default 0\n",
    "    Number of lines at bottom of file to skip (Unsupported with engine='c').\n",
    "nrows : int, optional\n",
    "    Number of rows of file to read. Useful for reading pieces of large files.\n",
    "na_values : scalar, str, list-like, or dict, optional\n",
    "    Additional strings to recognize as NA/NaN. If dict passed, specific\n",
    "    per-column NA values.  By default the following values are interpreted as\n",
    "    NaN: '', '#N/A', '#N/A N/A', '#NA', '-1.#IND', '-1.#QNAN', '-NaN', '-nan',\n",
    "    '1.#IND', '1.#QNAN', '<NA>', 'N/A', 'NA', 'NULL', 'NaN', 'n/a',\n",
    "    'nan', 'null'.\n",
    "keep_default_na : bool, default True\n",
    "    Whether or not to include the default NaN values when parsing the data.\n",
    "    Depending on whether `na_values` is passed in, the behavior is as follows:\n",
    "\n",
    "    * If `keep_default_na` is True, and `na_values` are specified, `na_values`\n",
    "      is appended to the default NaN values used for parsing.\n",
    "    * If `keep_default_na` is True, and `na_values` are not specified, only\n",
    "      the default NaN values are used for parsing.\n",
    "    * If `keep_default_na` is False, and `na_values` are specified, only\n",
    "      the NaN values specified `na_values` are used for parsing.\n",
    "    * If `keep_default_na` is False, and `na_values` are not specified, no\n",
    "      strings will be parsed as NaN.\n",
    "\n",
    "    Note that if `na_filter` is passed in as False, the `keep_default_na` and\n",
    "    `na_values` parameters will be ignored.\n",
    "na_filter : bool, default True\n",
    "    Detect missing value markers (empty strings and the value of na_values). In\n",
    "    data without any NAs, passing na_filter=False can improve the performance\n",
    "    of reading a large file.\n",
    "verbose : bool, default False\n",
    "    Indicate number of NA values placed in non-numeric columns.\n",
    "skip_blank_lines : bool, default True\n",
    "    If True, skip over blank lines rather than interpreting as NaN values.\n",
    "parse_dates : bool or list of int or names or list of lists or dict, default False\n",
    "    The behavior is as follows:\n",
    "\n",
    "    * boolean. If True -> try parsing the index.\n",
    "    * list of int or names. e.g. If [1, 2, 3] -> try parsing columns 1, 2, 3\n",
    "      each as a separate date column.\n",
    "    * list of lists. e.g.  If [[1, 3]] -> combine columns 1 and 3 and parse as\n",
    "      a single date column.\n",
    "    * dict, e.g. {'foo' : [1, 3]} -> parse columns 1, 3 as date and call\n",
    "      result 'foo'\n",
    "\n",
    "    If a column or index cannot be represented as an array of datetimes,\n",
    "    say because of an unparsable value or a mixture of timezones, the column\n",
    "    or index will be returned unaltered as an object data type. For\n",
    "    non-standard datetime parsing, use ``pd.to_datetime`` after\n",
    "    ``pd.read_csv``. To parse an index or column with a mixture of timezones,\n",
    "    specify ``date_parser`` to be a partially-applied\n",
    "    :func:`pandas.to_datetime` with ``utc=True``. See\n",
    "    :ref:`io.csv.mixed_timezones` for more.\n",
    "\n",
    "    Note: A fast-path exists for iso8601-formatted dates.\n",
    "infer_datetime_format : bool, default False\n",
    "    If True and `parse_dates` is enabled, pandas will attempt to infer the\n",
    "    format of the datetime strings in the columns, and if it can be inferred,\n",
    "    switch to a faster method of parsing them. In some cases this can increase\n",
    "    the parsing speed by 5-10x.\n",
    "keep_date_col : bool, default False\n",
    "    If True and `parse_dates` specifies combining multiple columns then\n",
    "    keep the original columns.\n",
    "date_parser : function, optional\n",
    "    Function to use for converting a sequence of string columns to an array of\n",
    "    datetime instances. The default uses ``dateutil.parser.parser`` to do the\n",
    "    conversion. Pandas will try to call `date_parser` in three different ways,\n",
    "    advancing to the next if an exception occurs: 1) Pass one or more arrays\n",
    "    (as defined by `parse_dates`) as arguments; 2) concatenate (row-wise) the\n",
    "    string values from the columns defined by `parse_dates` into a single array\n",
    "    and pass that; and 3) call `date_parser` once for each row using one or\n",
    "    more strings (corresponding to the columns defined by `parse_dates`) as\n",
    "    arguments.\n",
    "dayfirst : bool, default False\n",
    "    DD/MM format dates, international and European format.\n",
    "cache_dates : bool, default True\n",
    "    If True, use a cache of unique, converted dates to apply the datetime\n",
    "    conversion. May produce significant speed-up when parsing duplicate\n",
    "    date strings, especially ones with timezone offsets.\n",
    "\n",
    "    .. versionadded:: 0.25.0\n",
    "iterator : bool, default False\n",
    "    Return TextFileReader object for iteration or getting chunks with\n",
    "    ``get_chunk()``.\n",
    "\n",
    "    .. versionchanged:: 1.2\n",
    "\n",
    "       ``TextFileReader`` is a context manager.\n",
    "chunksize : int, optional\n",
    "    Return TextFileReader object for iteration.\n",
    "    See the `IO Tools docs\n",
    "    <https://pandas.pydata.org/pandas-docs/stable/io.html#io-chunking>`_\n",
    "    for more information on ``iterator`` and ``chunksize``.\n",
    "\n",
    "    .. versionchanged:: 1.2\n",
    "\n",
    "       ``TextFileReader`` is a context manager.\n",
    "compression : str or dict, default 'infer'\n",
    "    For on-the-fly decompression of on-disk data. If 'infer' and '%s' is\n",
    "    path-like, then detect compression from the following extensions: '.gz',\n",
    "    '.bz2', '.zip', '.xz', or '.zst' (otherwise no compression). If using\n",
    "    'zip', the ZIP file must contain only one data file to be read in. Set to\n",
    "    ``None`` for no decompression. Can also be a dict with key ``'method'`` set\n",
    "    to one of {``'zip'``, ``'gzip'``, ``'bz2'``, ``'zstd'``} and other\n",
    "    key-value pairs are forwarded to ``zipfile.ZipFile``, ``gzip.GzipFile``,\n",
    "    ``bz2.BZ2File``, or ``zstandard.ZstdDecompressor``, respectively. As an\n",
    "    example, the following could be passed for Zstandard decompression using a\n",
    "    custom compression dictionary:\n",
    "    ``compression={'method': 'zstd', 'dict_data': my_compression_dict}``.\n",
    "\n",
    "    .. versionchanged:: 1.4.0 Zstandard support.\n",
    "\n",
    "thousands : str, optional\n",
    "    Thousands separator.\n",
    "decimal : str, default '.'\n",
    "    Character to recognize as decimal point (e.g. use ',' for European data).\n",
    "lineterminator : str (length 1), optional\n",
    "    Character to break file into lines. Only valid with C parser.\n",
    "quotechar : str (length 1), optional\n",
    "    The character used to denote the start and end of a quoted item. Quoted\n",
    "    items can include the delimiter and it will be ignored.\n",
    "quoting : int or csv.QUOTE_* instance, default 0\n",
    "    Control field quoting behavior per ``csv.QUOTE_*`` constants. Use one of\n",
    "    QUOTE_MINIMAL (0), QUOTE_ALL (1), QUOTE_NONNUMERIC (2) or QUOTE_NONE (3).\n",
    "doublequote : bool, default ``True``\n",
    "   When quotechar is specified and quoting is not ``QUOTE_NONE``, indicate\n",
    "   whether or not to interpret two consecutive quotechar elements INSIDE a\n",
    "   field as a single ``quotechar`` element.\n",
    "escapechar : str (length 1), optional\n",
    "    One-character string used to escape other characters.\n",
    "comment : str, optional\n",
    "    Indicates remainder of line should not be parsed. If found at the beginning\n",
    "    of a line, the line will be ignored altogether. This parameter must be a\n",
    "    single character. Like empty lines (as long as ``skip_blank_lines=True``),\n",
    "    fully commented lines are ignored by the parameter `header` but not by\n",
    "    `skiprows`. For example, if ``comment='#'``, parsing\n",
    "    ``#empty\\na,b,c\\n1,2,3`` with ``header=0`` will result in 'a,b,c' being\n",
    "    treated as the header.\n",
    "encoding : str, optional\n",
    "    Encoding to use for UTF when reading/writing (ex. 'utf-8'). `List of Python\n",
    "    standard encodings\n",
    "    <https://docs.python.org/3/library/codecs.html#standard-encodings>`_ .\n",
    "\n",
    "    .. versionchanged:: 1.2\n",
    "\n",
    "       When ``encoding`` is ``None``, ``errors=\"replace\"`` is passed to\n",
    "       ``open()``. Otherwise, ``errors=\"strict\"`` is passed to ``open()``.\n",
    "       This behavior was previously only the case for ``engine=\"python\"``.\n",
    "\n",
    "    .. versionchanged:: 1.3.0\n",
    "\n",
    "       ``encoding_errors`` is a new argument. ``encoding`` has no longer an\n",
    "       influence on how encoding errors are handled.\n",
    "\n",
    "encoding_errors : str, optional, default \"strict\"\n",
    "    How encoding errors are treated. `List of possible values\n",
    "    <https://docs.python.org/3/library/codecs.html#error-handlers>`_ .\n",
    "\n",
    "    .. versionadded:: 1.3.0\n",
    "\n",
    "dialect : str or csv.Dialect, optional\n",
    "    If provided, this parameter will override values (default or not) for the\n",
    "    following parameters: `delimiter`, `doublequote`, `escapechar`,\n",
    "    `skipinitialspace`, `quotechar`, and `quoting`. If it is necessary to\n",
    "    override values, a ParserWarning will be issued. See csv.Dialect\n",
    "    documentation for more details.\n",
    "error_bad_lines : bool, optional, default ``None``\n",
    "    Lines with too many fields (e.g. a csv line with too many commas) will by\n",
    "    default cause an exception to be raised, and no DataFrame will be returned.\n",
    "    If False, then these \"bad lines\" will be dropped from the DataFrame that is\n",
    "    returned.\n",
    "\n",
    "    .. deprecated:: 1.3.0\n",
    "       The ``on_bad_lines`` parameter should be used instead to specify behavior upon\n",
    "       encountering a bad line instead.\n",
    "warn_bad_lines : bool, optional, default ``None``\n",
    "    If error_bad_lines is False, and warn_bad_lines is True, a warning for each\n",
    "    \"bad line\" will be output.\n",
    "\n",
    "    .. deprecated:: 1.3.0\n",
    "       The ``on_bad_lines`` parameter should be used instead to specify behavior upon\n",
    "       encountering a bad line instead.\n",
    "on_bad_lines : {'error', 'warn', 'skip'} or callable, default 'error'\n",
    "    Specifies what to do upon encountering a bad line (a line with too many fields).\n",
    "    Allowed values are :\n",
    "\n",
    "        - 'error', raise an Exception when a bad line is encountered.\n",
    "        - 'warn', raise a warning when a bad line is encountered and skip that line.\n",
    "        - 'skip', skip bad lines without raising or warning when they are encountered.\n",
    "\n",
    "    .. versionadded:: 1.3.0\n",
    "\n",
    "        - callable, function with signature\n",
    "          ``(bad_line: list[str]) -> list[str] | None`` that will process a single\n",
    "          bad line. ``bad_line`` is a list of strings split by the ``sep``.\n",
    "          If the function returns ``None``, the bad line will be ignored.\n",
    "          If the function returns a new list of strings with more elements than\n",
    "          expected, a ``ParserWarning`` will be emitted while dropping extra elements.\n",
    "          Only supported when ``engine=\"python\"``\n",
    "\n",
    "    .. versionadded:: 1.4.0\n",
    "\n",
    "delim_whitespace : bool, default False\n",
    "    Specifies whether or not whitespace (e.g. ``' '`` or ``'    '``) will be\n",
    "    used as the sep. Equivalent to setting ``sep='\\s+'``. If this option\n",
    "    is set to True, nothing should be passed in for the ``delimiter``\n",
    "    parameter.\n",
    "low_memory : bool, default True\n",
    "    Internally process the file in chunks, resulting in lower memory use\n",
    "    while parsing, but possibly mixed type inference.  To ensure no mixed\n",
    "    types either set False, or specify the type with the `dtype` parameter.\n",
    "    Note that the entire file is read into a single DataFrame regardless,\n",
    "    use the `chunksize` or `iterator` parameter to return the data in chunks.\n",
    "    (Only valid with C parser).\n",
    "memory_map : bool, default False\n",
    "    If a filepath is provided for `filepath_or_buffer`, map the file object\n",
    "    directly onto memory and access the data directly from there. Using this\n",
    "    option can improve performance because there is no longer any I/O overhead.\n",
    "float_precision : str, optional\n",
    "    Specifies which converter the C engine should use for floating-point\n",
    "    values. The options are ``None`` or 'high' for the ordinary converter,\n",
    "    'legacy' for the original lower precision pandas converter, and\n",
    "    'round_trip' for the round-trip converter.\n",
    "\n",
    "    .. versionchanged:: 1.2\n",
    "\n",
    "storage_options : dict, optional\n",
    "    Extra options that make sense for a particular storage connection, e.g.\n",
    "    host, port, username, password, etc. For HTTP(S) URLs the key-value pairs\n",
    "    are forwarded to ``urllib`` as header options. For other URLs (e.g.\n",
    "    starting with \"s3://\", and \"gcs://\") the key-value pairs are forwarded to\n",
    "    ``fsspec``. Please see ``fsspec`` and ``urllib`` for more details.\n",
    "\n",
    "    .. versionadded:: 1.2\n",
    "\n",
    "Returns\n",
    "-------\n",
    "DataFrame or TextParser\n",
    "    A comma-separated values (csv) file is returned as two-dimensional\n",
    "    data structure with labeled axes.\n",
    "\n",
    "See Also\n",
    "--------\n",
    "DataFrame.to_csv : Write DataFrame to a comma-separated values (csv) file.\n",
    "read_csv : Read a comma-separated values (csv) file into DataFrame.\n",
    "read_fwf : Read a table of fixed-width formatted lines into DataFrame.\n",
    "\n",
    "Examples\n",
    "--------\n",
    ">>> pd.read_csv('data.csv')  # doctest: +SKIP\n",
    "\n",
    "</code>\n",
    "<a href='#1'>back to header</a>\n",
    "</blockquote>\n",
    "</details>\n",
    "</li>\n",
    "</ul>\n",
    "</li>\n",
    "\n",
    "</ul>\n",
    "</details> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9e45c6",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "SMS = pd.read_csv('../preprocess2/SMS_2.csv')\n",
    "Calls = pd.read_csv('../preprocess2/Calls_2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87db4948",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<div> <h3 class='hg'>2. Data Preparation | Feature Engineering</h3>  <a id='2'></a><small><a href='#top_phases'>back to top</a></small><details><summary style='list-style: none; cursor: pointer;'><u>View function calls</u></summary>\n",
    "<ul>\n",
    "\n",
    "<li> <strong class='hglib'>pandas</strong>\n",
    "<ul>\n",
    "<li>\n",
    "<details><summary style='list-style: none; cursor: pointer;'><u>pandas.core.generic.NDFrame._add_numeric_operations.<locals>.sum</u></summary>\n",
    "<blockquote>\n",
    "<code>\n",
    "Return the sum of the values over the requested axis.\n",
    "\n",
    "This is equivalent to the method ``numpy.sum``.\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "axis : {index (0), columns (1)}\n",
    "    Axis for the function to be applied on.\n",
    "skipna : bool, default True\n",
    "    Exclude NA/null values when computing the result.\n",
    "level : int or level name, default None\n",
    "    If the axis is a MultiIndex (hierarchical), count along a\n",
    "    particular level, collapsing into a Series.\n",
    "numeric_only : bool, default None\n",
    "    Include only float, int, boolean columns. If None, will attempt to use\n",
    "    everything, then use only numeric data. Not implemented for Series.\n",
    "min_count : int, default 0\n",
    "    The required number of valid values to perform the operation. If fewer than\n",
    "    ``min_count`` non-NA values are present the result will be NA.\n",
    "**kwargs\n",
    "    Additional keyword arguments to be passed to the function.\n",
    "\n",
    "Returns\n",
    "-------\n",
    "Series or DataFrame (if level specified)\n",
    "\n",
    "See Also\n",
    "--------\n",
    "Series.sum : Return the sum.\n",
    "Series.min : Return the minimum.\n",
    "Series.max : Return the maximum.\n",
    "Series.idxmin : Return the index of the minimum.\n",
    "Series.idxmax : Return the index of the maximum.\n",
    "DataFrame.sum : Return the sum over the requested axis.\n",
    "DataFrame.min : Return the minimum over the requested axis.\n",
    "DataFrame.max : Return the maximum over the requested axis.\n",
    "DataFrame.idxmin : Return the index of the minimum over the requested axis.\n",
    "DataFrame.idxmax : Return the index of the maximum over the requested axis.\n",
    "\n",
    "Examples\n",
    "--------\n",
    ">>> idx = pd.MultiIndex.from_arrays([\n",
    "...     ['warm', 'warm', 'cold', 'cold'],\n",
    "...     ['dog', 'falcon', 'fish', 'spider']],\n",
    "...     names=['blooded', 'animal'])\n",
    ">>> s = pd.Series([4, 2, 0, 8], name='legs', index=idx)\n",
    ">>> s\n",
    "blooded  animal\n",
    "warm     dog       4\n",
    "         falcon    2\n",
    "cold     fish      0\n",
    "         spider    8\n",
    "Name: legs, dtype: int64\n",
    "\n",
    ">>> s.sum()\n",
    "14\n",
    "\n",
    "By default, the sum of an empty or all-NA Series is ``0``.\n",
    "\n",
    ">>> pd.Series([], dtype=\"float64\").sum()  # min_count=0 is the default\n",
    "0.0\n",
    "\n",
    "This can be controlled with the ``min_count`` parameter. For example, if\n",
    "you'd like the sum of an empty series to be NaN, pass ``min_count=1``.\n",
    "\n",
    ">>> pd.Series([], dtype=\"float64\").sum(min_count=1)\n",
    "nan\n",
    "\n",
    "Thanks to the ``skipna`` parameter, ``min_count`` handles all-NA and\n",
    "empty series identically.\n",
    "\n",
    ">>> pd.Series([np.nan]).sum()\n",
    "0.0\n",
    "\n",
    ">>> pd.Series([np.nan]).sum(min_count=1)\n",
    "nan\n",
    "\n",
    "</code>\n",
    "<a href='#2'>back to header</a>\n",
    "</blockquote>\n",
    "</details>\n",
    "</li>\n",
    "<li>\n",
    "<details><summary style='list-style: none; cursor: pointer;'><u>pandas.core.frame.DataFrame.isnull</u></summary>\n",
    "<blockquote>\n",
    "<code>\n",
    "DataFrame.isnull is an alias for DataFrame.isna.\n",
    "\n",
    "Detect missing values.\n",
    "\n",
    "Return a boolean same-sized object indicating if the values are NA.\n",
    "NA values, such as None or :attr:`numpy.NaN`, gets mapped to True\n",
    "values.\n",
    "Everything else gets mapped to False values. Characters such as empty\n",
    "strings ``''`` or :attr:`numpy.inf` are not considered NA values\n",
    "(unless you set ``pandas.options.mode.use_inf_as_na = True``).\n",
    "\n",
    "Returns\n",
    "-------\n",
    "DataFrame\n",
    "    Mask of bool values for each element in DataFrame that\n",
    "    indicates whether an element is an NA value.\n",
    "\n",
    "See Also\n",
    "--------\n",
    "DataFrame.isnull : Alias of isna.\n",
    "DataFrame.notna : Boolean inverse of isna.\n",
    "DataFrame.dropna : Omit axes labels with missing values.\n",
    "isna : Top-level isna.\n",
    "\n",
    "Examples\n",
    "--------\n",
    "Show which entries in a DataFrame are NA.\n",
    "\n",
    ">>> df = pd.DataFrame(dict(age=[5, 6, np.NaN],\n",
    "...                    born=[pd.NaT, pd.Timestamp('1939-05-27'),\n",
    "...                          pd.Timestamp('1940-04-25')],\n",
    "...                    name=['Alfred', 'Batman', ''],\n",
    "...                    toy=[None, 'Batmobile', 'Joker']))\n",
    ">>> df\n",
    "   age       born    name        toy\n",
    "0  5.0        NaT  Alfred       None\n",
    "1  6.0 1939-05-27  Batman  Batmobile\n",
    "2  NaN 1940-04-25              Joker\n",
    "\n",
    ">>> df.isna()\n",
    "     age   born   name    toy\n",
    "0  False   True  False   True\n",
    "1  False  False  False  False\n",
    "2   True  False  False  False\n",
    "\n",
    "Show which entries in a Series are NA.\n",
    "\n",
    ">>> ser = pd.Series([5, 6, np.NaN])\n",
    ">>> ser\n",
    "0    5.0\n",
    "1    6.0\n",
    "2    NaN\n",
    "dtype: float64\n",
    "\n",
    ">>> ser.isna()\n",
    "0    False\n",
    "1    False\n",
    "2     True\n",
    "dtype: bool\n",
    "\n",
    "</code>\n",
    "<a href='#2'>back to header</a>\n",
    "</blockquote>\n",
    "</details>\n",
    "</li>\n",
    "</ul>\n",
    "</li>\n",
    "\n",
    "</ul>\n",
    "</details> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7491f522",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Calls.shape)\n",
    "print(Calls.isnull().sum())\n",
    "print('-----------')\n",
    "# Calls = Calls.dropna()\n",
    "# print(Calls.shape)\n",
    "# print(Calls.isnull().sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9da83e1",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<div> <h3 class='hg'>3. Data Preparation | Feature Engineering</h3>  <a id='3'></a><small><a href='#top_phases'>back to top</a></small><details><summary style='list-style: none; cursor: pointer;'><u>View function calls</u></summary>\n",
    "<ul>\n",
    "\n",
    "<li> <strong class='hglib'>pandas</strong>\n",
    "<ul>\n",
    "<li>\n",
    "<details><summary style='list-style: none; cursor: pointer;'><u>pandas.core.generic.NDFrame._add_numeric_operations.<locals>.sum</u></summary>\n",
    "<blockquote>\n",
    "<code>\n",
    "Return the sum of the values over the requested axis.\n",
    "\n",
    "This is equivalent to the method ``numpy.sum``.\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "axis : {index (0), columns (1)}\n",
    "    Axis for the function to be applied on.\n",
    "skipna : bool, default True\n",
    "    Exclude NA/null values when computing the result.\n",
    "level : int or level name, default None\n",
    "    If the axis is a MultiIndex (hierarchical), count along a\n",
    "    particular level, collapsing into a Series.\n",
    "numeric_only : bool, default None\n",
    "    Include only float, int, boolean columns. If None, will attempt to use\n",
    "    everything, then use only numeric data. Not implemented for Series.\n",
    "min_count : int, default 0\n",
    "    The required number of valid values to perform the operation. If fewer than\n",
    "    ``min_count`` non-NA values are present the result will be NA.\n",
    "**kwargs\n",
    "    Additional keyword arguments to be passed to the function.\n",
    "\n",
    "Returns\n",
    "-------\n",
    "Series or DataFrame (if level specified)\n",
    "\n",
    "See Also\n",
    "--------\n",
    "Series.sum : Return the sum.\n",
    "Series.min : Return the minimum.\n",
    "Series.max : Return the maximum.\n",
    "Series.idxmin : Return the index of the minimum.\n",
    "Series.idxmax : Return the index of the maximum.\n",
    "DataFrame.sum : Return the sum over the requested axis.\n",
    "DataFrame.min : Return the minimum over the requested axis.\n",
    "DataFrame.max : Return the maximum over the requested axis.\n",
    "DataFrame.idxmin : Return the index of the minimum over the requested axis.\n",
    "DataFrame.idxmax : Return the index of the maximum over the requested axis.\n",
    "\n",
    "Examples\n",
    "--------\n",
    ">>> idx = pd.MultiIndex.from_arrays([\n",
    "...     ['warm', 'warm', 'cold', 'cold'],\n",
    "...     ['dog', 'falcon', 'fish', 'spider']],\n",
    "...     names=['blooded', 'animal'])\n",
    ">>> s = pd.Series([4, 2, 0, 8], name='legs', index=idx)\n",
    ">>> s\n",
    "blooded  animal\n",
    "warm     dog       4\n",
    "         falcon    2\n",
    "cold     fish      0\n",
    "         spider    8\n",
    "Name: legs, dtype: int64\n",
    "\n",
    ">>> s.sum()\n",
    "14\n",
    "\n",
    "By default, the sum of an empty or all-NA Series is ``0``.\n",
    "\n",
    ">>> pd.Series([], dtype=\"float64\").sum()  # min_count=0 is the default\n",
    "0.0\n",
    "\n",
    "This can be controlled with the ``min_count`` parameter. For example, if\n",
    "you'd like the sum of an empty series to be NaN, pass ``min_count=1``.\n",
    "\n",
    ">>> pd.Series([], dtype=\"float64\").sum(min_count=1)\n",
    "nan\n",
    "\n",
    "Thanks to the ``skipna`` parameter, ``min_count`` handles all-NA and\n",
    "empty series identically.\n",
    "\n",
    ">>> pd.Series([np.nan]).sum()\n",
    "0.0\n",
    "\n",
    ">>> pd.Series([np.nan]).sum(min_count=1)\n",
    "nan\n",
    "\n",
    "</code>\n",
    "<a href='#3'>back to header</a>\n",
    "</blockquote>\n",
    "</details>\n",
    "</li>\n",
    "<li>\n",
    "<details><summary style='list-style: none; cursor: pointer;'><u>pandas.core.frame.DataFrame.isnull</u></summary>\n",
    "<blockquote>\n",
    "<code>\n",
    "DataFrame.isnull is an alias for DataFrame.isna.\n",
    "\n",
    "Detect missing values.\n",
    "\n",
    "Return a boolean same-sized object indicating if the values are NA.\n",
    "NA values, such as None or :attr:`numpy.NaN`, gets mapped to True\n",
    "values.\n",
    "Everything else gets mapped to False values. Characters such as empty\n",
    "strings ``''`` or :attr:`numpy.inf` are not considered NA values\n",
    "(unless you set ``pandas.options.mode.use_inf_as_na = True``).\n",
    "\n",
    "Returns\n",
    "-------\n",
    "DataFrame\n",
    "    Mask of bool values for each element in DataFrame that\n",
    "    indicates whether an element is an NA value.\n",
    "\n",
    "See Also\n",
    "--------\n",
    "DataFrame.isnull : Alias of isna.\n",
    "DataFrame.notna : Boolean inverse of isna.\n",
    "DataFrame.dropna : Omit axes labels with missing values.\n",
    "isna : Top-level isna.\n",
    "\n",
    "Examples\n",
    "--------\n",
    "Show which entries in a DataFrame are NA.\n",
    "\n",
    ">>> df = pd.DataFrame(dict(age=[5, 6, np.NaN],\n",
    "...                    born=[pd.NaT, pd.Timestamp('1939-05-27'),\n",
    "...                          pd.Timestamp('1940-04-25')],\n",
    "...                    name=['Alfred', 'Batman', ''],\n",
    "...                    toy=[None, 'Batmobile', 'Joker']))\n",
    ">>> df\n",
    "   age       born    name        toy\n",
    "0  5.0        NaT  Alfred       None\n",
    "1  6.0 1939-05-27  Batman  Batmobile\n",
    "2  NaN 1940-04-25              Joker\n",
    "\n",
    ">>> df.isna()\n",
    "     age   born   name    toy\n",
    "0  False   True  False   True\n",
    "1  False  False  False  False\n",
    "2   True  False  False  False\n",
    "\n",
    "Show which entries in a Series are NA.\n",
    "\n",
    ">>> ser = pd.Series([5, 6, np.NaN])\n",
    ">>> ser\n",
    "0    5.0\n",
    "1    6.0\n",
    "2    NaN\n",
    "dtype: float64\n",
    "\n",
    ">>> ser.isna()\n",
    "0    False\n",
    "1    False\n",
    "2     True\n",
    "dtype: bool\n",
    "\n",
    "</code>\n",
    "<a href='#3'>back to header</a>\n",
    "</blockquote>\n",
    "</details>\n",
    "</li>\n",
    "</ul>\n",
    "</li>\n",
    "\n",
    "</ul>\n",
    "</details> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299ceb36",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "print(SMS.shape)\n",
    "print(SMS.isnull().sum())\n",
    "print('-------------')\n",
    "\n",
    "# SMS = SMS.dropna()\n",
    "# print(SMS.shape)\n",
    "# print(SMS.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "369b0358",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<div> <h3 class='hg'>4. Data Preparation</h3>  <a id='4'></a><small><a href='#top_phases'>back to top</a></small><details><summary style='list-style: none; cursor: pointer;'><u>View function calls</u></summary>\n",
    "<ul>\n",
    "\n",
    "<li> <strong class='hglib'>pandas</strong>\n",
    "<ul>\n",
    "<li>\n",
    "<details><summary style='list-style: none; cursor: pointer;'><u>pandas.core.generic.NDFrame.head</u></summary>\n",
    "<blockquote>\n",
    "<code>\n",
    "Return the first `n` rows.\n",
    "\n",
    "This function returns the first `n` rows for the object based\n",
    "on position. It is useful for quickly testing if your object\n",
    "has the right type of data in it.\n",
    "\n",
    "For negative values of `n`, this function returns all rows except\n",
    "the last `n` rows, equivalent to ``df[:-n]``.\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "n : int, default 5\n",
    "    Number of rows to select.\n",
    "\n",
    "Returns\n",
    "-------\n",
    "same type as caller\n",
    "    The first `n` rows of the caller object.\n",
    "\n",
    "See Also\n",
    "--------\n",
    "DataFrame.tail: Returns the last `n` rows.\n",
    "\n",
    "Examples\n",
    "--------\n",
    ">>> df = pd.DataFrame({'animal': ['alligator', 'bee', 'falcon', 'lion',\n",
    "...                    'monkey', 'parrot', 'shark', 'whale', 'zebra']})\n",
    ">>> df\n",
    "      animal\n",
    "0  alligator\n",
    "1        bee\n",
    "2     falcon\n",
    "3       lion\n",
    "4     monkey\n",
    "5     parrot\n",
    "6      shark\n",
    "7      whale\n",
    "8      zebra\n",
    "\n",
    "Viewing the first 5 lines\n",
    "\n",
    ">>> df.head()\n",
    "      animal\n",
    "0  alligator\n",
    "1        bee\n",
    "2     falcon\n",
    "3       lion\n",
    "4     monkey\n",
    "\n",
    "Viewing the first `n` lines (three in this case)\n",
    "\n",
    ">>> df.head(3)\n",
    "      animal\n",
    "0  alligator\n",
    "1        bee\n",
    "2     falcon\n",
    "\n",
    "For negative values of `n`\n",
    "\n",
    ">>> df.head(-3)\n",
    "      animal\n",
    "0  alligator\n",
    "1        bee\n",
    "2     falcon\n",
    "3       lion\n",
    "4     monkey\n",
    "5     parrot\n",
    "\n",
    "</code>\n",
    "<a href='#4'>back to header</a>\n",
    "</blockquote>\n",
    "</details>\n",
    "</li>\n",
    "</ul>\n",
    "</li>\n",
    "\n",
    "</ul>\n",
    "</details> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407f5f39",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "Calls.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674cde11",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<div> <h3 class='hg'>5. Data Preparation</h3>  <a id='5'></a><small><a href='#top_phases'>back to top</a></small><details><summary style='list-style: none; cursor: pointer;'><u>View function calls</u></summary>\n",
    "<ul>\n",
    "\n",
    "<li> <strong class='hglib'>pandas</strong>\n",
    "<ul>\n",
    "<li>\n",
    "<details><summary style='list-style: none; cursor: pointer;'><u>pandas.core.generic.NDFrame.head</u></summary>\n",
    "<blockquote>\n",
    "<code>\n",
    "Return the first `n` rows.\n",
    "\n",
    "This function returns the first `n` rows for the object based\n",
    "on position. It is useful for quickly testing if your object\n",
    "has the right type of data in it.\n",
    "\n",
    "For negative values of `n`, this function returns all rows except\n",
    "the last `n` rows, equivalent to ``df[:-n]``.\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "n : int, default 5\n",
    "    Number of rows to select.\n",
    "\n",
    "Returns\n",
    "-------\n",
    "same type as caller\n",
    "    The first `n` rows of the caller object.\n",
    "\n",
    "See Also\n",
    "--------\n",
    "DataFrame.tail: Returns the last `n` rows.\n",
    "\n",
    "Examples\n",
    "--------\n",
    ">>> df = pd.DataFrame({'animal': ['alligator', 'bee', 'falcon', 'lion',\n",
    "...                    'monkey', 'parrot', 'shark', 'whale', 'zebra']})\n",
    ">>> df\n",
    "      animal\n",
    "0  alligator\n",
    "1        bee\n",
    "2     falcon\n",
    "3       lion\n",
    "4     monkey\n",
    "5     parrot\n",
    "6      shark\n",
    "7      whale\n",
    "8      zebra\n",
    "\n",
    "Viewing the first 5 lines\n",
    "\n",
    ">>> df.head()\n",
    "      animal\n",
    "0  alligator\n",
    "1        bee\n",
    "2     falcon\n",
    "3       lion\n",
    "4     monkey\n",
    "\n",
    "Viewing the first `n` lines (three in this case)\n",
    "\n",
    ">>> df.head(3)\n",
    "      animal\n",
    "0  alligator\n",
    "1        bee\n",
    "2     falcon\n",
    "\n",
    "For negative values of `n`\n",
    "\n",
    ">>> df.head(-3)\n",
    "      animal\n",
    "0  alligator\n",
    "1        bee\n",
    "2     falcon\n",
    "3       lion\n",
    "4     monkey\n",
    "5     parrot\n",
    "\n",
    "</code>\n",
    "<a href='#5'>back to header</a>\n",
    "</blockquote>\n",
    "</details>\n",
    "</li>\n",
    "</ul>\n",
    "</li>\n",
    "\n",
    "</ul>\n",
    "</details> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27dcb3dd",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "SMS.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f27cf0",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "set(Calls.relationship)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fea712f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<div> <h3 class='hg'>7. Data Preparation | Feature Engineering</h3>  <a id='7'></a><small><a href='#top_phases'>back to top</a></small> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9111dc0e",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "Calls.ix[Calls.duration < 0, :]\n",
    "# Calls.relationship.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4192d04",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<div> <h3 class='hg'>8. Data Preparation</h3>  <a id='8'></a><small><a href='#top_phases'>back to top</a></small><details><summary style='list-style: none; cursor: pointer;'><u>View function calls</u></summary>\n",
    "<ul>\n",
    "\n",
    "<li> <strong class='hglib'>pandas</strong>\n",
    "<ul>\n",
    "<li>\n",
    "<details><summary style='list-style: none; cursor: pointer;'><u>pandas.core.generic.NDFrame.head</u></summary>\n",
    "<blockquote>\n",
    "<code>\n",
    "Return the first `n` rows.\n",
    "\n",
    "This function returns the first `n` rows for the object based\n",
    "on position. It is useful for quickly testing if your object\n",
    "has the right type of data in it.\n",
    "\n",
    "For negative values of `n`, this function returns all rows except\n",
    "the last `n` rows, equivalent to ``df[:-n]``.\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "n : int, default 5\n",
    "    Number of rows to select.\n",
    "\n",
    "Returns\n",
    "-------\n",
    "same type as caller\n",
    "    The first `n` rows of the caller object.\n",
    "\n",
    "See Also\n",
    "--------\n",
    "DataFrame.tail: Returns the last `n` rows.\n",
    "\n",
    "Examples\n",
    "--------\n",
    ">>> df = pd.DataFrame({'animal': ['alligator', 'bee', 'falcon', 'lion',\n",
    "...                    'monkey', 'parrot', 'shark', 'whale', 'zebra']})\n",
    ">>> df\n",
    "      animal\n",
    "0  alligator\n",
    "1        bee\n",
    "2     falcon\n",
    "3       lion\n",
    "4     monkey\n",
    "5     parrot\n",
    "6      shark\n",
    "7      whale\n",
    "8      zebra\n",
    "\n",
    "Viewing the first 5 lines\n",
    "\n",
    ">>> df.head()\n",
    "      animal\n",
    "0  alligator\n",
    "1        bee\n",
    "2     falcon\n",
    "3       lion\n",
    "4     monkey\n",
    "\n",
    "Viewing the first `n` lines (three in this case)\n",
    "\n",
    ">>> df.head(3)\n",
    "      animal\n",
    "0  alligator\n",
    "1        bee\n",
    "2     falcon\n",
    "\n",
    "For negative values of `n`\n",
    "\n",
    ">>> df.head(-3)\n",
    "      animal\n",
    "0  alligator\n",
    "1        bee\n",
    "2     falcon\n",
    "3       lion\n",
    "4     monkey\n",
    "5     parrot\n",
    "\n",
    "</code>\n",
    "<a href='#8'>back to header</a>\n",
    "</blockquote>\n",
    "</details>\n",
    "</li>\n",
    "</ul>\n",
    "</li>\n",
    "\n",
    "</ul>\n",
    "</details> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72a19af",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "Calls.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2607d700",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<div> <h3 class='hg'>9. Data Preparation | Feature Engineering</h3>  <a id='9'></a><small><a href='#top_phases'>back to top</a></small> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5636ebb1",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "Calls['isCall'] = 1\n",
    "Calls['isSMS'] = 0\n",
    "Calls['isCloseFriend'] = Calls.relationship == 'CloseFriend'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd59c6a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<div> <h3 class='hg'>10. Data Preparation</h3>  <a id='10'></a><small><a href='#top_phases'>back to top</a></small><details><summary style='list-style: none; cursor: pointer;'><u>View function calls</u></summary>\n",
    "<ul>\n",
    "\n",
    "<li> <strong class='hglib'>pandas</strong>\n",
    "<ul>\n",
    "<li>\n",
    "<details><summary style='list-style: none; cursor: pointer;'><u>pandas.core.generic.NDFrame.head</u></summary>\n",
    "<blockquote>\n",
    "<code>\n",
    "Return the first `n` rows.\n",
    "\n",
    "This function returns the first `n` rows for the object based\n",
    "on position. It is useful for quickly testing if your object\n",
    "has the right type of data in it.\n",
    "\n",
    "For negative values of `n`, this function returns all rows except\n",
    "the last `n` rows, equivalent to ``df[:-n]``.\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "n : int, default 5\n",
    "    Number of rows to select.\n",
    "\n",
    "Returns\n",
    "-------\n",
    "same type as caller\n",
    "    The first `n` rows of the caller object.\n",
    "\n",
    "See Also\n",
    "--------\n",
    "DataFrame.tail: Returns the last `n` rows.\n",
    "\n",
    "Examples\n",
    "--------\n",
    ">>> df = pd.DataFrame({'animal': ['alligator', 'bee', 'falcon', 'lion',\n",
    "...                    'monkey', 'parrot', 'shark', 'whale', 'zebra']})\n",
    ">>> df\n",
    "      animal\n",
    "0  alligator\n",
    "1        bee\n",
    "2     falcon\n",
    "3       lion\n",
    "4     monkey\n",
    "5     parrot\n",
    "6      shark\n",
    "7      whale\n",
    "8      zebra\n",
    "\n",
    "Viewing the first 5 lines\n",
    "\n",
    ">>> df.head()\n",
    "      animal\n",
    "0  alligator\n",
    "1        bee\n",
    "2     falcon\n",
    "3       lion\n",
    "4     monkey\n",
    "\n",
    "Viewing the first `n` lines (three in this case)\n",
    "\n",
    ">>> df.head(3)\n",
    "      animal\n",
    "0  alligator\n",
    "1        bee\n",
    "2     falcon\n",
    "\n",
    "For negative values of `n`\n",
    "\n",
    ">>> df.head(-3)\n",
    "      animal\n",
    "0  alligator\n",
    "1        bee\n",
    "2     falcon\n",
    "3       lion\n",
    "4     monkey\n",
    "5     parrot\n",
    "\n",
    "</code>\n",
    "<a href='#10'>back to header</a>\n",
    "</blockquote>\n",
    "</details>\n",
    "</li>\n",
    "</ul>\n",
    "</li>\n",
    "\n",
    "</ul>\n",
    "</details> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c0605b",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "SMS.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94d1b9f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<div> <h3 class='hg'>11. Data Preparation</h3>  <a id='11'></a><small><a href='#top_phases'>back to top</a></small><details><summary style='list-style: none; cursor: pointer;'><u>View function calls</u></summary>\n",
    "<ul>\n",
    "\n",
    "<li> <strong class='hglib'>pandas</strong>\n",
    "<ul>\n",
    "<li>\n",
    "<details><summary style='list-style: none; cursor: pointer;'><u>pandas.core.generic.NDFrame.head</u></summary>\n",
    "<blockquote>\n",
    "<code>\n",
    "Return the first `n` rows.\n",
    "\n",
    "This function returns the first `n` rows for the object based\n",
    "on position. It is useful for quickly testing if your object\n",
    "has the right type of data in it.\n",
    "\n",
    "For negative values of `n`, this function returns all rows except\n",
    "the last `n` rows, equivalent to ``df[:-n]``.\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "n : int, default 5\n",
    "    Number of rows to select.\n",
    "\n",
    "Returns\n",
    "-------\n",
    "same type as caller\n",
    "    The first `n` rows of the caller object.\n",
    "\n",
    "See Also\n",
    "--------\n",
    "DataFrame.tail: Returns the last `n` rows.\n",
    "\n",
    "Examples\n",
    "--------\n",
    ">>> df = pd.DataFrame({'animal': ['alligator', 'bee', 'falcon', 'lion',\n",
    "...                    'monkey', 'parrot', 'shark', 'whale', 'zebra']})\n",
    ">>> df\n",
    "      animal\n",
    "0  alligator\n",
    "1        bee\n",
    "2     falcon\n",
    "3       lion\n",
    "4     monkey\n",
    "5     parrot\n",
    "6      shark\n",
    "7      whale\n",
    "8      zebra\n",
    "\n",
    "Viewing the first 5 lines\n",
    "\n",
    ">>> df.head()\n",
    "      animal\n",
    "0  alligator\n",
    "1        bee\n",
    "2     falcon\n",
    "3       lion\n",
    "4     monkey\n",
    "\n",
    "Viewing the first `n` lines (three in this case)\n",
    "\n",
    ">>> df.head(3)\n",
    "      animal\n",
    "0  alligator\n",
    "1        bee\n",
    "2     falcon\n",
    "\n",
    "For negative values of `n`\n",
    "\n",
    ">>> df.head(-3)\n",
    "      animal\n",
    "0  alligator\n",
    "1        bee\n",
    "2     falcon\n",
    "3       lion\n",
    "4     monkey\n",
    "5     parrot\n",
    "\n",
    "</code>\n",
    "<a href='#11'>back to header</a>\n",
    "</blockquote>\n",
    "</details>\n",
    "</li>\n",
    "</ul>\n",
    "</li>\n",
    "\n",
    "</ul>\n",
    "</details> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c999f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "SMS['isSMS'] = 1\n",
    "SMS['isCall'] = 0\n",
    "SMS['isCloseFriend'] = SMS.relationship == 'CloseFriend'\n",
    "SMS.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1983d576",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "type(SMS.time[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e32f7de",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<div> <h3 class='hg'>13. Data Preparation</h3>  <a id='13'></a><small><a href='#top_phases'>back to top</a></small><details><summary style='list-style: none; cursor: pointer;'><u>View function calls</u></summary>\n",
    "<ul>\n",
    "\n",
    "<li> <strong class='hglib'>pandas</strong>\n",
    "<ul>\n",
    "<li>\n",
    "<details><summary style='list-style: none; cursor: pointer;'><u>pandas.core.generic.NDFrame.head</u></summary>\n",
    "<blockquote>\n",
    "<code>\n",
    "Return the first `n` rows.\n",
    "\n",
    "This function returns the first `n` rows for the object based\n",
    "on position. It is useful for quickly testing if your object\n",
    "has the right type of data in it.\n",
    "\n",
    "For negative values of `n`, this function returns all rows except\n",
    "the last `n` rows, equivalent to ``df[:-n]``.\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "n : int, default 5\n",
    "    Number of rows to select.\n",
    "\n",
    "Returns\n",
    "-------\n",
    "same type as caller\n",
    "    The first `n` rows of the caller object.\n",
    "\n",
    "See Also\n",
    "--------\n",
    "DataFrame.tail: Returns the last `n` rows.\n",
    "\n",
    "Examples\n",
    "--------\n",
    ">>> df = pd.DataFrame({'animal': ['alligator', 'bee', 'falcon', 'lion',\n",
    "...                    'monkey', 'parrot', 'shark', 'whale', 'zebra']})\n",
    ">>> df\n",
    "      animal\n",
    "0  alligator\n",
    "1        bee\n",
    "2     falcon\n",
    "3       lion\n",
    "4     monkey\n",
    "5     parrot\n",
    "6      shark\n",
    "7      whale\n",
    "8      zebra\n",
    "\n",
    "Viewing the first 5 lines\n",
    "\n",
    ">>> df.head()\n",
    "      animal\n",
    "0  alligator\n",
    "1        bee\n",
    "2     falcon\n",
    "3       lion\n",
    "4     monkey\n",
    "\n",
    "Viewing the first `n` lines (three in this case)\n",
    "\n",
    ">>> df.head(3)\n",
    "      animal\n",
    "0  alligator\n",
    "1        bee\n",
    "2     falcon\n",
    "\n",
    "For negative values of `n`\n",
    "\n",
    ">>> df.head(-3)\n",
    "      animal\n",
    "0  alligator\n",
    "1        bee\n",
    "2     falcon\n",
    "3       lion\n",
    "4     monkey\n",
    "5     parrot\n",
    "\n",
    "</code>\n",
    "<a href='#13'>back to header</a>\n",
    "</blockquote>\n",
    "</details>\n",
    "</li>\n",
    "</ul>\n",
    "</li>\n",
    "\n",
    "</ul>\n",
    "</details> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a33716",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "Calls.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227a75ae",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<div> <h3 class='hg'>14. Data Preparation</h3>  <a id='14'></a><small><a href='#top_phases'>back to top</a></small><details><summary style='list-style: none; cursor: pointer;'><u>View function calls</u></summary>\n",
    "<ul>\n",
    "\n",
    "<li> <strong class='hglib'>pandas</strong>\n",
    "<ul>\n",
    "<li>\n",
    "<details><summary style='list-style: none; cursor: pointer;'><u>pandas.core.generic.NDFrame.head</u></summary>\n",
    "<blockquote>\n",
    "<code>\n",
    "Return the first `n` rows.\n",
    "\n",
    "This function returns the first `n` rows for the object based\n",
    "on position. It is useful for quickly testing if your object\n",
    "has the right type of data in it.\n",
    "\n",
    "For negative values of `n`, this function returns all rows except\n",
    "the last `n` rows, equivalent to ``df[:-n]``.\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "n : int, default 5\n",
    "    Number of rows to select.\n",
    "\n",
    "Returns\n",
    "-------\n",
    "same type as caller\n",
    "    The first `n` rows of the caller object.\n",
    "\n",
    "See Also\n",
    "--------\n",
    "DataFrame.tail: Returns the last `n` rows.\n",
    "\n",
    "Examples\n",
    "--------\n",
    ">>> df = pd.DataFrame({'animal': ['alligator', 'bee', 'falcon', 'lion',\n",
    "...                    'monkey', 'parrot', 'shark', 'whale', 'zebra']})\n",
    ">>> df\n",
    "      animal\n",
    "0  alligator\n",
    "1        bee\n",
    "2     falcon\n",
    "3       lion\n",
    "4     monkey\n",
    "5     parrot\n",
    "6      shark\n",
    "7      whale\n",
    "8      zebra\n",
    "\n",
    "Viewing the first 5 lines\n",
    "\n",
    ">>> df.head()\n",
    "      animal\n",
    "0  alligator\n",
    "1        bee\n",
    "2     falcon\n",
    "3       lion\n",
    "4     monkey\n",
    "\n",
    "Viewing the first `n` lines (three in this case)\n",
    "\n",
    ">>> df.head(3)\n",
    "      animal\n",
    "0  alligator\n",
    "1        bee\n",
    "2     falcon\n",
    "\n",
    "For negative values of `n`\n",
    "\n",
    ">>> df.head(-3)\n",
    "      animal\n",
    "0  alligator\n",
    "1        bee\n",
    "2     falcon\n",
    "3       lion\n",
    "4     monkey\n",
    "5     parrot\n",
    "\n",
    "</code>\n",
    "<a href='#14'>back to header</a>\n",
    "</blockquote>\n",
    "</details>\n",
    "</li>\n",
    "</ul>\n",
    "</li>\n",
    "\n",
    "</ul>\n",
    "</details> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8f5640",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "Calls.columns = ['user.id', 'datetime', 'duration', 'dest.user.id', 'dest.phone.hash',\n",
    "       'id_tuple', 'relationship', 'isCall', 'isSMS', 'isCloseFriend']\n",
    "Calls.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ccdaaa",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<div> <h3 class='hg'>15. Data Preparation | Feature Engineering</h3>  <a id='15'></a><small><a href='#top_phases'>back to top</a></small><details><summary style='list-style: none; cursor: pointer;'><u>View function calls</u></summary>\n",
    "<ul>\n",
    "\n",
    "<li> <strong class='hglib'>pandas</strong>\n",
    "<ul>\n",
    "<li>\n",
    "<details><summary style='list-style: none; cursor: pointer;'><u>pandas.core.tools.datetimes.to_datetime</u></summary>\n",
    "<blockquote>\n",
    "<code>\n",
    "Convert argument to datetime.\n",
    "\n",
    "This function converts a scalar, array-like, :class:`Series` or\n",
    ":class:`DataFrame`/dict-like to a pandas datetime object.\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "arg : int, float, str, datetime, list, tuple, 1-d array, Series, DataFrame/dict-like\n",
    "    The object to convert to a datetime. If a :class:`DataFrame` is provided, the\n",
    "    method expects minimally the following columns: :const:`\"year\"`,\n",
    "    :const:`\"month\"`, :const:`\"day\"`.\n",
    "errors : {'ignore', 'raise', 'coerce'}, default 'raise'\n",
    "    - If :const:`'raise'`, then invalid parsing will raise an exception.\n",
    "    - If :const:`'coerce'`, then invalid parsing will be set as :const:`NaT`.\n",
    "    - If :const:`'ignore'`, then invalid parsing will return the input.\n",
    "dayfirst : bool, default False\n",
    "    Specify a date parse order if `arg` is str or is list-like.\n",
    "    If :const:`True`, parses dates with the day first, e.g. :const:`\"10/11/12\"`\n",
    "    is parsed as :const:`2012-11-10`.\n",
    "\n",
    "    .. warning::\n",
    "\n",
    "        ``dayfirst=True`` is not strict, but will prefer to parse\n",
    "        with day first. If a delimited date string cannot be parsed in\n",
    "        accordance with the given `dayfirst` option, e.g.\n",
    "        ``to_datetime(['31-12-2021'])``, then a warning will be shown.\n",
    "\n",
    "yearfirst : bool, default False\n",
    "    Specify a date parse order if `arg` is str or is list-like.\n",
    "\n",
    "    - If :const:`True` parses dates with the year first, e.g.\n",
    "      :const:`\"10/11/12\"` is parsed as :const:`2010-11-12`.\n",
    "    - If both `dayfirst` and `yearfirst` are :const:`True`, `yearfirst` is\n",
    "      preceded (same as :mod:`dateutil`).\n",
    "\n",
    "    .. warning::\n",
    "\n",
    "        ``yearfirst=True`` is not strict, but will prefer to parse\n",
    "        with year first.\n",
    "\n",
    "utc : bool, default None\n",
    "    Control timezone-related parsing, localization and conversion.\n",
    "\n",
    "    - If :const:`True`, the function *always* returns a timezone-aware\n",
    "      UTC-localized :class:`Timestamp`, :class:`Series` or\n",
    "      :class:`DatetimeIndex`. To do this, timezone-naive inputs are\n",
    "      *localized* as UTC, while timezone-aware inputs are *converted* to UTC.\n",
    "\n",
    "    - If :const:`False` (default), inputs will not be coerced to UTC.\n",
    "      Timezone-naive inputs will remain naive, while timezone-aware ones\n",
    "      will keep their time offsets. Limitations exist for mixed\n",
    "      offsets (typically, daylight savings), see :ref:`Examples\n",
    "      <to_datetime_tz_examples>` section for details.\n",
    "\n",
    "    See also: pandas general documentation about `timezone conversion and\n",
    "    localization\n",
    "    <https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html\n",
    "    #time-zone-handling>`_.\n",
    "\n",
    "format : str, default None\n",
    "    The strftime to parse time, e.g. :const:`\"%d/%m/%Y\"`. Note that\n",
    "    :const:`\"%f\"` will parse all the way up to nanoseconds. See\n",
    "    `strftime documentation\n",
    "    <https://docs.python.org/3/library/datetime.html\n",
    "    #strftime-and-strptime-behavior>`_ for more information on choices.\n",
    "exact : bool, default True\n",
    "    Control how `format` is used:\n",
    "\n",
    "    - If :const:`True`, require an exact `format` match.\n",
    "    - If :const:`False`, allow the `format` to match anywhere in the target\n",
    "      string.\n",
    "\n",
    "unit : str, default 'ns'\n",
    "    The unit of the arg (D,s,ms,us,ns) denote the unit, which is an\n",
    "    integer or float number. This will be based off the origin.\n",
    "    Example, with ``unit='ms'`` and ``origin='unix'`` (the default), this\n",
    "    would calculate the number of milliseconds to the unix epoch start.\n",
    "infer_datetime_format : bool, default False\n",
    "    If :const:`True` and no `format` is given, attempt to infer the format\n",
    "    of the datetime strings based on the first non-NaN element,\n",
    "    and if it can be inferred, switch to a faster method of parsing them.\n",
    "    In some cases this can increase the parsing speed by ~5-10x.\n",
    "origin : scalar, default 'unix'\n",
    "    Define the reference date. The numeric values would be parsed as number\n",
    "    of units (defined by `unit`) since this reference date.\n",
    "\n",
    "    - If :const:`'unix'` (or POSIX) time; origin is set to 1970-01-01.\n",
    "    - If :const:`'julian'`, unit must be :const:`'D'`, and origin is set to\n",
    "      beginning of Julian Calendar. Julian day number :const:`0` is assigned\n",
    "      to the day starting at noon on January 1, 4713 BC.\n",
    "    - If Timestamp convertible, origin is set to Timestamp identified by\n",
    "      origin.\n",
    "cache : bool, default True\n",
    "    If :const:`True`, use a cache of unique, converted dates to apply the\n",
    "    datetime conversion. May produce significant speed-up when parsing\n",
    "    duplicate date strings, especially ones with timezone offsets. The cache\n",
    "    is only used when there are at least 50 values. The presence of\n",
    "    out-of-bounds values will render the cache unusable and may slow down\n",
    "    parsing.\n",
    "\n",
    "    .. versionchanged:: 0.25.0\n",
    "        changed default value from :const:`False` to :const:`True`.\n",
    "\n",
    "Returns\n",
    "-------\n",
    "datetime\n",
    "    If parsing succeeded.\n",
    "    Return type depends on input (types in parenthesis correspond to\n",
    "    fallback in case of unsuccessful timezone or out-of-range timestamp\n",
    "    parsing):\n",
    "\n",
    "    - scalar: :class:`Timestamp` (or :class:`datetime.datetime`)\n",
    "    - array-like: :class:`DatetimeIndex` (or :class:`Series` with\n",
    "      :class:`object` dtype containing :class:`datetime.datetime`)\n",
    "    - Series: :class:`Series` of :class:`datetime64` dtype (or\n",
    "      :class:`Series` of :class:`object` dtype containing\n",
    "      :class:`datetime.datetime`)\n",
    "    - DataFrame: :class:`Series` of :class:`datetime64` dtype (or\n",
    "      :class:`Series` of :class:`object` dtype containing\n",
    "      :class:`datetime.datetime`)\n",
    "\n",
    "Raises\n",
    "------\n",
    "ParserError\n",
    "    When parsing a date from string fails.\n",
    "ValueError\n",
    "    When another datetime conversion error happens. For example when one\n",
    "    of 'year', 'month', day' columns is missing in a :class:`DataFrame`, or\n",
    "    when a Timezone-aware :class:`datetime.datetime` is found in an array-like\n",
    "    of mixed time offsets, and ``utc=False``.\n",
    "\n",
    "See Also\n",
    "--------\n",
    "DataFrame.astype : Cast argument to a specified dtype.\n",
    "to_timedelta : Convert argument to timedelta.\n",
    "convert_dtypes : Convert dtypes.\n",
    "\n",
    "Notes\n",
    "-----\n",
    "\n",
    "Many input types are supported, and lead to different output types:\n",
    "\n",
    "- **scalars** can be int, float, str, datetime object (from stdlib :mod:`datetime`\n",
    "  module or :mod:`numpy`). They are converted to :class:`Timestamp` when\n",
    "  possible, otherwise they are converted to :class:`datetime.datetime`.\n",
    "  None/NaN/null scalars are converted to :const:`NaT`.\n",
    "\n",
    "- **array-like** can contain int, float, str, datetime objects. They are\n",
    "  converted to :class:`DatetimeIndex` when possible, otherwise they are\n",
    "  converted to :class:`Index` with :class:`object` dtype, containing\n",
    "  :class:`datetime.datetime`. None/NaN/null entries are converted to\n",
    "  :const:`NaT` in both cases.\n",
    "\n",
    "- **Series** are converted to :class:`Series` with :class:`datetime64`\n",
    "  dtype when possible, otherwise they are converted to :class:`Series` with\n",
    "  :class:`object` dtype, containing :class:`datetime.datetime`. None/NaN/null\n",
    "  entries are converted to :const:`NaT` in both cases.\n",
    "\n",
    "- **DataFrame/dict-like** are converted to :class:`Series` with\n",
    "  :class:`datetime64` dtype. For each row a datetime is created from assembling\n",
    "  the various dataframe columns. Column keys can be common abbreviations\n",
    "  like [‘year’, ‘month’, ‘day’, ‘minute’, ‘second’, ‘ms’, ‘us’, ‘ns’]) or\n",
    "  plurals of the same.\n",
    "\n",
    "The following causes are responsible for :class:`datetime.datetime` objects\n",
    "being returned (possibly inside an :class:`Index` or a :class:`Series` with\n",
    ":class:`object` dtype) instead of a proper pandas designated type\n",
    "(:class:`Timestamp`, :class:`DatetimeIndex` or :class:`Series`\n",
    "with :class:`datetime64` dtype):\n",
    "\n",
    "- when any input element is before :const:`Timestamp.min` or after\n",
    "  :const:`Timestamp.max`, see `timestamp limitations\n",
    "  <https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html\n",
    "  #timeseries-timestamp-limits>`_.\n",
    "\n",
    "- when ``utc=False`` (default) and the input is an array-like or\n",
    "  :class:`Series` containing mixed naive/aware datetime, or aware with mixed\n",
    "  time offsets. Note that this happens in the (quite frequent) situation when\n",
    "  the timezone has a daylight savings policy. In that case you may wish to\n",
    "  use ``utc=True``.\n",
    "\n",
    "Examples\n",
    "--------\n",
    "\n",
    "**Handling various input formats**\n",
    "\n",
    "Assembling a datetime from multiple columns of a :class:`DataFrame`. The keys\n",
    "can be common abbreviations like ['year', 'month', 'day', 'minute', 'second',\n",
    "'ms', 'us', 'ns']) or plurals of the same\n",
    "\n",
    ">>> df = pd.DataFrame({'year': [2015, 2016],\n",
    "...                    'month': [2, 3],\n",
    "...                    'day': [4, 5]})\n",
    ">>> pd.to_datetime(df)\n",
    "0   2015-02-04\n",
    "1   2016-03-05\n",
    "dtype: datetime64[ns]\n",
    "\n",
    "Passing ``infer_datetime_format=True`` can often-times speedup a parsing\n",
    "if its not an ISO8601 format exactly, but in a regular format.\n",
    "\n",
    ">>> s = pd.Series(['3/11/2000', '3/12/2000', '3/13/2000'] * 1000)\n",
    ">>> s.head()\n",
    "0    3/11/2000\n",
    "1    3/12/2000\n",
    "2    3/13/2000\n",
    "3    3/11/2000\n",
    "4    3/12/2000\n",
    "dtype: object\n",
    "\n",
    ">>> %timeit pd.to_datetime(s, infer_datetime_format=True)  # doctest: +SKIP\n",
    "100 loops, best of 3: 10.4 ms per loop\n",
    "\n",
    ">>> %timeit pd.to_datetime(s, infer_datetime_format=False)  # doctest: +SKIP\n",
    "1 loop, best of 3: 471 ms per loop\n",
    "\n",
    "Using a unix epoch time\n",
    "\n",
    ">>> pd.to_datetime(1490195805, unit='s')\n",
    "Timestamp('2017-03-22 15:16:45')\n",
    ">>> pd.to_datetime(1490195805433502912, unit='ns')\n",
    "Timestamp('2017-03-22 15:16:45.433502912')\n",
    "\n",
    ".. warning:: For float arg, precision rounding might happen. To prevent\n",
    "    unexpected behavior use a fixed-width exact type.\n",
    "\n",
    "Using a non-unix epoch origin\n",
    "\n",
    ">>> pd.to_datetime([1, 2, 3], unit='D',\n",
    "...                origin=pd.Timestamp('1960-01-01'))\n",
    "DatetimeIndex(['1960-01-02', '1960-01-03', '1960-01-04'],\n",
    "              dtype='datetime64[ns]', freq=None)\n",
    "\n",
    "**Non-convertible date/times**\n",
    "\n",
    "If a date does not meet the `timestamp limitations\n",
    "<https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html\n",
    "timeseries-timestamp-limits>`_, passing ``errors='ignore'``\n",
    "will return the original input instead of raising any exception.\n",
    "\n",
    "Passing ``errors='coerce'`` will force an out-of-bounds date to :const:`NaT`,\n",
    "in addition to forcing non-dates (or non-parseable dates) to :const:`NaT`.\n",
    "\n",
    ">>> pd.to_datetime('13000101', format='%Y%m%d', errors='ignore')\n",
    "datetime.datetime(1300, 1, 1, 0, 0)\n",
    ">>> pd.to_datetime('13000101', format='%Y%m%d', errors='coerce')\n",
    "NaT\n",
    "\n",
    ".. _to_datetime_tz_examples:\n",
    "\n",
    "**Timezones and time offsets**\n",
    "\n",
    "The default behaviour (``utc=False``) is as follows:\n",
    "\n",
    "- Timezone-naive inputs are converted to timezone-naive :class:`DatetimeIndex`:\n",
    "\n",
    ">>> pd.to_datetime(['2018-10-26 12:00', '2018-10-26 13:00:15'])\n",
    "DatetimeIndex(['2018-10-26 12:00:00', '2018-10-26 13:00:15'],\n",
    "              dtype='datetime64[ns]', freq=None)\n",
    "\n",
    "- Timezone-aware inputs *with constant time offset* are converted to\n",
    "  timezone-aware :class:`DatetimeIndex`:\n",
    "\n",
    ">>> pd.to_datetime(['2018-10-26 12:00 -0500', '2018-10-26 13:00 -0500'])\n",
    "DatetimeIndex(['2018-10-26 12:00:00-05:00', '2018-10-26 13:00:00-05:00'],\n",
    "              dtype='datetime64[ns, pytz.FixedOffset(-300)]', freq=None)\n",
    "\n",
    "- However, timezone-aware inputs *with mixed time offsets* (for example\n",
    "  issued from a timezone with daylight savings, such as Europe/Paris)\n",
    "  are **not successfully converted** to a :class:`DatetimeIndex`. Instead a\n",
    "  simple :class:`Index` containing :class:`datetime.datetime` objects is\n",
    "  returned:\n",
    "\n",
    ">>> pd.to_datetime(['2020-10-25 02:00 +0200', '2020-10-25 04:00 +0100'])\n",
    "Index([2020-10-25 02:00:00+02:00, 2020-10-25 04:00:00+01:00],\n",
    "      dtype='object')\n",
    "\n",
    "- A mix of timezone-aware and timezone-naive inputs is converted to\n",
    "  a timezone-aware :class:`DatetimeIndex` if the offsets of the timezone-aware\n",
    "  are constant:\n",
    "\n",
    ">>> from datetime import datetime\n",
    ">>> pd.to_datetime([\"2020-01-01 01:00 -01:00\", datetime(2020, 1, 1, 3, 0)])\n",
    "DatetimeIndex(['2020-01-01 01:00:00-01:00', '2020-01-01 02:00:00-01:00'],\n",
    "              dtype='datetime64[ns, pytz.FixedOffset(-60)]', freq=None)\n",
    "\n",
    "- Finally, mixing timezone-aware strings and :class:`datetime.datetime` always\n",
    "  raises an error, even if the elements all have the same time offset.\n",
    "\n",
    ">>> from datetime import datetime, timezone, timedelta\n",
    ">>> d = datetime(2020, 1, 1, 18, tzinfo=timezone(-timedelta(hours=1)))\n",
    ">>> pd.to_datetime([\"2020-01-01 17:00 -0100\", d])\n",
    "Traceback (most recent call last):\n",
    "    ...\n",
    "ValueError: Tz-aware datetime.datetime cannot be converted to datetime64\n",
    "            unless utc=True\n",
    "\n",
    "|\n",
    "\n",
    "Setting ``utc=True`` solves most of the above issues:\n",
    "\n",
    "- Timezone-naive inputs are *localized* as UTC\n",
    "\n",
    ">>> pd.to_datetime(['2018-10-26 12:00', '2018-10-26 13:00'], utc=True)\n",
    "DatetimeIndex(['2018-10-26 12:00:00+00:00', '2018-10-26 13:00:00+00:00'],\n",
    "              dtype='datetime64[ns, UTC]', freq=None)\n",
    "\n",
    "- Timezone-aware inputs are *converted* to UTC (the output represents the\n",
    "  exact same datetime, but viewed from the UTC time offset `+00:00`).\n",
    "\n",
    ">>> pd.to_datetime(['2018-10-26 12:00 -0530', '2018-10-26 12:00 -0500'],\n",
    "...                utc=True)\n",
    "DatetimeIndex(['2018-10-26 17:30:00+00:00', '2018-10-26 17:00:00+00:00'],\n",
    "              dtype='datetime64[ns, UTC]', freq=None)\n",
    "\n",
    "- Inputs can contain both naive and aware, string or datetime, the above\n",
    "  rules still apply\n",
    "\n",
    ">>> pd.to_datetime(['2018-10-26 12:00', '2018-10-26 12:00 -0530',\n",
    "...                datetime(2020, 1, 1, 18),\n",
    "...                datetime(2020, 1, 1, 18,\n",
    "...                tzinfo=timezone(-timedelta(hours=1)))],\n",
    "...                utc=True)\n",
    "DatetimeIndex(['2018-10-26 12:00:00+00:00', '2018-10-26 17:30:00+00:00',\n",
    "               '2020-01-01 18:00:00+00:00', '2020-01-01 19:00:00+00:00'],\n",
    "              dtype='datetime64[ns, UTC]', freq=None)\n",
    "\n",
    "</code>\n",
    "<a href='#15'>back to header</a>\n",
    "</blockquote>\n",
    "</details>\n",
    "</li>\n",
    "</ul>\n",
    "</li>\n",
    "\n",
    "</ul>\n",
    "</details> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69db8d1c",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "Calls.datetime = pd.to_datetime(Calls.datetime)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd0a3ab",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<div> <h3 class='hg'>16. Data Preparation | Feature Engineering</h3>  <a id='16'></a><small><a href='#top_phases'>back to top</a></small><details><summary style='list-style: none; cursor: pointer;'><u>View function calls</u></summary>\n",
    "<ul>\n",
    "\n",
    "<li> <strong class='hglib'>pandas</strong>\n",
    "<ul>\n",
    "<li>\n",
    "<details><summary style='list-style: none; cursor: pointer;'><u>pandas.core.series.Series.apply</u></summary>\n",
    "<blockquote>\n",
    "<code>\n",
    "Invoke function on values of Series.\n",
    "\n",
    "Can be ufunc (a NumPy function that applies to the entire Series)\n",
    "or a Python function that only works on single values.\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "func : function\n",
    "    Python function or NumPy ufunc to apply.\n",
    "convert_dtype : bool, default True\n",
    "    Try to find better dtype for elementwise function results. If\n",
    "    False, leave as dtype=object. Note that the dtype is always\n",
    "    preserved for some extension array dtypes, such as Categorical.\n",
    "args : tuple\n",
    "    Positional arguments passed to func after the series value.\n",
    "**kwargs\n",
    "    Additional keyword arguments passed to func.\n",
    "\n",
    "Returns\n",
    "-------\n",
    "Series or DataFrame\n",
    "    If func returns a Series object the result will be a DataFrame.\n",
    "\n",
    "See Also\n",
    "--------\n",
    "Series.map: For element-wise operations.\n",
    "Series.agg: Only perform aggregating type operations.\n",
    "Series.transform: Only perform transforming type operations.\n",
    "\n",
    "Notes\n",
    "-----\n",
    "Functions that mutate the passed object can produce unexpected\n",
    "behavior or errors and are not supported. See :ref:`gotchas.udf-mutation`\n",
    "for more details.\n",
    "\n",
    "Examples\n",
    "--------\n",
    "Create a series with typical summer temperatures for each city.\n",
    "\n",
    ">>> s = pd.Series([20, 21, 12],\n",
    "...               index=['London', 'New York', 'Helsinki'])\n",
    ">>> s\n",
    "London      20\n",
    "New York    21\n",
    "Helsinki    12\n",
    "dtype: int64\n",
    "\n",
    "Square the values by defining a function and passing it as an\n",
    "argument to ``apply()``.\n",
    "\n",
    ">>> def square(x):\n",
    "...     return x ** 2\n",
    ">>> s.apply(square)\n",
    "London      400\n",
    "New York    441\n",
    "Helsinki    144\n",
    "dtype: int64\n",
    "\n",
    "Square the values by passing an anonymous function as an\n",
    "argument to ``apply()``.\n",
    "\n",
    ">>> s.apply(lambda x: x ** 2)\n",
    "London      400\n",
    "New York    441\n",
    "Helsinki    144\n",
    "dtype: int64\n",
    "\n",
    "Define a custom function that needs additional positional\n",
    "arguments and pass these additional arguments using the\n",
    "``args`` keyword.\n",
    "\n",
    ">>> def subtract_custom_value(x, custom_value):\n",
    "...     return x - custom_value\n",
    "\n",
    ">>> s.apply(subtract_custom_value, args=(5,))\n",
    "London      15\n",
    "New York    16\n",
    "Helsinki     7\n",
    "dtype: int64\n",
    "\n",
    "Define a custom function that takes keyword arguments\n",
    "and pass these arguments to ``apply``.\n",
    "\n",
    ">>> def add_custom_values(x, **kwargs):\n",
    "...     for month in kwargs:\n",
    "...         x += kwargs[month]\n",
    "...     return x\n",
    "\n",
    ">>> s.apply(add_custom_values, june=30, july=20, august=25)\n",
    "London      95\n",
    "New York    96\n",
    "Helsinki    87\n",
    "dtype: int64\n",
    "\n",
    "Use a function from the Numpy library.\n",
    "\n",
    ">>> s.apply(np.log)\n",
    "London      2.995732\n",
    "New York    3.044522\n",
    "Helsinki    2.484907\n",
    "dtype: float64\n",
    "\n",
    "</code>\n",
    "<a href='#16'>back to header</a>\n",
    "</blockquote>\n",
    "</details>\n",
    "</li>\n",
    "<li>\n",
    "<details><summary style='list-style: none; cursor: pointer;'><u>pandas.core.frame.DataFrame.apply</u></summary>\n",
    "<blockquote>\n",
    "<code>\n",
    "Apply a function along an axis of the DataFrame.\n",
    "\n",
    "Objects passed to the function are Series objects whose index is\n",
    "either the DataFrame's index (``axis=0``) or the DataFrame's columns\n",
    "(``axis=1``). By default (``result_type=None``), the final return type\n",
    "is inferred from the return type of the applied function. Otherwise,\n",
    "it depends on the `result_type` argument.\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "func : function\n",
    "    Function to apply to each column or row.\n",
    "axis : {0 or 'index', 1 or 'columns'}, default 0\n",
    "    Axis along which the function is applied:\n",
    "\n",
    "    * 0 or 'index': apply function to each column.\n",
    "    * 1 or 'columns': apply function to each row.\n",
    "\n",
    "raw : bool, default False\n",
    "    Determines if row or column is passed as a Series or ndarray object:\n",
    "\n",
    "    * ``False`` : passes each row or column as a Series to the\n",
    "      function.\n",
    "    * ``True`` : the passed function will receive ndarray objects\n",
    "      instead.\n",
    "      If you are just applying a NumPy reduction function this will\n",
    "      achieve much better performance.\n",
    "\n",
    "result_type : {'expand', 'reduce', 'broadcast', None}, default None\n",
    "    These only act when ``axis=1`` (columns):\n",
    "\n",
    "    * 'expand' : list-like results will be turned into columns.\n",
    "    * 'reduce' : returns a Series if possible rather than expanding\n",
    "      list-like results. This is the opposite of 'expand'.\n",
    "    * 'broadcast' : results will be broadcast to the original shape\n",
    "      of the DataFrame, the original index and columns will be\n",
    "      retained.\n",
    "\n",
    "    The default behaviour (None) depends on the return value of the\n",
    "    applied function: list-like results will be returned as a Series\n",
    "    of those. However if the apply function returns a Series these\n",
    "    are expanded to columns.\n",
    "args : tuple\n",
    "    Positional arguments to pass to `func` in addition to the\n",
    "    array/series.\n",
    "**kwargs\n",
    "    Additional keyword arguments to pass as keywords arguments to\n",
    "    `func`.\n",
    "\n",
    "Returns\n",
    "-------\n",
    "Series or DataFrame\n",
    "    Result of applying ``func`` along the given axis of the\n",
    "    DataFrame.\n",
    "\n",
    "See Also\n",
    "--------\n",
    "DataFrame.applymap: For elementwise operations.\n",
    "DataFrame.aggregate: Only perform aggregating type operations.\n",
    "DataFrame.transform: Only perform transforming type operations.\n",
    "\n",
    "Notes\n",
    "-----\n",
    "Functions that mutate the passed object can produce unexpected\n",
    "behavior or errors and are not supported. See :ref:`gotchas.udf-mutation`\n",
    "for more details.\n",
    "\n",
    "Examples\n",
    "--------\n",
    ">>> df = pd.DataFrame([[4, 9]] * 3, columns=['A', 'B'])\n",
    ">>> df\n",
    "   A  B\n",
    "0  4  9\n",
    "1  4  9\n",
    "2  4  9\n",
    "\n",
    "Using a numpy universal function (in this case the same as\n",
    "``np.sqrt(df)``):\n",
    "\n",
    ">>> df.apply(np.sqrt)\n",
    "     A    B\n",
    "0  2.0  3.0\n",
    "1  2.0  3.0\n",
    "2  2.0  3.0\n",
    "\n",
    "Using a reducing function on either axis\n",
    "\n",
    ">>> df.apply(np.sum, axis=0)\n",
    "A    12\n",
    "B    27\n",
    "dtype: int64\n",
    "\n",
    ">>> df.apply(np.sum, axis=1)\n",
    "0    13\n",
    "1    13\n",
    "2    13\n",
    "dtype: int64\n",
    "\n",
    "Returning a list-like will result in a Series\n",
    "\n",
    ">>> df.apply(lambda x: [1, 2], axis=1)\n",
    "0    [1, 2]\n",
    "1    [1, 2]\n",
    "2    [1, 2]\n",
    "dtype: object\n",
    "\n",
    "Passing ``result_type='expand'`` will expand list-like results\n",
    "to columns of a Dataframe\n",
    "\n",
    ">>> df.apply(lambda x: [1, 2], axis=1, result_type='expand')\n",
    "   0  1\n",
    "0  1  2\n",
    "1  1  2\n",
    "2  1  2\n",
    "\n",
    "Returning a Series inside the function is similar to passing\n",
    "``result_type='expand'``. The resulting column names\n",
    "will be the Series index.\n",
    "\n",
    ">>> df.apply(lambda x: pd.Series([1, 2], index=['foo', 'bar']), axis=1)\n",
    "   foo  bar\n",
    "0    1    2\n",
    "1    1    2\n",
    "2    1    2\n",
    "\n",
    "Passing ``result_type='broadcast'`` will ensure the same shape\n",
    "result, whether list-like or scalar is returned by the function,\n",
    "and broadcast it along the axis. The resulting column names will\n",
    "be the originals.\n",
    "\n",
    ">>> df.apply(lambda x: [1, 2], axis=1, result_type='broadcast')\n",
    "   A  B\n",
    "0  1  2\n",
    "1  1  2\n",
    "2  1  2\n",
    "\n",
    "</code>\n",
    "<a href='#16'>back to header</a>\n",
    "</blockquote>\n",
    "</details>\n",
    "</li>\n",
    "</ul>\n",
    "</li>\n",
    "\n",
    "</ul>\n",
    "</details> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af34a39b",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "fun = lambda x:x.time()\n",
    "Calls['time'] = Calls.datetime.apply(fun)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ebfd32",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<div> <h3 class='hg'>17. Data Preparation</h3>  <a id='17'></a><small><a href='#top_phases'>back to top</a></small><details><summary style='list-style: none; cursor: pointer;'><u>View function calls</u></summary>\n",
    "<ul>\n",
    "\n",
    "<li> <strong class='hglib'>pandas</strong>\n",
    "<ul>\n",
    "<li>\n",
    "<details><summary style='list-style: none; cursor: pointer;'><u>pandas.core.generic.NDFrame.head</u></summary>\n",
    "<blockquote>\n",
    "<code>\n",
    "Return the first `n` rows.\n",
    "\n",
    "This function returns the first `n` rows for the object based\n",
    "on position. It is useful for quickly testing if your object\n",
    "has the right type of data in it.\n",
    "\n",
    "For negative values of `n`, this function returns all rows except\n",
    "the last `n` rows, equivalent to ``df[:-n]``.\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "n : int, default 5\n",
    "    Number of rows to select.\n",
    "\n",
    "Returns\n",
    "-------\n",
    "same type as caller\n",
    "    The first `n` rows of the caller object.\n",
    "\n",
    "See Also\n",
    "--------\n",
    "DataFrame.tail: Returns the last `n` rows.\n",
    "\n",
    "Examples\n",
    "--------\n",
    ">>> df = pd.DataFrame({'animal': ['alligator', 'bee', 'falcon', 'lion',\n",
    "...                    'monkey', 'parrot', 'shark', 'whale', 'zebra']})\n",
    ">>> df\n",
    "      animal\n",
    "0  alligator\n",
    "1        bee\n",
    "2     falcon\n",
    "3       lion\n",
    "4     monkey\n",
    "5     parrot\n",
    "6      shark\n",
    "7      whale\n",
    "8      zebra\n",
    "\n",
    "Viewing the first 5 lines\n",
    "\n",
    ">>> df.head()\n",
    "      animal\n",
    "0  alligator\n",
    "1        bee\n",
    "2     falcon\n",
    "3       lion\n",
    "4     monkey\n",
    "\n",
    "Viewing the first `n` lines (three in this case)\n",
    "\n",
    ">>> df.head(3)\n",
    "      animal\n",
    "0  alligator\n",
    "1        bee\n",
    "2     falcon\n",
    "\n",
    "For negative values of `n`\n",
    "\n",
    ">>> df.head(-3)\n",
    "      animal\n",
    "0  alligator\n",
    "1        bee\n",
    "2     falcon\n",
    "3       lion\n",
    "4     monkey\n",
    "5     parrot\n",
    "\n",
    "</code>\n",
    "<a href='#17'>back to header</a>\n",
    "</blockquote>\n",
    "</details>\n",
    "</li>\n",
    "</ul>\n",
    "</li>\n",
    "\n",
    "</ul>\n",
    "</details> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7e14d7",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "Calls.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02477f9",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<div> <h3 class='hg'>18. Data Preparation | Feature Engineering | Library Loading</h3>  <a id='18'></a><small><a href='#top_phases'>back to top</a></small><details><summary style='list-style: none; cursor: pointer;'><u>View function calls</u></summary>\n",
    "<ul>\n",
    "\n",
    "<li> <strong class='hglib'>datetime</strong>\n",
    "<ul>\n",
    "<li>\n",
    "<details><summary style='list-style: none; cursor: pointer;'><u>datetime.time</u></summary>\n",
    "<blockquote>\n",
    "<code>\n",
    "time([hour[, minute[, second[, microsecond[, tzinfo]]]]]) --> a time object\n",
    "\n",
    "All arguments are optional. tzinfo may be None, or an instance of\n",
    "a tzinfo subclass. The remaining arguments may be ints.\n",
    "\n",
    "</code>\n",
    "<a href='#18'>back to header</a>\n",
    "</blockquote>\n",
    "</details>\n",
    "</li>\n",
    "</ul>\n",
    "</li>\n",
    "<li> <strong class='hglib'>pandas</strong>\n",
    "<ul>\n",
    "<li>\n",
    "<details><summary style='list-style: none; cursor: pointer;'><u>pandas.core.series.Series.apply</u></summary>\n",
    "<blockquote>\n",
    "<code>\n",
    "Invoke function on values of Series.\n",
    "\n",
    "Can be ufunc (a NumPy function that applies to the entire Series)\n",
    "or a Python function that only works on single values.\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "func : function\n",
    "    Python function or NumPy ufunc to apply.\n",
    "convert_dtype : bool, default True\n",
    "    Try to find better dtype for elementwise function results. If\n",
    "    False, leave as dtype=object. Note that the dtype is always\n",
    "    preserved for some extension array dtypes, such as Categorical.\n",
    "args : tuple\n",
    "    Positional arguments passed to func after the series value.\n",
    "**kwargs\n",
    "    Additional keyword arguments passed to func.\n",
    "\n",
    "Returns\n",
    "-------\n",
    "Series or DataFrame\n",
    "    If func returns a Series object the result will be a DataFrame.\n",
    "\n",
    "See Also\n",
    "--------\n",
    "Series.map: For element-wise operations.\n",
    "Series.agg: Only perform aggregating type operations.\n",
    "Series.transform: Only perform transforming type operations.\n",
    "\n",
    "Notes\n",
    "-----\n",
    "Functions that mutate the passed object can produce unexpected\n",
    "behavior or errors and are not supported. See :ref:`gotchas.udf-mutation`\n",
    "for more details.\n",
    "\n",
    "Examples\n",
    "--------\n",
    "Create a series with typical summer temperatures for each city.\n",
    "\n",
    ">>> s = pd.Series([20, 21, 12],\n",
    "...               index=['London', 'New York', 'Helsinki'])\n",
    ">>> s\n",
    "London      20\n",
    "New York    21\n",
    "Helsinki    12\n",
    "dtype: int64\n",
    "\n",
    "Square the values by defining a function and passing it as an\n",
    "argument to ``apply()``.\n",
    "\n",
    ">>> def square(x):\n",
    "...     return x ** 2\n",
    ">>> s.apply(square)\n",
    "London      400\n",
    "New York    441\n",
    "Helsinki    144\n",
    "dtype: int64\n",
    "\n",
    "Square the values by passing an anonymous function as an\n",
    "argument to ``apply()``.\n",
    "\n",
    ">>> s.apply(lambda x: x ** 2)\n",
    "London      400\n",
    "New York    441\n",
    "Helsinki    144\n",
    "dtype: int64\n",
    "\n",
    "Define a custom function that needs additional positional\n",
    "arguments and pass these additional arguments using the\n",
    "``args`` keyword.\n",
    "\n",
    ">>> def subtract_custom_value(x, custom_value):\n",
    "...     return x - custom_value\n",
    "\n",
    ">>> s.apply(subtract_custom_value, args=(5,))\n",
    "London      15\n",
    "New York    16\n",
    "Helsinki     7\n",
    "dtype: int64\n",
    "\n",
    "Define a custom function that takes keyword arguments\n",
    "and pass these arguments to ``apply``.\n",
    "\n",
    ">>> def add_custom_values(x, **kwargs):\n",
    "...     for month in kwargs:\n",
    "...         x += kwargs[month]\n",
    "...     return x\n",
    "\n",
    ">>> s.apply(add_custom_values, june=30, july=20, august=25)\n",
    "London      95\n",
    "New York    96\n",
    "Helsinki    87\n",
    "dtype: int64\n",
    "\n",
    "Use a function from the Numpy library.\n",
    "\n",
    ">>> s.apply(np.log)\n",
    "London      2.995732\n",
    "New York    3.044522\n",
    "Helsinki    2.484907\n",
    "dtype: float64\n",
    "\n",
    "</code>\n",
    "<a href='#18'>back to header</a>\n",
    "</blockquote>\n",
    "</details>\n",
    "</li>\n",
    "<li>\n",
    "<details><summary style='list-style: none; cursor: pointer;'><u>pandas.core.frame.DataFrame.apply</u></summary>\n",
    "<blockquote>\n",
    "<code>\n",
    "Apply a function along an axis of the DataFrame.\n",
    "\n",
    "Objects passed to the function are Series objects whose index is\n",
    "either the DataFrame's index (``axis=0``) or the DataFrame's columns\n",
    "(``axis=1``). By default (``result_type=None``), the final return type\n",
    "is inferred from the return type of the applied function. Otherwise,\n",
    "it depends on the `result_type` argument.\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "func : function\n",
    "    Function to apply to each column or row.\n",
    "axis : {0 or 'index', 1 or 'columns'}, default 0\n",
    "    Axis along which the function is applied:\n",
    "\n",
    "    * 0 or 'index': apply function to each column.\n",
    "    * 1 or 'columns': apply function to each row.\n",
    "\n",
    "raw : bool, default False\n",
    "    Determines if row or column is passed as a Series or ndarray object:\n",
    "\n",
    "    * ``False`` : passes each row or column as a Series to the\n",
    "      function.\n",
    "    * ``True`` : the passed function will receive ndarray objects\n",
    "      instead.\n",
    "      If you are just applying a NumPy reduction function this will\n",
    "      achieve much better performance.\n",
    "\n",
    "result_type : {'expand', 'reduce', 'broadcast', None}, default None\n",
    "    These only act when ``axis=1`` (columns):\n",
    "\n",
    "    * 'expand' : list-like results will be turned into columns.\n",
    "    * 'reduce' : returns a Series if possible rather than expanding\n",
    "      list-like results. This is the opposite of 'expand'.\n",
    "    * 'broadcast' : results will be broadcast to the original shape\n",
    "      of the DataFrame, the original index and columns will be\n",
    "      retained.\n",
    "\n",
    "    The default behaviour (None) depends on the return value of the\n",
    "    applied function: list-like results will be returned as a Series\n",
    "    of those. However if the apply function returns a Series these\n",
    "    are expanded to columns.\n",
    "args : tuple\n",
    "    Positional arguments to pass to `func` in addition to the\n",
    "    array/series.\n",
    "**kwargs\n",
    "    Additional keyword arguments to pass as keywords arguments to\n",
    "    `func`.\n",
    "\n",
    "Returns\n",
    "-------\n",
    "Series or DataFrame\n",
    "    Result of applying ``func`` along the given axis of the\n",
    "    DataFrame.\n",
    "\n",
    "See Also\n",
    "--------\n",
    "DataFrame.applymap: For elementwise operations.\n",
    "DataFrame.aggregate: Only perform aggregating type operations.\n",
    "DataFrame.transform: Only perform transforming type operations.\n",
    "\n",
    "Notes\n",
    "-----\n",
    "Functions that mutate the passed object can produce unexpected\n",
    "behavior or errors and are not supported. See :ref:`gotchas.udf-mutation`\n",
    "for more details.\n",
    "\n",
    "Examples\n",
    "--------\n",
    ">>> df = pd.DataFrame([[4, 9]] * 3, columns=['A', 'B'])\n",
    ">>> df\n",
    "   A  B\n",
    "0  4  9\n",
    "1  4  9\n",
    "2  4  9\n",
    "\n",
    "Using a numpy universal function (in this case the same as\n",
    "``np.sqrt(df)``):\n",
    "\n",
    ">>> df.apply(np.sqrt)\n",
    "     A    B\n",
    "0  2.0  3.0\n",
    "1  2.0  3.0\n",
    "2  2.0  3.0\n",
    "\n",
    "Using a reducing function on either axis\n",
    "\n",
    ">>> df.apply(np.sum, axis=0)\n",
    "A    12\n",
    "B    27\n",
    "dtype: int64\n",
    "\n",
    ">>> df.apply(np.sum, axis=1)\n",
    "0    13\n",
    "1    13\n",
    "2    13\n",
    "dtype: int64\n",
    "\n",
    "Returning a list-like will result in a Series\n",
    "\n",
    ">>> df.apply(lambda x: [1, 2], axis=1)\n",
    "0    [1, 2]\n",
    "1    [1, 2]\n",
    "2    [1, 2]\n",
    "dtype: object\n",
    "\n",
    "Passing ``result_type='expand'`` will expand list-like results\n",
    "to columns of a Dataframe\n",
    "\n",
    ">>> df.apply(lambda x: [1, 2], axis=1, result_type='expand')\n",
    "   0  1\n",
    "0  1  2\n",
    "1  1  2\n",
    "2  1  2\n",
    "\n",
    "Returning a Series inside the function is similar to passing\n",
    "``result_type='expand'``. The resulting column names\n",
    "will be the Series index.\n",
    "\n",
    ">>> df.apply(lambda x: pd.Series([1, 2], index=['foo', 'bar']), axis=1)\n",
    "   foo  bar\n",
    "0    1    2\n",
    "1    1    2\n",
    "2    1    2\n",
    "\n",
    "Passing ``result_type='broadcast'`` will ensure the same shape\n",
    "result, whether list-like or scalar is returned by the function,\n",
    "and broadcast it along the axis. The resulting column names will\n",
    "be the originals.\n",
    "\n",
    ">>> df.apply(lambda x: [1, 2], axis=1, result_type='broadcast')\n",
    "   A  B\n",
    "0  1  2\n",
    "1  1  2\n",
    "2  1  2\n",
    "\n",
    "</code>\n",
    "<a href='#18'>back to header</a>\n",
    "</blockquote>\n",
    "</details>\n",
    "</li>\n",
    "</ul>\n",
    "</li>\n",
    "\n",
    "</ul>\n",
    "</details> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d89a27",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "from datetime import time\n",
    "\n",
    "office_time_start = time(10, 0)\n",
    "office_time_end = time(18, 0)\n",
    "\n",
    "fun = lambda x: x > office_time_start and x < office_time_end\n",
    "Calls['inOffice'] = Calls.time.apply(fun)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0c29aa",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<div> <h3 class='hg'>19. Data Preparation</h3>  <a id='19'></a><small><a href='#top_phases'>back to top</a></small><details><summary style='list-style: none; cursor: pointer;'><u>View function calls</u></summary>\n",
    "<ul>\n",
    "\n",
    "<li> <strong class='hglib'>pandas</strong>\n",
    "<ul>\n",
    "<li>\n",
    "<details><summary style='list-style: none; cursor: pointer;'><u>pandas.core.generic.NDFrame.head</u></summary>\n",
    "<blockquote>\n",
    "<code>\n",
    "Return the first `n` rows.\n",
    "\n",
    "This function returns the first `n` rows for the object based\n",
    "on position. It is useful for quickly testing if your object\n",
    "has the right type of data in it.\n",
    "\n",
    "For negative values of `n`, this function returns all rows except\n",
    "the last `n` rows, equivalent to ``df[:-n]``.\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "n : int, default 5\n",
    "    Number of rows to select.\n",
    "\n",
    "Returns\n",
    "-------\n",
    "same type as caller\n",
    "    The first `n` rows of the caller object.\n",
    "\n",
    "See Also\n",
    "--------\n",
    "DataFrame.tail: Returns the last `n` rows.\n",
    "\n",
    "Examples\n",
    "--------\n",
    ">>> df = pd.DataFrame({'animal': ['alligator', 'bee', 'falcon', 'lion',\n",
    "...                    'monkey', 'parrot', 'shark', 'whale', 'zebra']})\n",
    ">>> df\n",
    "      animal\n",
    "0  alligator\n",
    "1        bee\n",
    "2     falcon\n",
    "3       lion\n",
    "4     monkey\n",
    "5     parrot\n",
    "6      shark\n",
    "7      whale\n",
    "8      zebra\n",
    "\n",
    "Viewing the first 5 lines\n",
    "\n",
    ">>> df.head()\n",
    "      animal\n",
    "0  alligator\n",
    "1        bee\n",
    "2     falcon\n",
    "3       lion\n",
    "4     monkey\n",
    "\n",
    "Viewing the first `n` lines (three in this case)\n",
    "\n",
    ">>> df.head(3)\n",
    "      animal\n",
    "0  alligator\n",
    "1        bee\n",
    "2     falcon\n",
    "\n",
    "For negative values of `n`\n",
    "\n",
    ">>> df.head(-3)\n",
    "      animal\n",
    "0  alligator\n",
    "1        bee\n",
    "2     falcon\n",
    "3       lion\n",
    "4     monkey\n",
    "5     parrot\n",
    "\n",
    "</code>\n",
    "<a href='#19'>back to header</a>\n",
    "</blockquote>\n",
    "</details>\n",
    "</li>\n",
    "</ul>\n",
    "</li>\n",
    "\n",
    "</ul>\n",
    "</details> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28823bc",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "Calls.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8bed7d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<div> <h3 class='hg'>20. Data Preparation</h3>  <a id='20'></a><small><a href='#top_phases'>back to top</a></small><details><summary style='list-style: none; cursor: pointer;'><u>View function calls</u></summary>\n",
    "<ul>\n",
    "\n",
    "<li> <strong class='hglib'>pandas</strong>\n",
    "<ul>\n",
    "<li>\n",
    "<details><summary style='list-style: none; cursor: pointer;'><u>pandas.core.generic.NDFrame.head</u></summary>\n",
    "<blockquote>\n",
    "<code>\n",
    "Return the first `n` rows.\n",
    "\n",
    "This function returns the first `n` rows for the object based\n",
    "on position. It is useful for quickly testing if your object\n",
    "has the right type of data in it.\n",
    "\n",
    "For negative values of `n`, this function returns all rows except\n",
    "the last `n` rows, equivalent to ``df[:-n]``.\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "n : int, default 5\n",
    "    Number of rows to select.\n",
    "\n",
    "Returns\n",
    "-------\n",
    "same type as caller\n",
    "    The first `n` rows of the caller object.\n",
    "\n",
    "See Also\n",
    "--------\n",
    "DataFrame.tail: Returns the last `n` rows.\n",
    "\n",
    "Examples\n",
    "--------\n",
    ">>> df = pd.DataFrame({'animal': ['alligator', 'bee', 'falcon', 'lion',\n",
    "...                    'monkey', 'parrot', 'shark', 'whale', 'zebra']})\n",
    ">>> df\n",
    "      animal\n",
    "0  alligator\n",
    "1        bee\n",
    "2     falcon\n",
    "3       lion\n",
    "4     monkey\n",
    "5     parrot\n",
    "6      shark\n",
    "7      whale\n",
    "8      zebra\n",
    "\n",
    "Viewing the first 5 lines\n",
    "\n",
    ">>> df.head()\n",
    "      animal\n",
    "0  alligator\n",
    "1        bee\n",
    "2     falcon\n",
    "3       lion\n",
    "4     monkey\n",
    "\n",
    "Viewing the first `n` lines (three in this case)\n",
    "\n",
    ">>> df.head(3)\n",
    "      animal\n",
    "0  alligator\n",
    "1        bee\n",
    "2     falcon\n",
    "\n",
    "For negative values of `n`\n",
    "\n",
    ">>> df.head(-3)\n",
    "      animal\n",
    "0  alligator\n",
    "1        bee\n",
    "2     falcon\n",
    "3       lion\n",
    "4     monkey\n",
    "5     parrot\n",
    "\n",
    "</code>\n",
    "<a href='#20'>back to header</a>\n",
    "</blockquote>\n",
    "</details>\n",
    "</li>\n",
    "</ul>\n",
    "</li>\n",
    "\n",
    "</ul>\n",
    "</details> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d917fcac",
   "metadata": {},
   "outputs": [],
   "source": [
    "SMS.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6399446",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# SMS.columns = ['user.id', 'datetime', 'duration', 'dest.user.id', 'dest.phone.hash',\n",
    "#        'id_tuple', 'relationship', 'isCall', 'isSMS', 'isCloseFriend']\n",
    "# SMS.datetime = pd.to_datetime(SMS.datetime)\n",
    "# fun1 = lambda x : x.time()\n",
    "# SMS['time'] = SMS.datetime.apply(fun1)\n",
    "# fun2 = lambda x : x > office_time_start and x < office_time_end\n",
    "# SMS['isOffice'] = SMS.time.apply(fun2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95c2090",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<div> <h3 class='hg'>22. Data Preparation</h3>  <a id='22'></a><small><a href='#top_phases'>back to top</a></small> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13a1ef6",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "SMS.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434aa43b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<div> <h3 class='hg'>23. Data Preparation</h3>  <a id='23'></a><small><a href='#top_phases'>back to top</a></small> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bdadfd0",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "## move out SMS's that user.id and dest.id are the same\n",
    "SMS = SMS.ix[SMS['user.id'] != SMS['dest.user.id'], :]\n",
    "SMS.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0054bf37",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<div> <h3 class='hg'>24. Data Preparation</h3>  <a id='24'></a><small><a href='#top_phases'>back to top</a></small> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25f0d23",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "SMS.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f866fa0d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<div> <h3 class='hg'>25. Data Preparation | Feature Engineering</h3>  <a id='25'></a><small><a href='#top_phases'>back to top</a></small><details><summary style='list-style: none; cursor: pointer;'><u>View function calls</u></summary>\n",
    "<ul>\n",
    "\n",
    "<li> <strong class='hglib'>pandas</strong>\n",
    "<ul>\n",
    "<li>\n",
    "<details><summary style='list-style: none; cursor: pointer;'><u>pandas.core.tools.datetimes.to_datetime</u></summary>\n",
    "<blockquote>\n",
    "<code>\n",
    "Convert argument to datetime.\n",
    "\n",
    "This function converts a scalar, array-like, :class:`Series` or\n",
    ":class:`DataFrame`/dict-like to a pandas datetime object.\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "arg : int, float, str, datetime, list, tuple, 1-d array, Series, DataFrame/dict-like\n",
    "    The object to convert to a datetime. If a :class:`DataFrame` is provided, the\n",
    "    method expects minimally the following columns: :const:`\"year\"`,\n",
    "    :const:`\"month\"`, :const:`\"day\"`.\n",
    "errors : {'ignore', 'raise', 'coerce'}, default 'raise'\n",
    "    - If :const:`'raise'`, then invalid parsing will raise an exception.\n",
    "    - If :const:`'coerce'`, then invalid parsing will be set as :const:`NaT`.\n",
    "    - If :const:`'ignore'`, then invalid parsing will return the input.\n",
    "dayfirst : bool, default False\n",
    "    Specify a date parse order if `arg` is str or is list-like.\n",
    "    If :const:`True`, parses dates with the day first, e.g. :const:`\"10/11/12\"`\n",
    "    is parsed as :const:`2012-11-10`.\n",
    "\n",
    "    .. warning::\n",
    "\n",
    "        ``dayfirst=True`` is not strict, but will prefer to parse\n",
    "        with day first. If a delimited date string cannot be parsed in\n",
    "        accordance with the given `dayfirst` option, e.g.\n",
    "        ``to_datetime(['31-12-2021'])``, then a warning will be shown.\n",
    "\n",
    "yearfirst : bool, default False\n",
    "    Specify a date parse order if `arg` is str or is list-like.\n",
    "\n",
    "    - If :const:`True` parses dates with the year first, e.g.\n",
    "      :const:`\"10/11/12\"` is parsed as :const:`2010-11-12`.\n",
    "    - If both `dayfirst` and `yearfirst` are :const:`True`, `yearfirst` is\n",
    "      preceded (same as :mod:`dateutil`).\n",
    "\n",
    "    .. warning::\n",
    "\n",
    "        ``yearfirst=True`` is not strict, but will prefer to parse\n",
    "        with year first.\n",
    "\n",
    "utc : bool, default None\n",
    "    Control timezone-related parsing, localization and conversion.\n",
    "\n",
    "    - If :const:`True`, the function *always* returns a timezone-aware\n",
    "      UTC-localized :class:`Timestamp`, :class:`Series` or\n",
    "      :class:`DatetimeIndex`. To do this, timezone-naive inputs are\n",
    "      *localized* as UTC, while timezone-aware inputs are *converted* to UTC.\n",
    "\n",
    "    - If :const:`False` (default), inputs will not be coerced to UTC.\n",
    "      Timezone-naive inputs will remain naive, while timezone-aware ones\n",
    "      will keep their time offsets. Limitations exist for mixed\n",
    "      offsets (typically, daylight savings), see :ref:`Examples\n",
    "      <to_datetime_tz_examples>` section for details.\n",
    "\n",
    "    See also: pandas general documentation about `timezone conversion and\n",
    "    localization\n",
    "    <https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html\n",
    "    #time-zone-handling>`_.\n",
    "\n",
    "format : str, default None\n",
    "    The strftime to parse time, e.g. :const:`\"%d/%m/%Y\"`. Note that\n",
    "    :const:`\"%f\"` will parse all the way up to nanoseconds. See\n",
    "    `strftime documentation\n",
    "    <https://docs.python.org/3/library/datetime.html\n",
    "    #strftime-and-strptime-behavior>`_ for more information on choices.\n",
    "exact : bool, default True\n",
    "    Control how `format` is used:\n",
    "\n",
    "    - If :const:`True`, require an exact `format` match.\n",
    "    - If :const:`False`, allow the `format` to match anywhere in the target\n",
    "      string.\n",
    "\n",
    "unit : str, default 'ns'\n",
    "    The unit of the arg (D,s,ms,us,ns) denote the unit, which is an\n",
    "    integer or float number. This will be based off the origin.\n",
    "    Example, with ``unit='ms'`` and ``origin='unix'`` (the default), this\n",
    "    would calculate the number of milliseconds to the unix epoch start.\n",
    "infer_datetime_format : bool, default False\n",
    "    If :const:`True` and no `format` is given, attempt to infer the format\n",
    "    of the datetime strings based on the first non-NaN element,\n",
    "    and if it can be inferred, switch to a faster method of parsing them.\n",
    "    In some cases this can increase the parsing speed by ~5-10x.\n",
    "origin : scalar, default 'unix'\n",
    "    Define the reference date. The numeric values would be parsed as number\n",
    "    of units (defined by `unit`) since this reference date.\n",
    "\n",
    "    - If :const:`'unix'` (or POSIX) time; origin is set to 1970-01-01.\n",
    "    - If :const:`'julian'`, unit must be :const:`'D'`, and origin is set to\n",
    "      beginning of Julian Calendar. Julian day number :const:`0` is assigned\n",
    "      to the day starting at noon on January 1, 4713 BC.\n",
    "    - If Timestamp convertible, origin is set to Timestamp identified by\n",
    "      origin.\n",
    "cache : bool, default True\n",
    "    If :const:`True`, use a cache of unique, converted dates to apply the\n",
    "    datetime conversion. May produce significant speed-up when parsing\n",
    "    duplicate date strings, especially ones with timezone offsets. The cache\n",
    "    is only used when there are at least 50 values. The presence of\n",
    "    out-of-bounds values will render the cache unusable and may slow down\n",
    "    parsing.\n",
    "\n",
    "    .. versionchanged:: 0.25.0\n",
    "        changed default value from :const:`False` to :const:`True`.\n",
    "\n",
    "Returns\n",
    "-------\n",
    "datetime\n",
    "    If parsing succeeded.\n",
    "    Return type depends on input (types in parenthesis correspond to\n",
    "    fallback in case of unsuccessful timezone or out-of-range timestamp\n",
    "    parsing):\n",
    "\n",
    "    - scalar: :class:`Timestamp` (or :class:`datetime.datetime`)\n",
    "    - array-like: :class:`DatetimeIndex` (or :class:`Series` with\n",
    "      :class:`object` dtype containing :class:`datetime.datetime`)\n",
    "    - Series: :class:`Series` of :class:`datetime64` dtype (or\n",
    "      :class:`Series` of :class:`object` dtype containing\n",
    "      :class:`datetime.datetime`)\n",
    "    - DataFrame: :class:`Series` of :class:`datetime64` dtype (or\n",
    "      :class:`Series` of :class:`object` dtype containing\n",
    "      :class:`datetime.datetime`)\n",
    "\n",
    "Raises\n",
    "------\n",
    "ParserError\n",
    "    When parsing a date from string fails.\n",
    "ValueError\n",
    "    When another datetime conversion error happens. For example when one\n",
    "    of 'year', 'month', day' columns is missing in a :class:`DataFrame`, or\n",
    "    when a Timezone-aware :class:`datetime.datetime` is found in an array-like\n",
    "    of mixed time offsets, and ``utc=False``.\n",
    "\n",
    "See Also\n",
    "--------\n",
    "DataFrame.astype : Cast argument to a specified dtype.\n",
    "to_timedelta : Convert argument to timedelta.\n",
    "convert_dtypes : Convert dtypes.\n",
    "\n",
    "Notes\n",
    "-----\n",
    "\n",
    "Many input types are supported, and lead to different output types:\n",
    "\n",
    "- **scalars** can be int, float, str, datetime object (from stdlib :mod:`datetime`\n",
    "  module or :mod:`numpy`). They are converted to :class:`Timestamp` when\n",
    "  possible, otherwise they are converted to :class:`datetime.datetime`.\n",
    "  None/NaN/null scalars are converted to :const:`NaT`.\n",
    "\n",
    "- **array-like** can contain int, float, str, datetime objects. They are\n",
    "  converted to :class:`DatetimeIndex` when possible, otherwise they are\n",
    "  converted to :class:`Index` with :class:`object` dtype, containing\n",
    "  :class:`datetime.datetime`. None/NaN/null entries are converted to\n",
    "  :const:`NaT` in both cases.\n",
    "\n",
    "- **Series** are converted to :class:`Series` with :class:`datetime64`\n",
    "  dtype when possible, otherwise they are converted to :class:`Series` with\n",
    "  :class:`object` dtype, containing :class:`datetime.datetime`. None/NaN/null\n",
    "  entries are converted to :const:`NaT` in both cases.\n",
    "\n",
    "- **DataFrame/dict-like** are converted to :class:`Series` with\n",
    "  :class:`datetime64` dtype. For each row a datetime is created from assembling\n",
    "  the various dataframe columns. Column keys can be common abbreviations\n",
    "  like [‘year’, ‘month’, ‘day’, ‘minute’, ‘second’, ‘ms’, ‘us’, ‘ns’]) or\n",
    "  plurals of the same.\n",
    "\n",
    "The following causes are responsible for :class:`datetime.datetime` objects\n",
    "being returned (possibly inside an :class:`Index` or a :class:`Series` with\n",
    ":class:`object` dtype) instead of a proper pandas designated type\n",
    "(:class:`Timestamp`, :class:`DatetimeIndex` or :class:`Series`\n",
    "with :class:`datetime64` dtype):\n",
    "\n",
    "- when any input element is before :const:`Timestamp.min` or after\n",
    "  :const:`Timestamp.max`, see `timestamp limitations\n",
    "  <https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html\n",
    "  #timeseries-timestamp-limits>`_.\n",
    "\n",
    "- when ``utc=False`` (default) and the input is an array-like or\n",
    "  :class:`Series` containing mixed naive/aware datetime, or aware with mixed\n",
    "  time offsets. Note that this happens in the (quite frequent) situation when\n",
    "  the timezone has a daylight savings policy. In that case you may wish to\n",
    "  use ``utc=True``.\n",
    "\n",
    "Examples\n",
    "--------\n",
    "\n",
    "**Handling various input formats**\n",
    "\n",
    "Assembling a datetime from multiple columns of a :class:`DataFrame`. The keys\n",
    "can be common abbreviations like ['year', 'month', 'day', 'minute', 'second',\n",
    "'ms', 'us', 'ns']) or plurals of the same\n",
    "\n",
    ">>> df = pd.DataFrame({'year': [2015, 2016],\n",
    "...                    'month': [2, 3],\n",
    "...                    'day': [4, 5]})\n",
    ">>> pd.to_datetime(df)\n",
    "0   2015-02-04\n",
    "1   2016-03-05\n",
    "dtype: datetime64[ns]\n",
    "\n",
    "Passing ``infer_datetime_format=True`` can often-times speedup a parsing\n",
    "if its not an ISO8601 format exactly, but in a regular format.\n",
    "\n",
    ">>> s = pd.Series(['3/11/2000', '3/12/2000', '3/13/2000'] * 1000)\n",
    ">>> s.head()\n",
    "0    3/11/2000\n",
    "1    3/12/2000\n",
    "2    3/13/2000\n",
    "3    3/11/2000\n",
    "4    3/12/2000\n",
    "dtype: object\n",
    "\n",
    ">>> %timeit pd.to_datetime(s, infer_datetime_format=True)  # doctest: +SKIP\n",
    "100 loops, best of 3: 10.4 ms per loop\n",
    "\n",
    ">>> %timeit pd.to_datetime(s, infer_datetime_format=False)  # doctest: +SKIP\n",
    "1 loop, best of 3: 471 ms per loop\n",
    "\n",
    "Using a unix epoch time\n",
    "\n",
    ">>> pd.to_datetime(1490195805, unit='s')\n",
    "Timestamp('2017-03-22 15:16:45')\n",
    ">>> pd.to_datetime(1490195805433502912, unit='ns')\n",
    "Timestamp('2017-03-22 15:16:45.433502912')\n",
    "\n",
    ".. warning:: For float arg, precision rounding might happen. To prevent\n",
    "    unexpected behavior use a fixed-width exact type.\n",
    "\n",
    "Using a non-unix epoch origin\n",
    "\n",
    ">>> pd.to_datetime([1, 2, 3], unit='D',\n",
    "...                origin=pd.Timestamp('1960-01-01'))\n",
    "DatetimeIndex(['1960-01-02', '1960-01-03', '1960-01-04'],\n",
    "              dtype='datetime64[ns]', freq=None)\n",
    "\n",
    "**Non-convertible date/times**\n",
    "\n",
    "If a date does not meet the `timestamp limitations\n",
    "<https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html\n",
    "timeseries-timestamp-limits>`_, passing ``errors='ignore'``\n",
    "will return the original input instead of raising any exception.\n",
    "\n",
    "Passing ``errors='coerce'`` will force an out-of-bounds date to :const:`NaT`,\n",
    "in addition to forcing non-dates (or non-parseable dates) to :const:`NaT`.\n",
    "\n",
    ">>> pd.to_datetime('13000101', format='%Y%m%d', errors='ignore')\n",
    "datetime.datetime(1300, 1, 1, 0, 0)\n",
    ">>> pd.to_datetime('13000101', format='%Y%m%d', errors='coerce')\n",
    "NaT\n",
    "\n",
    ".. _to_datetime_tz_examples:\n",
    "\n",
    "**Timezones and time offsets**\n",
    "\n",
    "The default behaviour (``utc=False``) is as follows:\n",
    "\n",
    "- Timezone-naive inputs are converted to timezone-naive :class:`DatetimeIndex`:\n",
    "\n",
    ">>> pd.to_datetime(['2018-10-26 12:00', '2018-10-26 13:00:15'])\n",
    "DatetimeIndex(['2018-10-26 12:00:00', '2018-10-26 13:00:15'],\n",
    "              dtype='datetime64[ns]', freq=None)\n",
    "\n",
    "- Timezone-aware inputs *with constant time offset* are converted to\n",
    "  timezone-aware :class:`DatetimeIndex`:\n",
    "\n",
    ">>> pd.to_datetime(['2018-10-26 12:00 -0500', '2018-10-26 13:00 -0500'])\n",
    "DatetimeIndex(['2018-10-26 12:00:00-05:00', '2018-10-26 13:00:00-05:00'],\n",
    "              dtype='datetime64[ns, pytz.FixedOffset(-300)]', freq=None)\n",
    "\n",
    "- However, timezone-aware inputs *with mixed time offsets* (for example\n",
    "  issued from a timezone with daylight savings, such as Europe/Paris)\n",
    "  are **not successfully converted** to a :class:`DatetimeIndex`. Instead a\n",
    "  simple :class:`Index` containing :class:`datetime.datetime` objects is\n",
    "  returned:\n",
    "\n",
    ">>> pd.to_datetime(['2020-10-25 02:00 +0200', '2020-10-25 04:00 +0100'])\n",
    "Index([2020-10-25 02:00:00+02:00, 2020-10-25 04:00:00+01:00],\n",
    "      dtype='object')\n",
    "\n",
    "- A mix of timezone-aware and timezone-naive inputs is converted to\n",
    "  a timezone-aware :class:`DatetimeIndex` if the offsets of the timezone-aware\n",
    "  are constant:\n",
    "\n",
    ">>> from datetime import datetime\n",
    ">>> pd.to_datetime([\"2020-01-01 01:00 -01:00\", datetime(2020, 1, 1, 3, 0)])\n",
    "DatetimeIndex(['2020-01-01 01:00:00-01:00', '2020-01-01 02:00:00-01:00'],\n",
    "              dtype='datetime64[ns, pytz.FixedOffset(-60)]', freq=None)\n",
    "\n",
    "- Finally, mixing timezone-aware strings and :class:`datetime.datetime` always\n",
    "  raises an error, even if the elements all have the same time offset.\n",
    "\n",
    ">>> from datetime import datetime, timezone, timedelta\n",
    ">>> d = datetime(2020, 1, 1, 18, tzinfo=timezone(-timedelta(hours=1)))\n",
    ">>> pd.to_datetime([\"2020-01-01 17:00 -0100\", d])\n",
    "Traceback (most recent call last):\n",
    "    ...\n",
    "ValueError: Tz-aware datetime.datetime cannot be converted to datetime64\n",
    "            unless utc=True\n",
    "\n",
    "|\n",
    "\n",
    "Setting ``utc=True`` solves most of the above issues:\n",
    "\n",
    "- Timezone-naive inputs are *localized* as UTC\n",
    "\n",
    ">>> pd.to_datetime(['2018-10-26 12:00', '2018-10-26 13:00'], utc=True)\n",
    "DatetimeIndex(['2018-10-26 12:00:00+00:00', '2018-10-26 13:00:00+00:00'],\n",
    "              dtype='datetime64[ns, UTC]', freq=None)\n",
    "\n",
    "- Timezone-aware inputs are *converted* to UTC (the output represents the\n",
    "  exact same datetime, but viewed from the UTC time offset `+00:00`).\n",
    "\n",
    ">>> pd.to_datetime(['2018-10-26 12:00 -0530', '2018-10-26 12:00 -0500'],\n",
    "...                utc=True)\n",
    "DatetimeIndex(['2018-10-26 17:30:00+00:00', '2018-10-26 17:00:00+00:00'],\n",
    "              dtype='datetime64[ns, UTC]', freq=None)\n",
    "\n",
    "- Inputs can contain both naive and aware, string or datetime, the above\n",
    "  rules still apply\n",
    "\n",
    ">>> pd.to_datetime(['2018-10-26 12:00', '2018-10-26 12:00 -0530',\n",
    "...                datetime(2020, 1, 1, 18),\n",
    "...                datetime(2020, 1, 1, 18,\n",
    "...                tzinfo=timezone(-timedelta(hours=1)))],\n",
    "...                utc=True)\n",
    "DatetimeIndex(['2018-10-26 12:00:00+00:00', '2018-10-26 17:30:00+00:00',\n",
    "               '2020-01-01 18:00:00+00:00', '2020-01-01 19:00:00+00:00'],\n",
    "              dtype='datetime64[ns, UTC]', freq=None)\n",
    "\n",
    "</code>\n",
    "<a href='#25'>back to header</a>\n",
    "</blockquote>\n",
    "</details>\n",
    "</li>\n",
    "</ul>\n",
    "</li>\n",
    "\n",
    "</ul>\n",
    "</details> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe56c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "SMS.columns = ['user.id', 'datetime', 'incoming', 'dest.user.id', 'dest.phone.hash',\n",
    "       'id_tuple', 'relationship', 'isSMS', 'isCall', 'isCloseFriend']\n",
    "SMS.datetime = pd.to_datetime(SMS.datetime)\n",
    "fun1 = lambda x : x.time()\n",
    "SMS['time'] = SMS.datetime.apply(fun1)\n",
    "fun2 = lambda x : x > office_time_start and x < office_time_end\n",
    "SMS['inOffice'] = SMS.time.apply(fun2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14c755c",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "SMS.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4d781e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<div> <h3 class='hg'>27. Data Preparation</h3>  <a id='27'></a><small><a href='#top_phases'>back to top</a></small> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478fb382",
   "metadata": {},
   "outputs": [],
   "source": [
    "Calls = Calls.ix[Calls['user.id'] != ['dest.user.id'], :]\n",
    "Calls.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de975d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
